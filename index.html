<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es">
<head>
<!-- 2026-01-22 jue 09:15 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Redes Neuronales Artificiales</title>
<meta name="author" content="Eduardo Alcaraz" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="src/readtheorg_theme/css/readtheorg.css"/>
<script type="text/javascript" src="src/lib/js/jquery.min.js"></script>
<script type="text/javascript" src="src/lib/js/bootstrap.min.js"></script>
<script type="text/javascript" src="src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="src/readtheorg_theme/js/readtheorg.js"></script>
<style> #content{max-width:1800px;}</style>
<style>pre.src {background-color: #303030; color: #e5e5e5;}</style>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Redes Neuronales Artificiales</h1>
<div id="table-of-contents" role="doc-toc">
<h2>&Iacute;ndice</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org0578de3">Presentación del Curso</a>
<ul>
<li><a href="#orgafc0ce4">Objetivo general</a></li>
</ul>
</li>
<li><a href="#org781d2f6">Instalación de requerimientos</a>
<ul>
<li><a href="#org3a6d47c">Verificación de Python</a></li>
<li><a href="#org5efebb7">Creación del entorno virtual</a></li>
<li><a href="#org86c4da1">Activación del entorno virtual</a>
<ul>
<li><a href="#org62edb06">GNU/Linux y macOS</a></li>
<li><a href="#org4eed1c1">Windows – Símbolo del sistema (CMD)</a></li>
<li><a href="#orgd25130c">Windows – PowerShell</a></li>
<li><a href="#org0288a39">Windows – Git Bash</a></li>
</ul>
</li>
<li><a href="#orgd32f5c5">Actualización del gestor de paquetes</a></li>
<li><a href="#orgec5528d">Instalación de dependencias</a></li>
<li><a href="#org3e260b3">Verificación de la instalación</a></li>
<li><a href="#orgd021d99">Desactivación del entorno virtual</a></li>
</ul>
</li>
<li><a href="#orgb9434b6">Manual de Entornos Virtuales en Python</a>
<ul>
<li><a href="#org092b5a8">Introducción</a></li>
<li><a href="#orgbcd7617">Flujo de Trabajo Básico</a>
<ul>
<li><a href="#orgcb07b0e">1. Creación del entorno</a></li>
<li><a href="#org398489d">2. Activación</a></li>
</ul>
</li>
<li><a href="#orgc35a7c9">Gestión de paquetes</a></li>
<li><a href="#org45cf890">El archivo de Requerimientos</a></li>
<li><a href="#orgb99af69">Exportar dependencias</a></li>
<li><a href="#org3cf9dbd">Instalar desde el archivo</a></li>
<li><a href="#orgff22999">Tips de Limpieza</a></li>
<li><a href="#org2c27276">Entornos Virtuales Python (Edición Windows)</a></li>
<li><a href="#org94c90cf">Requisitos Previos</a></li>
<li><a href="#org971074d">Flujo de Trabajo en Windows</a>
<ul>
<li><a href="#org771f650">1. Crear el Entorno Virtual</a></li>
<li><a href="#org3611dd5">2. El Paso Crítico: La Activación</a></li>
<li><a href="#org9dbfaa8">3. Confirmación</a></li>
</ul>
</li>
<li><a href="#org0eea39a">Gestión de Librerías con PIP</a>
<ul>
<li><a href="#org0d94cbd">Instalación de paquetes</a></li>
<li><a href="#org3058664">Congelar dependencias (Compartir proyecto)</a></li>
<li><a href="#orge002bc7">Instalar desde un archivo recibido</a></li>
</ul>
</li>
<li><a href="#orgc247193">Uso de Entornos en Emacs (Windows)</a>
<ul>
<li><a href="#org21d9ae4">Instalación del paquete pyvenv</a></li>
<li><a href="#org99a2204">Cómo activarlo dentro de Emacs</a></li>
</ul>
</li>
<li><a href="#org1c24eed">Solución de Problemas Comunes en Windows</a></li>
<li><a href="#orgcb390bb">Desactivación y Limpieza</a></li>
<li><a href="#org4298281">Agregar a jupyter notebook</a></li>
</ul>
</li>
<li><a href="#orgd85f4db">Introducción a la Inteligencia Artificial (IA)</a>
<ul>
<li><a href="#orgb4ff948">Definición formal</a></li>
<li><a href="#orgedcf31d">IA débil vs IA fuerte</a></li>
</ul>
</li>
<li><a href="#org5e59c2b">Machine Learning (Aprendizaje Automático)</a>
<ul>
<li><a href="#org7a9789c">Tipos de aprendizaje</a></li>
</ul>
</li>
<li><a href="#org4a4ec43">Historia de las Redes Neuronales</a>
<ul>
<li><a href="#org7e09907">Contexto histórico</a></li>
<li><a href="#org33e377e">McCulloch y Pitts (1943)</a></li>
<li><a href="#org845a403">Perceptrón y optimismo inicial</a></li>
<li><a href="#org3accf4b">Críticas y estancamiento</a></li>
<li><a href="#org5174a36">Renacimiento moderno</a></li>
</ul>
</li>
<li><a href="#org3f4c21f">La Neurona Artificial</a>
<ul>
<li><a href="#org328d269">Motivación</a></li>
<li><a href="#orgcccfb62">Componentes</a></li>
<li><a href="#org50dd34a">Modelo matemático</a></li>
</ul>
</li>
<li><a href="#org77dacbf">El Perceptrón</a>
<ul>
<li><a href="#org6dc974d">Definición</a></li>
<li><a href="#org44904dd">Interpretación geométrica</a></li>
<li><a href="#org8480890">Aprendizaje</a></li>
<li><a href="#orgb84ee2e">Limitaciones</a></li>
</ul>
</li>
<li><a href="#orgf2e0ee0">¿Qué es un problema linealmente separable?</a>
<ul>
<li><a href="#orgf0ec79b">Intuición básica</a></li>
</ul>
</li>
<li><a href="#org0b79708">Estructura de un Perceptrón Simple</a>
<ul>
<li><a href="#org1aef6fa">Entradas (Inputs)</a></li>
<li><a href="#org664d7b1">Pesos Sinápticos (Weights)</a></li>
<li><a href="#orgf9d3f22">Suma Ponderada (Weighted Sum)</a></li>
<li><a href="#org1e26ea7">Sesgo (Bias)</a></li>
<li><a href="#org78e4b3c">Función de Activación</a></li>
<li><a href="#org10ecb66">Salida (Output)</a></li>
</ul>
</li>
<li><a href="#org283328d">Ejemplo Tacos</a>
<ul>
<li><a href="#org9fb64bf">1. El Escenario: La Decisión de la Cena</a>
<ul>
<li><a href="#orgfc964f4">Nuestras Entradas (Inputs)</a></li>
<li><a href="#org71fa55b">El Peso (Weight): La Importancia</a></li>
</ul>
</li>
<li><a href="#org9d90d0f">2. ¿Cómo toma la decisión? (La Suma y el Sesgo)</a>
<ul>
<li><a href="#orge748a72">El Sesgo (Bias)</a></li>
</ul>
</li>
<li><a href="#org56cecce">3. El Descenso del Gradiente: ¿Cómo "Aprende" la Neurona?</a>
<ul>
<li><a href="#orgf5167ce">El Error: La Brújula</a></li>
<li><a href="#org02111c9">El Ajuste (La Regla Delta)</a></li>
</ul>
</li>
<li><a href="#org9bf12b5">Perceptrón ejemplo (Python)</a>
<ul>
<li><a href="#orgb76a05f">Perceptrón para una compuerta "AND"</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org9a53982">Codigo C python</a></li>
<li><a href="#org25cc032">Redes Neuronales Multicapa (Multilayer Perceptron)</a>
<ul>
<li><a href="#orgbd138a4">Introducción</a></li>
<li><a href="#org0ff6595">Modelo matemático</a>
<ul>
<li><a href="#org19f75a2">Neurona individual</a></li>
<li><a href="#orgc3a2f26">Forma matricial de una capa</a></li>
</ul>
</li>
<li><a href="#orgf3554df">Funciones de activación</a>
<ul>
<li><a href="#orgdd6fd9d">¿Para qué sirven las funciones de activación?</a></li>
</ul>
</li>
<li><a href="#org0f05bba">Clasificación de las funciones de activación</a>
<ul>
<li><a href="#org78d849d">Funciones de activación clásicas</a></li>
<li><a href="#org95ec858">Funciones de activación modernas</a></li>
<li><a href="#orge891035">Funciones de activación en la capa de salida</a></li>
<li><a href="#org0006919">Impacto en el entrenamiento</a></li>
</ul>
</li>
<li><a href="#orgc6c4f00">Propagación hacia adelante (Forward Propagation)</a></li>
<li><a href="#org9eb7fa2">Funciones de pérdida</a>
<ul>
<li><a href="#orga3cf2ff">Error cuadrático medio (MSE)</a></li>
<li><a href="#org4a6bd31">Entropía cruzada (Cross-Entropy)</a></li>
</ul>
</li>
<li><a href="#org6954e52">Backpropagation</a></li>
<li><a href="#orgad8adcb">Descenso de gradiente</a></li>
</ul>
</li>
<li><a href="#org78bfea3">Ejemplo Clasificación del dataset Iris con MLP</a>
<ul>
<li><a href="#orgc5fe42a">Reproducibilidad del experimento</a></li>
<li><a href="#orgb87ed75">Estratificación de clases</a></li>
<li><a href="#org1b123d7">Importancia en redes neuronales</a></li>
<li><a href="#org04559a5">Normalización de los datos</a></li>
<li><a href="#org9276b26">Definir el Perceptrón Multicapa (MLP)</a>
<ul>
<li><a href="#orgcc7f0a9">Arquitectura de la red neuronal</a></li>
<li><a href="#org49b240a">Capa de entrada</a></li>
<li><a href="#org9c5fd14">Capas ocultas</a></li>
<li><a href="#org0e3bd62">Función de activación</a></li>
<li><a href="#org072a2f8">Capa de salida</a></li>
<li><a href="#org572939d">Entrenamiento del modelo</a></li>
</ul>
</li>
<li><a href="#org399a85b">Número de iteraciones</a></li>
<li><a href="#orge3ce6d6">Reproducibilidad</a></li>
<li><a href="#orgb68a41a">Entrenamiento del modelo</a>
<ul>
<li><a href="#org9e03b80">Propagación hacia adelante (forward pass)</a></li>
<li><a href="#org8c8e72f">Cálculo del error</a></li>
<li><a href="#orga2eb6c7">Backpropagation</a></li>
<li><a href="#org97f8834">Descenso de gradiente con Adam</a></li>
</ul>
</li>
<li><a href="#orgc2d613e">Evaluación del modelo</a>
<ul>
<li><a href="#orga395feb">Métricas utilizadas</a></li>
</ul>
</li>
<li><a href="#org43b55d9">Predicción con una nueva flor</a></li>
<li><a href="#org57eb578">Interpretación matemática del MLP</a></li>
</ul>
</li>
<li><a href="#org7a7506f">Ejemplo Clasificación de Cáncer de Mama con MLP</a>
<ul>
<li><a href="#orgd5e9dd9">Importar librerías</a></li>
<li><a href="#org57b2039">Cargar el dataset Breast Cancer</a>
<ul>
<li><a href="#orgbb49222">Importancia del dominio</a></li>
</ul>
</li>
<li><a href="#orgeb76b5d">Partición del conjunto de datos</a>
<ul>
<li><a href="#org4c986be">Significado de los parámetros</a></li>
<li><a href="#org6e2705d">Propósito de la partición</a></li>
</ul>
</li>
<li><a href="#org2bf65fb">Normalización (Estandarización)</a>
<ul>
<li><a href="#orgf3bea83">Importante</a></li>
</ul>
</li>
<li><a href="#org0ad78e8">Definición del Perceptrón Multicapa (MLP)</a>
<ul>
<li><a href="#orgd83e35f">Arquitectura del modelo</a></li>
<li><a href="#orgd231633">Función de activación ReLU</a></li>
<li><a href="#org34da567">Optimizador Adam</a></li>
<li><a href="#org24820ea">Número máximo de iteraciones</a></li>
<li><a href="#org57241e7">Reproducibilidad</a></li>
</ul>
</li>
<li><a href="#org16c99ca">Entrenamiento del modelo</a>
<ul>
<li><a href="#orga737dff">Proceso interno (visión conceptual)</a></li>
</ul>
</li>
<li><a href="#org72e3b1e">Evaluación del modelo</a>
<ul>
<li><a href="#org383afd9">Métricas principales</a></li>
</ul>
</li>
<li><a href="#org2933617">Interpretación matemática de la salida binaria</a></li>
<li><a href="#orgb59e385">Predicción de una nueva muestra</a>
<ul>
<li><a href="#org23aa0ee">Comentarios importantes</a></li>
</ul>
</li>
<li><a href="#org5b3b989">Resumen conceptual</a></li>
</ul>
</li>
<li><a href="#org71f1a3e">Juego de Bala y Salto con MLP</a>
<ul>
<li><a href="#orge715c10">Introducción</a>
<ul>
<li><a href="#org152d922">¿Qué es este juego?</a></li>
<li><a href="#org524dc9e">Concepto principal</a></li>
<li><a href="#org92cde8f">Objetivo del juego</a></li>
</ul>
</li>
<li><a href="#org13d5d50">Requisitos e Instalación</a>
<ul>
<li><a href="#org3d87e59">Dependencias necesarias</a></li>
<li><a href="#orgbffb2cf">Instalación</a></li>
<li><a href="#org7aa224c">Estructura de archivos</a></li>
</ul>
</li>
<li><a href="#org27f95ba">Cómo Jugar</a>
<ul>
<li><a href="#org3ee1a2b">Iniciar el juego</a></li>
<li><a href="#org0c69b59">Menú principal</a></li>
<li><a href="#org8554341">Controles durante el juego</a></li>
</ul>
</li>
<li><a href="#org82be7ab">Modo Manual: Recolectando Datos</a>
<ul>
<li><a href="#org0ca9650">¿Qué hace el modo manual?</a></li>
<li><a href="#org6c3e704">Cómo jugar en modo manual</a></li>
<li><a href="#org36bdcd5">Consejos para recolectar buenos datos</a></li>
<li><a href="#org3fd0398">Registro de datos</a></li>
</ul>
</li>
<li><a href="#org98d0421">Entrenamiento del Modelo MLP</a>
<ul>
<li><a href="#org12fa1cc">¿Qué es un MLP?</a></li>
<li><a href="#org37c0128">Arquitectura del modelo</a></li>
<li><a href="#org37465a7">Cómo entrenar</a></li>
<li><a href="#orge348a56">Casos especiales</a></li>
<li><a href="#org84721c1">Interpretando los resultados</a></li>
</ul>
</li>
<li><a href="#orgec493b5">Modo Auto: El MLP Juega Solo</a>
<ul>
<li><a href="#org4205575">¿Qué hace el modo auto?</a></li>
<li><a href="#org0baba3b">Cómo activar modo auto</a></li>
<li><a href="#org087f401">Visualización en tiempo real</a></li>
<li><a href="#org3ae4d01">Limitaciones del modo auto</a></li>
</ul>
</li>
<li><a href="#orgcb82d65">Exportación y Visualización de Datos</a>
<ul>
<li><a href="#org9125d21">Exportar a CSV</a></li>
<li><a href="#org9425b97">Visualizar los datos</a></li>
<li><a href="#org29adcfc">Interpretando las gráficas</a></li>
</ul>
</li>
<li><a href="#org1ef95ca">Arquitectura del Código</a>
<ul>
<li><a href="#org3cd0b95">Estructura principal</a></li>
<li><a href="#org16d0ca5">Clase Sample</a></li>
<li><a href="#orgaef5915">Flujo de datos</a></li>
</ul>
</li>
<li><a href="#orga63029c">Parámetros Configurables</a>
<ul>
<li><a href="#org1bccb08">Parámetros del juego</a></li>
<li><a href="#orgc332bc3">Parámetros del MLP</a></li>
<li><a href="#org3781b79">Parámetros de registro</a></li>
</ul>
</li>
<li><a href="#org7c78b18">Mejores Prácticas</a>
<ul>
<li><a href="#orgf150d15">Recolectando datos de calidad</a></li>
<li><a href="#orgdc25001">Entrenando el modelo</a></li>
<li><a href="#orgf00d02b">Jugando en modo auto</a></li>
</ul>
</li>
<li><a href="#org05f7242">Solución de Problemas</a>
<ul>
<li><a href="#org0c10d19">El modelo no aprende (accuracy &lt; 0.5)</a></li>
<li><a href="#org82515a1">El modo auto no salta nunca</a></li>
<li><a href="#org21ad150">El modo auto salta demasiado</a></li>
<li><a href="#org6f04c16">Las gráficas no se muestran</a></li>
<li><a href="#org6da0f21">El juego se ve lento o con lag</a></li>
</ul>
</li>
<li><a href="#org70e46b7">Conceptos Técnicos Avanzados</a>
<ul>
<li><a href="#org504f3b5">¿Por qué MLP y no otro algoritmo?</a></li>
<li><a href="#org753a247">Normalización (StandardScaler)</a></li>
<li><a href="#orgad31a25">División train/test</a></li>
<li><a href="#org7690aa4">Overfitting y Underfitting</a></li>
</ul>
</li>
<li><a href="#org355b6df">Código de Ejemplo</a>
<ul>
<li><a href="#org697a364">Cargar y visualizar datos manualmente</a></li>
<li><a href="#org593659f">Entrenar modelo desde CSV</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orge9b21eb">Métricas de Evaluación para Machine Learning</a>
<ul>
<li><a href="#org4ad9e76">Introducción</a>
<ul>
<li><a href="#org9305658">¿Qué son las métricas de evaluación?</a></li>
<li><a href="#org1e48330">¿Por qué son importantes?</a></li>
</ul>
</li>
<li><a href="#org1ce3a0e">Matriz de Confusión: La Base de Todo</a>
<ul>
<li><a href="#orgebc2286">¿Qué es una matriz de confusión?</a></li>
<li><a href="#org1fc891c">Estructura de la matriz (2 clases)</a></li>
<li><a href="#org97b91fd">Interpretación en el contexto del juego</a></li>
<li><a href="#org3e1c3ed">Ejemplo práctico</a></li>
</ul>
</li>
<li><a href="#orgd7257bb">Accuracy (Precisión General)</a>
<ul>
<li><a href="#orged575be">Definición</a></li>
<li><a href="#org037682a">Cálculo del ejemplo anterior</a></li>
<li><a href="#org358761b">Ventajas</a></li>
<li><a href="#org83c5a06">Desventajas</a></li>
<li><a href="#orgd04aa5e">Ejemplo del problema</a></li>
<li><a href="#org3047b21">Cuándo usar Accuracy</a></li>
</ul>
</li>
<li><a href="#org3e6f22e">Precision (Precisión)</a>
<ul>
<li><a href="#org6faf81f">Definición</a></li>
<li><a href="#orgd2c416e">Cálculo del ejemplo</a></li>
<li><a href="#orgc9c755a">Interpretación</a></li>
<li><a href="#org32135d7">En el contexto del juego</a></li>
<li><a href="#org0901f2e">Cuándo es importante</a></li>
</ul>
</li>
<li><a href="#orgc9c7b48">Recall (Sensibilidad o Exhaustividad)</a>
<ul>
<li><a href="#org2da609b">Definición</a></li>
<li><a href="#orgfefe95e">Cálculo del ejemplo</a></li>
<li><a href="#org9b67850">Interpretación</a></li>
<li><a href="#orgcd63016">En el contexto del juego</a></li>
<li><a href="#org84adcf3">Cuándo es crítico</a></li>
<li><a href="#org4bd0c8e">Trade-off Precision vs Recall</a></li>
</ul>
</li>
<li><a href="#orgdd7a2d2">F1-Score: El Balance Perfecto</a>
<ul>
<li><a href="#org518f7cd">Definición</a></li>
<li><a href="#org14461a6">Cálculo del ejemplo</a></li>
<li><a href="#orge03020b">¿Por qué media armónica y no aritmética?</a></li>
<li><a href="#org546072d">Ventajas</a></li>
<li><a href="#orgcad701c">Desventajas</a></li>
<li><a href="#org2e433dc">Cuándo usar F1-Score</a></li>
</ul>
</li>
<li><a href="#org187bf49">Especificidad</a>
<ul>
<li><a href="#orga14ec63">Definición</a></li>
<li><a href="#org0e19282">Cálculo del ejemplo</a></li>
<li><a href="#org9fc0481">Interpretación</a></li>
<li><a href="#org57b6b08">En el contexto del juego</a></li>
</ul>
</li>
<li><a href="#org8f024a0">Comparación de Métricas: Tabla Resumen</a>
<ul>
<li><a href="#orgad3745f">Valores del ejemplo</a></li>
<li><a href="#org7b36f1d">¿Qué métrica usar?</a></li>
</ul>
</li>
<li><a href="#orgf93ae1d">Casos de Uso en el Juego</a>
<ul>
<li><a href="#org58294cb">Escenario 1: Modelo Conservador</a></li>
<li><a href="#orgc9eb7a7">Escenario 2: Modelo Agresivo</a></li>
<li><a href="#orgff6c6df">Escenario 3: Modelo Balanceado (Ideal)</a></li>
</ul>
</li>
<li><a href="#orgf6543cc">Implementación en Python</a>
<ul>
<li><a href="#orgdba9236">Cálculo manual de métricas</a></li>
<li><a href="#org5f3568f">Reporte completo de clasificación</a></li>
<li><a href="#orgb3a34f7">Visualización de la matriz de confusión</a></li>
</ul>
</li>
<li><a href="#org20f96ad">Mejorando el Juego con Métricas</a>
<ul>
<li><a href="#org4c0e601">Añadir métricas al entrenamiento</a></li>
<li><a href="#org0bb293c">Interpretar resultados en el juego</a></li>
</ul>
</li>
<li><a href="#org15a3216">Curvas ROC y AUC</a>
<ul>
<li><a href="#org4b7c4be">¿Qué es la curva ROC?</a></li>
<li><a href="#org58ec9a3">¿Qué es AUC?</a></li>
<li><a href="#org62fcf92">Código para generar curva ROC</a></li>
<li><a href="#org728b922">Interpretación</a></li>
</ul>
</li>
<li><a href="#orgc518504">Métricas para Clases Desbalanceadas</a>
<ul>
<li><a href="#org999d632">El problema</a></li>
<li><a href="#org4b39f31">Soluciones</a></li>
</ul>
</li>
<li><a href="#orga4070a2">Resumen: Guía Rápida</a>
<ul>
<li><a href="#org91f537e">Tabla de métricas clave</a></li>
<li><a href="#org43dd4cb">Decisión rápida: ¿Qué métrica usar?</a></li>
<li><a href="#org8dd0506">Checklist de evaluación</a></li>
</ul>
</li>
<li><a href="#orgfe9763b">Ejercicios Prácticos</a>
<ul>
<li><a href="#org8f64854">Ejercicio 1: Calcular métricas manualmente</a></li>
<li><a href="#org25b125d">Ejercicio 2: Interpretar resultados</a></li>
<li><a href="#orge9b9df8">Ejercicio 3: Mejorar un modelo</a></li>
</ul>
</li>
<li><a href="#org41135ad">Referencias y Recursos</a>
<ul>
<li><a href="#orga74b109">Documentación oficial</a></li>
<li><a href="#org6ce5dee">Lecturas recomendadas</a></li>
<li><a href="#orgf5ad7e4">Herramientas útiles</a></li>
</ul>
</li>
<li><a href="#org192bbfb">Conclusión</a></li>
</ul>
</li>
<li><a href="#org8c7aef8">Redes Neuronales Recurrentes (RNN)</a>
<ul>
<li><a href="#org48f4c30">Introducción</a>
<ul>
<li><a href="#org61a69fa">¿Qué son las Redes Recurrentes?</a></li>
<li><a href="#orgb297444">Características Fundamentales</a></li>
<li><a href="#org40daabd">Aplicaciones Comunes</a></li>
</ul>
</li>
<li><a href="#org9f75a96">El Problema que Resuelven las RNN</a>
<ul>
<li><a href="#org288cd58">Limitaciones de las Redes Feedforward</a></li>
<li><a href="#org1ddbc95">El Concepto de Secuencias</a></li>
</ul>
</li>
<li><a href="#org4f6da19">Arquitectura Básica de RNN</a>
<ul>
<li><a href="#orgf46e076">Estructura Fundamental</a></li>
<li><a href="#org7fdc11a">La Ecuación Matemática Fundamental</a></li>
<li><a href="#org8f2801b">Desglose Detallado de la Ecuación</a></li>
<li><a href="#org4d02370">Ejemplo Numérico Simple</a></li>
</ul>
</li>
<li><a href="#orgbda53d1">Propagación hacia Atrás en el Tiempo (BPTT)</a>
<ul>
<li><a href="#orgf74bab2">¿Qué es BPTT?</a></li>
<li><a href="#org1a34082">Analogía</a></li>
<li><a href="#org449f5aa">Cálculo de Gradientes</a></li>
<li><a href="#org45d1dee">El Problema del Gradiente que Desaparece</a></li>
<li><a href="#org1d44e7f">El Problema del Gradiente que Explota</a></li>
<li><a href="#org11df123">Soluciones</a></li>
</ul>
</li>
<li><a href="#orgbfae015">Tipos de Redes Recurrentes</a>
<ul>
<li><a href="#org68fc8de">RNN Vanilla (SimpleRNN)</a></li>
<li><a href="#orge17fefe">LSTM (Long Short-Term Memory)</a></li>
<li><a href="#orgdba46a0">GRU (Gated Recurrent Unit)</a></li>
</ul>
</li>
<li><a href="#org389ab2b">Implementación Práctica</a>
<ul>
<li><a href="#org13b73d1">Implementación desde Cero (NumPy)</a></li>
<li><a href="#orgdbe8dbc">Implementación con Keras/TensorFlow</a></li>
<li><a href="#orgd02aa86">Implementación con LSTM</a></li>
<li><a href="#org32ff645">Implementación con GRU</a></li>
</ul>
</li>
<li><a href="#org38e7b5c">Ejemplos Prácticos</a>
<ul>
<li><a href="#orga6d867e">Ejemplo 1: Predicción de Series Temporales</a></li>
<li><a href="#org7a97e20">Ejemplo 2: Clasificación de Texto</a></li>
<li><a href="#org74a6e42">Ejemplo 3: Generación de Secuencias</a></li>
</ul>
</li>
<li><a href="#orgaa07859">Variantes y Extensiones</a>
<ul>
<li><a href="#orgcdcafab">RNN Bidireccional</a></li>
<li><a href="#org6da1340">RNN Apiladas (Stacked)</a></li>
<li><a href="#org08e1e72">Attention Mechanism</a></li>
</ul>
</li>
<li><a href="#org4135e1a">Regularización y Mejoras</a>
<ul>
<li><a href="#orgdf401ff">Dropout</a></li>
<li><a href="#org40e3794">Early Stopping</a></li>
<li><a href="#orgd79965c">Gradient Clipping</a></li>
</ul>
</li>
<li><a href="#orgb98ceb8">Conceptos Clave</a>
<ul>
<li><a href="#org667e0a5">Cuándo Usar RNN</a></li>
<li><a href="#orga4c90b9">Cuándo NO Usar RNN</a></li>
<li><a href="#org45f99b5">Próximos Pasos</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org1c8a5a1">Redes Recurrentes (RNN) con Aplicación al Juego</a>
<ul>
<li><a href="#org9b9bb80">Introducción</a>
<ul>
<li><a href="#org2320d08">¿Qué son las Redes Recurrentes?</a></li>
<li><a href="#orgf055e60">¿Por qué RNN para el juego?</a></li>
<li><a href="#org1137961">Objetivo de estas notas</a></li>
</ul>
</li>
<li><a href="#org2fc62c7">Conceptos Fundamentales</a>
<ul>
<li><a href="#orge1d6668">El Problema de las Secuencias</a></li>
<li><a href="#orgb38dc52">Arquitectura Básica de RNN</a></li>
<li><a href="#org89994e6">Ecuación Matemática Básica</a></li>
<li><a href="#org5c82640">Ventajas de RNN</a></li>
<li><a href="#orgee38827">Desventajas de RNN Vanilla</a></li>
</ul>
</li>
<li><a href="#orga373c7d">Matemáticas Detalladas de las Redes Recurrentes</a>
<ul>
<li><a href="#orgcfcb00e">Desglose Paso a Paso de las Ecuaciones</a></li>
<li><a href="#orgd126d0e">Ecuación del Estado Oculto (Hidden State)</a></li>
<li><a href="#org4cf6278">Ecuación de la Salida</a></li>
<li><a href="#orgc474a38">Ejemplo Numérico Concreto</a></li>
<li><a href="#orgad06936">Cálculo de la Salida</a></li>
<li><a href="#orga607972">Propagación hacia Atrás en el Tiempo (BPTT)</a></li>
<li><a href="#org7938dfa">Idea General</a></li>
<li><a href="#org898b7ad">Derivadas Necesarias</a></li>
<li><a href="#orgd5fdb55">Cálculo del Gradiente en el Tiempo T</a></li>
<li><a href="#orgfd4d1ba">Ejemplo del Problema del Gradiente que Desaparece</a></li>
<li><a href="#org607f929">Visualización del Flujo de Información</a></li>
<li><a href="#org04eb302">Descomposición de la Ecuación RNN</a></li>
<li><a href="#org349ed9c">Función de Activación tanh</a></li>
<li><a href="#org68a3482">Ejemplo Completo: Secuencia de 3 Frames</a></li>
<li><a href="#org5f96cbc">Representación Matricial Completa</a></li>
<li><a href="#org2bc82e7">Cálculo de la Pérdida y Optimización</a></li>
<li><a href="#org99d24e6">Implementación Numérica</a></li>
<li><a href="#org0c48849">Resumen Matemático</a></li>
</ul>
</li>
<li><a href="#orgb7d9d8b">Tipos de Redes Recurrentes</a>
<ul>
<li><a href="#org71784cb">RNN Vanilla (Simple)</a></li>
<li><a href="#org8835713">LSTM (Long Short-Term Memory)</a></li>
<li><a href="#orgacc372a">GRU (Gated Recurrent Unit)</a></li>
</ul>
</li>
<li><a href="#orgf0ce3a4">Adaptando el Juego para RNN</a>
<ul>
<li><a href="#org0c489a2">Cambios Necesarios en los Datos</a></li>
<li><a href="#org570e72b">Estructura de Datos para RNN</a></li>
<li><a href="#org9060f4e">Longitud de Secuencia</a></li>
<li><a href="#orgcb74237">Ventana Deslizante (Sliding Window)</a></li>
</ul>
</li>
<li><a href="#orgd6eacb8">Implementación Práctica</a>
<ul>
<li><a href="#org3381c73">Instalación de Dependencias</a></li>
<li><a href="#org0d1fd23">Modificando el Juego: Recolectar Secuencias</a></li>
<li><a href="#org2ebc7d1">Preparación de Datos para RNN</a></li>
<li><a href="#org0fe380a">Creando una RNN con Keras</a></li>
<li><a href="#org1d02aeb">Entrenamiento de la RNN</a></li>
<li><a href="#org35ca976">Predicción con RNN</a></li>
</ul>
</li>
<li><a href="#org4ff89dd">Comparación: MLP vs RNN</a>
<ul>
<li><a href="#org109a23a">Tabla Comparativa</a></li>
<li><a href="#orgf76bda9">Ejemplo Práctico: Misma Situación</a></li>
<li><a href="#org6f6facc">Cuándo Usar Cada Una</a></li>
</ul>
</li>
<li><a href="#orgeaff0de">Implementación Completa: Juego con RNN</a>
<ul>
<li><a href="#org9d47443">Estructura del Código</a></li>
</ul>
</li>
<li><a href="#org04afa66">Visualización de Secuencias</a>
<ul>
<li><a href="#org33286be">Graficar Secuencias Temporales</a></li>
</ul>
</li>
<li><a href="#org176c179">Actividades Prácticas</a>
<ul>
<li><a href="#orgaa3a1ee">Actividad 1: Comparar MLP vs RNN</a></li>
<li><a href="#orgbd8821b">Actividad 2: Experimentar con Longitud de Secuencia</a></li>
<li><a href="#orgfbcebb9">Actividad 3: Comparar Tipos de RNN</a></li>
<li><a href="#orga32e15e">Actividad 4: Análisis de Secuencias</a></li>
</ul>
</li>
<li><a href="#org0b6cbde">Conceptos Avanzados</a>
<ul>
<li><a href="#orgeda4ef9">Bidireccionalidad (Bidirectional RNN)</a></li>
<li><a href="#orgb2a61b8">Stacked RNN (RNN Apiladas)</a></li>
<li><a href="#org67f236f">Attention Mechanism</a></li>
<li><a href="#org25ca826">Regularización para RNN</a></li>
</ul>
</li>
<li><a href="#org60178a7">Troubleshooting Común</a>
<ul>
<li><a href="#orgc99cc70">Problema: "No hay suficientes datos"</a></li>
<li><a href="#org9f9b50c">Problema: "El modelo no aprende (loss no baja)"</a></li>
<li><a href="#orgc55e954">Problema: "Overfitting (accuracy train &gt;&gt; accuracy test)"</a></li>
<li><a href="#org0133f95">Problema: "Entrenamiento muy lento"</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org1045288">Redes Neuronales LSTM (Long Short-Term Memory)</a>
<ul>
<li><a href="#orgbb76339">Estructura general de una RNN</a>
<ul>
<li><a href="#org9f5e7a6">Problema: vanishing y exploding gradients</a></li>
</ul>
</li>
<li><a href="#org735c313">Motivación de las LSTM</a></li>
<li><a href="#org4bbd0a8">Arquitectura interna de una celda LSTM</a>
<ul>
<li><a href="#orgb64c9cc">Ecuaciones de la LSTM</a></li>
<li><a href="#org6357ddc">Interpretación de las puertas</a></li>
</ul>
</li>
<li><a href="#orgd57c3b7">Intuición conceptual</a></li>
<li><a href="#org4338421">Entrenamiento de una LSTM</a></li>
<li><a href="#org91a1f9a">Tipos de tareas típicas con LSTM</a></li>
<li><a href="#org10b4b28">Variantes y extensiones de LSTM</a></li>
<li><a href="#orgde6d266">Implementación básica en Python (Keras)</a></li>
<li><a href="#orgcf7ef7b">Ventajas y limitaciones de LSTM</a>
<ul>
<li><a href="#org022b700">Ventajas</a></li>
<li><a href="#org8c2821d">Limitaciones</a></li>
</ul>
</li>
<li><a href="#orgf3c31f7">Conclusión</a></li>
</ul>
</li>
<li><a href="#orgda04a0a">Ejemplo Clasificación del dataset Iris con una red LSTM</a>
<ul>
<li><a href="#org89e758c">Importar librerías</a></li>
<li><a href="#org3f6c220">Cargar el dataset Iris</a></li>
<li><a href="#org836caf5">Partición entrenamiento / prueba</a>
<ul>
<li><a href="#org1065ce6">Propósito de la partición</a></li>
<li><a href="#org51f6f57">Parámetro test<sub>size</sub></a></li>
<li><a href="#orgda8f574">Reproducibilidad del experimento</a></li>
<li><a href="#org2b5088a">Estratificación de clases</a></li>
</ul>
</li>
<li><a href="#orgc8f85a3">Normalización de los datos</a></li>
<li><a href="#org70b6344">Preparar los datos para LSTM</a></li>
<li><a href="#org0bffa15">Definir la red LSTM</a>
<ul>
<li><a href="#org871cecb">Arquitectura de la red</a></li>
</ul>
</li>
<li><a href="#org594fc8a">Compilación del modelo</a></li>
<li><a href="#org844c4fb">Entrenamiento del modelo LSTM</a>
<ul>
<li><a href="#org3f59729">Propagación hacia adelante (forward pass)</a></li>
<li><a href="#org9a73e56">Cálculo del error</a></li>
<li><a href="#org0bd1ce6">Backpropagation Through Time (BPTT)</a></li>
<li><a href="#org4496298">Descenso de gradiente con Adam</a></li>
</ul>
</li>
<li><a href="#orga182cf4">Evaluación del modelo</a>
<ul>
<li><a href="#org97da62f">Métricas utilizadas</a></li>
</ul>
</li>
<li><a href="#org552cdf9">Predicción con una nueva flor</a></li>
<li><a href="#orge649d6b">Interpretación matemática básica de la LSTM</a></li>
</ul>
</li>
<li><a href="#org2b976a8">Bibliografía  Deep Learning</a>
<ul>
<li><a href="#org40ff0e0">Teórica y Académica&#xa0;&#xa0;&#xa0;<span class="tag"><span class="MATEMATICAS">MATEMATICAS</span>&#xa0;<span class="FUNDAMENTOS">FUNDAMENTOS</span></span></a>
<ul>
<li><a href="#orge063114">Deep Learning</a></li>
<li><a href="#org3c33460">Neural Networks and Deep Learning: A Textbook</a></li>
</ul>
</li>
<li><a href="#orgd417486">Práctica y Programación&#xa0;&#xa0;&#xa0;<span class="tag"><span class="PYTHON">PYTHON</span>&#xa0;<span class="PYTORCH">PYTORCH</span>&#xa0;<span class="KERAS">KERAS</span></span></a>
<ul>
<li><a href="#orgcd85552">Deep Learning with Python (3rd Edition)</a></li>
<li><a href="#org97e6bd7">Hands-On Machine Learning with Scikit-Learn and PyTorch</a></li>
</ul>
</li>
<li><a href="#org30571c1">Aprendizaje "Desde Cero"&#xa0;&#xa0;&#xa0;<span class="tag"><span class="NUMPY">NUMPY</span>&#xa0;<span class="LOGICA">LOGICA</span></span></a>
<ul>
<li><a href="#orgeacc3f3">Grokking Deep Learning</a></li>
<li><a href="#orgb93e5b6">Neural Networks from Scratch (NNFS)</a></li>
</ul>
</li>
<li><a href="#orgc2e1102">Tabla Comparativa para Elección Rápida</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org0578de3" class="outline-2">
<h2 id="org0578de3">Presentación del Curso</h2>
<div class="outline-text-2" id="text-org0578de3">
</div>
<div id="outline-container-orgafc0ce4" class="outline-3">
<h3 id="orgafc0ce4">Objetivo general</h3>
<div class="outline-text-3" id="text-orgafc0ce4">
<p>
Este curso tiene como objetivo proporcionar una
comprensión <b>profunda y progresiva</b> de las redes neuronales
artificiales, desde sus fundamentos teóricos hasta las principales
arquitecturas modernas utilizadas en la industria y la
investigación.
</p>


<ul class="org-ul">
<li>Fundamentos matemáticos y conceptuales</li>
<li>Funcionamiento interno de una red neuronal</li>
<li>Entrenamiento y optimización</li>
<li>Arquitecturas principales</li>
<li>Intuición práctica y casos de uso</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org781d2f6" class="outline-2">
<h2 id="org781d2f6">Instalación de requerimientos</h2>
<div class="outline-text-2" id="text-org781d2f6">
</div>
<div id="outline-container-org3a6d47c" class="outline-3">
<h3 id="org3a6d47c">Verificación de Python</h3>
<div class="outline-text-3" id="text-org3a6d47c">
<p>
Antes de instalar las dependencias, verifique que el sistema cuente con Python
versión 3.9 o superior.
</p>

<div class="org-src-container">
<pre class="src src-bash">python --version
</pre>
</div>

<p>
En caso de que el comando anterior no esté disponible, intente:
</p>

<div class="org-src-container">
<pre class="src src-bash">python3 --version
</pre>
</div>
</div>
</div>
<div id="outline-container-org5efebb7" class="outline-3">
<h3 id="org5efebb7">Creación del entorno virtual</h3>
<div class="outline-text-3" id="text-org5efebb7">
<p>
Se recomienda crear un entorno virtual para aislar las dependencias del proyecto
y evitar conflictos entre versiones de librerías.
</p>

<div class="org-src-container">
<pre class="src src-bash">python -m venv mlp_env
</pre>
</div>
</div>
</div>
<div id="outline-container-org86c4da1" class="outline-3">
<h3 id="org86c4da1">Activación del entorno virtual</h3>
<div class="outline-text-3" id="text-org86c4da1">
<p>
La activación del entorno virtual depende del sistema operativo y del intérprete
de comandos utilizado.
</p>
</div>
<div id="outline-container-org62edb06" class="outline-4">
<h4 id="org62edb06">GNU/Linux y macOS</h4>
<div class="outline-text-4" id="text-org62edb06">
<div class="org-src-container">
<pre class="src src-bash"><span style="color: #fe8019;">source</span> mlp_env/bin/activate
</pre>
</div>
</div>
</div>
<div id="outline-container-org4eed1c1" class="outline-4">
<h4 id="org4eed1c1">Windows – Símbolo del sistema (CMD)</h4>
<div class="outline-text-4" id="text-org4eed1c1">
<p>
Si se utiliza el <b>Símbolo del sistema</b> (cmd.exe), ejecute:
</p>

<div class="org-src-container">
<pre class="src src-bat">mlp_env\Scripts\activate.bat
</pre>
</div>
</div>
</div>
<div id="outline-container-orgd25130c" class="outline-4">
<h4 id="orgd25130c">Windows – PowerShell</h4>
<div class="outline-text-4" id="text-orgd25130c">
<p>
Si se utiliza <b>Windows PowerShell</b>, ejecute:
</p>

<div class="org-src-container">
<pre class="src src-powershell">mlp_env\Scripts\Activate.ps1
</pre>
</div>

<p>
En caso de que la ejecución de scripts esté deshabilitada, habilítela
temporalmente con:
</p>

<div class="org-src-container">
<pre class="src src-powershell">Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process
</pre>
</div>

<p>
Posteriormente, vuelva a ejecutar el comando de activación.
</p>
</div>
</div>
<div id="outline-container-org0288a39" class="outline-4">
<h4 id="org0288a39">Windows – Git Bash</h4>
<div class="outline-text-4" id="text-org0288a39">
<p>
Si se utiliza <b>Git Bash</b>, ejecute:
</p>

<div class="org-src-container">
<pre class="src src-bash"><span style="color: #fe8019;">source</span> mlp_env/Scripts/activate
</pre>
</div>

<p>
Una vez activado el entorno virtual, el nombre del entorno aparecerá entre
paréntesis al inicio de la línea de comandos.
</p>
</div>
</div>
</div>
<div id="outline-container-orgd32f5c5" class="outline-3">
<h3 id="orgd32f5c5">Actualización del gestor de paquetes</h3>
<div class="outline-text-3" id="text-orgd32f5c5">
<p>
Antes de instalar las librerías, se recomienda actualizar el gestor de paquetes
<code>pip</code>.
</p>

<div class="org-src-container">
<pre class="src src-bash">pip install --upgrade pip
</pre>
</div>
</div>
</div>
<div id="outline-container-orgec5528d" class="outline-3">
<h3 id="orgec5528d">Instalación de dependencias</h3>
<div class="outline-text-3" id="text-orgec5528d">
<p>
Ejecute el siguiente comando para instalar los requerimientos del módulo
Perceptrón Multicapa <b>feedforward</b>.
</p>

<div class="org-src-container">
<pre class="src src-bash">pip install numpy matplotlib scikit-learn pygame
</pre>
</div>
</div>
</div>
<div id="outline-container-org3e260b3" class="outline-3">
<h3 id="org3e260b3">Verificación de la instalación</h3>
<div class="outline-text-3" id="text-org3e260b3">
<p>
Para verificar que las dependencias se instalaron correctamente, ejecute Python
en modo interactivo:
</p>

<div class="org-src-container">
<pre class="src src-bash">python
</pre>
</div>

<p>
Posteriormente, importe las librerías:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> numpy
<span style="color: #fb4934;">import</span> matplotlib
<span style="color: #fb4934;">import</span> sklearn
<span style="color: #fb4934;">import</span> pygame
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Instalaci&#243;n de requerimientos completada correctamente"</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgd021d99" class="outline-3">
<h3 id="orgd021d99">Desactivación del entorno virtual</h3>
<div class="outline-text-3" id="text-orgd021d99">
<p>
Una vez finalizado el trabajo, el entorno virtual puede desactivarse con el
siguiente comando:
</p>

<div class="org-src-container">
<pre class="src src-bash">deactivate
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgb9434b6" class="outline-2">
<h2 id="orgb9434b6">Manual de Entornos Virtuales en Python</h2>
<div class="outline-text-2" id="text-orgb9434b6">
</div>
<div id="outline-container-org092b5a8" class="outline-3">
<h3 id="org092b5a8">Introducción</h3>
<div class="outline-text-3" id="text-org092b5a8">
<p>
El uso de entornos virtuales es esencial para mantener las
dependencias de tus proyectos aisladas. En este manual aprenderás a
gestionarlos usando el módulo estándar <code>venv</code>.
</p>
</div>
</div>
<div id="outline-container-orgbcd7617" class="outline-3">
<h3 id="orgbcd7617">Flujo de Trabajo Básico</h3>
<div class="outline-text-3" id="text-orgbcd7617">
</div>
<div id="outline-container-orgcb07b0e" class="outline-4">
<h4 id="orgcb07b0e">1. Creación del entorno</h4>
<div class="outline-text-4" id="text-orgcb07b0e">
<p>
Para crear un entorno virtual, navega a la raíz de tu proyecto en la terminal (o dentro de un buffer de Emacs con <code>M-x shell</code>) y ejecuta:
</p>

<div class="org-src-container">
<pre class="src src-bash">python -m venv .venv
</pre>
</div>

<p>
<b>Nota:</b> El nombre <code>.venv</code> es una convención que hace que el directorio sea oculto en sistemas Unix.
</p>
</div>
</div>
<div id="outline-container-org398489d" class="outline-4">
<h4 id="org398489d">2. Activación</h4>
<div class="outline-text-4" id="text-org398489d">
<p>
La activación depende de tu sistema operativo:
</p>
</div>
<ul class="org-ul">
<li><a id="orgeecb394"></a>En Windows (PowerShell)<br />
<div class="outline-text-5" id="text-orgeecb394">
<div class="org-src-container">
<pre class="src src-powershell">.\.venv\Scripts\Activate.ps1
</pre>
</div>
</div>
</li>
<li><a id="org6544a3f"></a>En macOS / Linux<br />
<div class="outline-text-5" id="text-org6544a3f">
<div class="org-src-container">
<pre class="src src-bash"><span style="color: #fe8019;">source</span> .venv/bin/activate
</pre>
</div>
</div>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgc35a7c9" class="outline-3">
<h3 id="orgc35a7c9">Gestión de paquetes</h3>
<div class="outline-text-3" id="text-orgc35a7c9">
<p>
Una vez activado (verás el prefijo <code>(.venv)</code> en tu prompt), puedes instalar librerías:
</p>

<div class="org-src-container">
<pre class="src src-bash">pip install requests pandas
</pre>
</div>
</div>
</div>
<div id="outline-container-org45cf890" class="outline-3">
<h3 id="org45cf890">El archivo de Requerimientos</h3>
<div class="outline-text-3" id="text-org45cf890">
<p>
Es fundamental para la reproducibilidad del proyecto.
</p>
</div>
</div>
<div id="outline-container-orgb99af69" class="outline-3">
<h3 id="orgb99af69">Exportar dependencias</h3>
<div class="outline-text-3" id="text-orgb99af69">
<div class="org-src-container">
<pre class="src src-bash">pip freeze &gt; requirements.txt
</pre>
</div>
</div>
</div>
<div id="outline-container-org3cf9dbd" class="outline-3">
<h3 id="org3cf9dbd">Instalar desde el archivo</h3>
<div class="outline-text-3" id="text-org3cf9dbd">
<div class="org-src-container">
<pre class="src src-bash">pip install -r requirements.txt
</pre>
</div>
</div>
</div>
<div id="outline-container-orgff22999" class="outline-3">
<h3 id="orgff22999">Tips de Limpieza</h3>
<div class="outline-text-3" id="text-orgff22999">
<p>
Para salir del entorno virtual:
</p>
<div class="org-src-container">
<pre class="src src-bash">deactivate
</pre>
</div>

<p>
Para borrar el entorno, simplemente elimina la carpeta:
</p>
<div class="org-src-container">
<pre class="src src-bash">rm -rf .venv  <span style="color: #928374;"># </span><span style="color: #928374;">En Linux/macOS
</span>rmdir /s /q .venv  <span style="color: #928374;"># </span><span style="color: #928374;">En Windows</span>
</pre>
</div>

<p>
&#x2014;
</p>
<blockquote>
<p>
"Keep your global Python clean, keep your projects isolated."
</p>
</blockquote>
</div>
</div>
<div id="outline-container-org2c27276" class="outline-3">
<h3 id="org2c27276">Entornos Virtuales Python (Edición Windows)</h3>
</div>

<div id="outline-container-org94c90cf" class="outline-3">
<h3 id="org94c90cf">Requisitos Previos</h3>
<div class="outline-text-3" id="text-org94c90cf">
<ol class="org-ol">
<li>Tener instalado Python (descargado de <a href="https://www.python.org/">python.org</a> o la Microsoft Store).</li>
<li>Durante la instalación, asegúrate de marcar la casilla: <b><b>"Add Python to PATH"</b></b>.</li>
</ol>
</div>
</div>
<div id="outline-container-org971074d" class="outline-3">
<h3 id="org971074d">Flujo de Trabajo en Windows</h3>
<div class="outline-text-3" id="text-org971074d">
</div>
<div id="outline-container-org771f650" class="outline-4">
<h4 id="org771f650">1. Crear el Entorno Virtual</h4>
<div class="outline-text-4" id="text-org771f650">
<p>
Abre tu terminal (PowerShell o CMD) en la carpeta de tu proyecto. El comando es el mismo para ambos:
</p>

<div class="org-src-container">
<pre class="src src-powershell">python -m venv venv
</pre>
</div>
</div>
</div>
<div id="outline-container-org3611dd5" class="outline-4">
<h4 id="org3611dd5">2. El Paso Crítico: La Activación</h4>
<div class="outline-text-4" id="text-org3611dd5">
<p>
En Windows, la activación depende de qué terminal estés usando.
</p>
</div>
<ul class="org-ul">
<li><a id="org9cd46ff"></a>Opción A: PowerShell (Recomendado)<br />
<div class="outline-text-5" id="text-org9cd46ff">
<p>
Si es la primera vez que usas scripts en Windows, podrías recibir un error de seguridad. Primero, ejecuta esto como administrador (solo una vez):
</p>
<div class="org-src-container">
<pre class="src src-powershell">Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
</pre>
</div>

<p>
Luego, para activar el entorno:
</p>
<div class="org-src-container">
<pre class="src src-powershell">.\venv\Scripts\Activate.ps1
</pre>
</div>
</div>
</li>
<li><a id="orgde1b21a"></a>Opción B: Símbolo del Sistema (CMD)<br />
<div class="outline-text-5" id="text-orgde1b21a">
<div class="org-src-container">
<pre class="src src-cmd">.\venv\Scripts\activate.bat
</pre>
</div>
</div>
</li>
</ul>
</div>
<div id="outline-container-org9dbfaa8" class="outline-4">
<h4 id="org9dbfaa8">3. Confirmación</h4>
<div class="outline-text-4" id="text-org9dbfaa8">
<p>
Sabrás que el entorno está activo porque el nombre <code>(venv)</code> aparecerá a la izquierda de la ruta en tu terminal:
#+example
(venv) C:\Proyectos\MiProyecto&gt;
#+example
</p>
</div>
</div>
</div>
<div id="outline-container-org0eea39a" class="outline-3">
<h3 id="org0eea39a">Gestión de Librerías con PIP</h3>
<div class="outline-text-3" id="text-org0eea39a">
</div>
<div id="outline-container-org0d94cbd" class="outline-4">
<h4 id="org0d94cbd">Instalación de paquetes</h4>
<div class="outline-text-4" id="text-org0d94cbd">
<p>
Una vez activo el entorno, instala lo que necesites:
</p>
<div class="org-src-container">
<pre class="src src-powershell">pip install pandas requests openpyxl
</pre>
</div>
</div>
</div>
<div id="outline-container-org3058664" class="outline-4">
<h4 id="org3058664">Congelar dependencias (Compartir proyecto)</h4>
<div class="outline-text-4" id="text-org3058664">
<p>
Para que otros participantes tengan exactamente lo mismo que tú:
</p>
<div class="org-src-container">
<pre class="src src-powershell">pip freeze &gt; requirements.txt
</pre>
</div>
</div>
</div>
<div id="outline-container-orge002bc7" class="outline-4">
<h4 id="orge002bc7">Instalar desde un archivo recibido</h4>
<div class="outline-text-4" id="text-orge002bc7">
<p>
Si un compañero te pasa su <code>requirements.txt</code>:
</p>
<div class="org-src-container">
<pre class="src src-powershell">pip install -r requirements.txt
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgc247193" class="outline-3">
<h3 id="orgc247193">Uso de Entornos en Emacs (Windows)</h3>
<div class="outline-text-3" id="text-orgc247193">
<p>
Para que Emacs en Windows gestione bien el entorno, añade esto a tu archivo de configuración (<code>init.el</code> o <code>.emacs</code>):
</p>
</div>
<div id="outline-container-org21d9ae4" class="outline-4">
<h4 id="org21d9ae4">Instalación del paquete pyvenv</h4>
<div class="outline-text-4" id="text-org21d9ae4">
<div class="org-src-container">
<pre class="src src-elisp"><span style="color: #fe8019;">(</span><span style="color: #fb4934;">use-package</span> pyvenv
  <span style="color: #fe8019;">:ensure</span> t
  <span style="color: #fe8019;">:config</span>
  <span style="color: #b16286;">(</span>pyvenv-mode 1<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org99a2204" class="outline-4">
<h4 id="org99a2204">Cómo activarlo dentro de Emacs</h4>
<div class="outline-text-4" id="text-org99a2204">
<ol class="org-ol">
<li>Presiona <code>M-x pyvenv-activate</code>.</li>
<li>Emacs te pedirá la ruta. Navega hasta la carpeta <code>venv</code> de tu proyecto.</li>
<li>Al seleccionarla, Emacs usará ese intérprete de Python para todos los scripts que ejecutes.</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org1c24eed" class="outline-3">
<h3 id="org1c24eed">Solución de Problemas Comunes en Windows</h3>
<div class="outline-text-3" id="text-org1c24eed">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">Error / Problema</td>
<td class="org-left">Solución</td>
</tr>

<tr>
<td class="org-left">:---</td>
<td class="org-left">:---</td>
</tr>

<tr>
<td class="org-left">"python" no se reconoce</td>
<td class="org-left">Reinstala Python y marca "Add to PATH" o usa el comando `py`.</td>
</tr>

<tr>
<td class="org-left">Error de "Execution Policy"</td>
<td class="org-left">Ejecuta `Set-ExecutionPolicy RemoteSigned -Scope CurrentUser`.</td>
</tr>

<tr>
<td class="org-left">No aparece el (venv)</td>
<td class="org-left">Asegúrate de usar el comando de activación correcto para tu terminal (.ps1 vs .bat).</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-orgcb390bb" class="outline-3">
<h3 id="orgcb390bb">Desactivación y Limpieza</h3>
<div class="outline-text-3" id="text-orgcb390bb">
<p>
Para salir del entorno:
</p>
<div class="org-src-container">
<pre class="src src-powershell">deactivate
</pre>
</div>

<p>
Si quieres borrar el entorno por completo (para empezar de cero):
</p>
<div class="org-src-container">
<pre class="src src-powershell">rmdir /s /q venv
</pre>
</div>

<p>
&#x2014;
</p>
<div class="IMPORTANT" id="orge5d3fac">
<p>
<b>Recordatorio:</b> Nunca incluyas la carpeta <code>venv</code> en tus archivos compartidos o en tu repositorio de Git. Solo comparte el código y el archivo <code>requirements.txt</code>.
</p>

</div>
</div>
</div>
<div id="outline-container-org4298281" class="outline-3">
<h3 id="org4298281">Agregar a jupyter notebook</h3>
<div class="outline-text-3" id="text-org4298281">
<div class="org-src-container">
<pre class="src src-shell">pip install ipykernel
python -m ipykernel install --user --name=redes --display-name=<span style="color: #b8bb26;">"redes"</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgd85f4db" class="outline-2">
<h2 id="orgd85f4db">Introducción a la Inteligencia Artificial (IA)</h2>
<div class="outline-text-2" id="text-orgd85f4db">
</div>
<div id="outline-container-orgb4ff948" class="outline-3">
<h3 id="orgb4ff948">Definición formal</h3>
<div class="outline-text-3" id="text-orgb4ff948">
<p>
La <b>Inteligencia Artificial</b> es el área de la computación que estudia
  cómo construir sistemas capaces de realizar tareas que, si fueran
  realizadas por humanos, requerirían inteligencia.
</p>

<p>
Esto incluye capacidades como:
</p>

<ul class="org-ul">
<li>Aprender de la experiencia</li>
<li>Razonar</li>
<li>Reconocer patrones</li>
<li>Tomar decisiones bajo incertidumbre</li>
</ul>

<p>
La IA no implica necesariamente consciencia; se centra en <b>comportamiento inteligente observable</b>.
</p>
</div>
</div>
<div id="outline-container-orgedcf31d" class="outline-3">
<h3 id="orgedcf31d">IA débil vs IA fuerte</h3>
<div class="outline-text-3" id="text-orgedcf31d">
<ul class="org-ul">
<li><b>IA débil</b>: sistemas especializados en una tarea concreta (la IA actual)</li>
<li><b>IA fuerte</b>: inteligencia general comparable a la humana (teórica)</li>
</ul>

<p>
Las redes neuronales pertenecen claramente a la IA débil.
</p>
</div>
</div>
</div>
<div id="outline-container-org5e59c2b" class="outline-2">
<h2 id="org5e59c2b">Machine Learning (Aprendizaje Automático)</h2>
<div class="outline-text-2" id="text-org5e59c2b">
<p>
<b>* Relación entre IA y ML
El *Machine Learning (ML)</b> es una subdisciplina de la IA. Mientras la IA es el objetivo general, el ML es una de las herramientas principales para alcanzarlo.
</p>

<p>
Idea clave:
</p>
<blockquote>
<p>
En lugar de programar reglas, el sistema aprende las reglas a partir de datos.
</p>
</blockquote>
</div>
<div id="outline-container-org7a9789c" class="outline-3">
<h3 id="org7a9789c">Tipos de aprendizaje</h3>
<div class="outline-text-3" id="text-org7a9789c">
<ul class="org-ul">
<li><b>Supervisado</b>: datos con etiqueta (clasificación, regresión)</li>
<li><b>No supervisado</b>: datos sin etiqueta (clustering, reducción de dimensión)</li>
<li><b>Por refuerzo</b>: aprendizaje mediante recompensa y castigo</li>
</ul>

<p>
Las redes neuronales pueden adaptarse a los tres esquemas.
</p>
</div>
</div>
</div>
<div id="outline-container-org4a4ec43" class="outline-2">
<h2 id="org4a4ec43">Historia de las Redes Neuronales</h2>
<div class="outline-text-2" id="text-org4a4ec43">
</div>
<div id="outline-container-org7e09907" class="outline-3">
<h3 id="org7e09907">Contexto histórico</h3>
<div class="outline-text-3" id="text-org7e09907">
<p>
Desde mediados del siglo XX, científicos han intentado entender si la inteligencia podía ser replicada mediante modelos matemáticos.
</p>
</div>
</div>
<div id="outline-container-org33e377e" class="outline-3">
<h3 id="org33e377e">McCulloch y Pitts (1943)</h3>
<div class="outline-text-3" id="text-org33e377e">
<p>
Propusieron la primera neurona artificial basada en lógica
booleana. Demostraron que redes de estas neuronas podían computar
cualquier función lógica.
</p>

<p>
Este trabajo sentó las bases teóricas de las redes neuronales.
</p>
</div>
</div>
<div id="outline-container-org845a403" class="outline-3">
<h3 id="org845a403">Perceptrón y optimismo inicial</h3>
<div class="outline-text-3" id="text-org845a403">
<p>
En los años 50 y 60, el perceptrón generó grandes expectativas al ser uno de los primeros sistemas que <b>aprendía</b> automáticamente.
</p>
</div>
</div>
<div id="outline-container-org3accf4b" class="outline-3">
<h3 id="org3accf4b">Críticas y estancamiento</h3>
<div class="outline-text-3" id="text-org3accf4b">
<p>
El libro <b>Perceptrons</b> (Minsky &amp; Papert, 1969) demostró limitaciones severas del perceptrón, provocando una fuerte caída en el interés por las redes neuronales.
</p>
</div>
</div>
<div id="outline-container-org5174a36" class="outline-3">
<h3 id="org5174a36">Renacimiento moderno</h3>
<div class="outline-text-3" id="text-org5174a36">
<p>
Con mayor poder computacional, grandes bases de datos y mejores algoritmos, las redes neuronales resurgen como <b>Deep Learning</b>.
</p>
</div>
</div>
</div>
<div id="outline-container-org3f4c21f" class="outline-2">
<h2 id="org3f4c21f">La Neurona Artificial</h2>
<div class="outline-text-2" id="text-org3f4c21f">
</div>
<div id="outline-container-org328d269" class="outline-3">
<h3 id="org328d269">Motivación</h3>
<div class="outline-text-3" id="text-org328d269">
<p>
Una red neuronal artificial es un modelo matemático inspirado en la
organización y conectividad de las neuronas biológicas, que abstrae
su funcionamiento esencial para construir sistemas capaces de
aprender representaciones a partir de datos mediante el ajuste de
parámetros.
</p>
</div>
</div>
<div id="outline-container-orgcccfb62" class="outline-3">
<h3 id="orgcccfb62">Componentes</h3>
<div class="outline-text-3" id="text-orgcccfb62">
<ul class="org-ul">
<li>Entradas: variables numéricas</li>
<li>Pesos: importancia relativa de cada entrada</li>
<li>Bias: ajuste del umbral</li>
<li>Activación: decisión final</li>
</ul>
</div>
</div>
<div id="outline-container-org50dd34a" class="outline-3">
<h3 id="org50dd34a">Modelo matemático</h3>
<div class="outline-text-3" id="text-org50dd34a">
<div class="org-src-container">
<pre class="src src-text">z = w&#183;x + b
a = f(z)
</pre>
</div>

<p>
Este modelo es la unidad básica de todas las redes neuronales modernas.
</p>
</div>
</div>
</div>
<div id="outline-container-org77dacbf" class="outline-2">
<h2 id="org77dacbf">El Perceptrón</h2>
<div class="outline-text-2" id="text-org77dacbf">
</div>
<div id="outline-container-org6dc974d" class="outline-3">
<h3 id="org6dc974d">Definición</h3>
<div class="outline-text-3" id="text-org6dc974d">
<p>
El perceptrón es una neurona artificial entrenable utilizada para clasificación binaria.
</p>
</div>
</div>
<div id="outline-container-org44904dd" class="outline-3">
<h3 id="org44904dd">Interpretación geométrica</h3>
<div class="outline-text-3" id="text-org44904dd">
<p>
El perceptrón aprende una <b>frontera de decisión lineal</b> que separa los datos en dos clases.
</p>
</div>
</div>
<div id="outline-container-org8480890" class="outline-3">
<h3 id="org8480890">Aprendizaje</h3>
<div class="outline-text-3" id="text-org8480890">
<p>
Cuando el perceptrón se equivoca, ajusta sus pesos para reducir el error.
</p>
</div>
</div>
<div id="outline-container-orgb84ee2e" class="outline-3">
<h3 id="orgb84ee2e">Limitaciones</h3>
<div class="outline-text-3" id="text-orgb84ee2e">
<p>
No puede aprender relaciones no lineales, como XOR.
</p>
</div>
</div>
</div>
<div id="outline-container-orgf2e0ee0" class="outline-2">
<h2 id="orgf2e0ee0">¿Qué es un problema linealmente separable?</h2>
<div class="outline-text-2" id="text-orgf2e0ee0">
</div>
<div id="outline-container-orgf0ec79b" class="outline-3">
<h3 id="orgf0ec79b">Intuición básica</h3>
<div class="outline-text-3" id="text-orgf0ec79b">
<p>
Un problema es linealmente separable si puedes separar las clases usando una línea recta (en 2D),
un plano (en 3D), o en general un hiperplano.
Si existe una sola frontera recta que divide perfectamente las clases, el problema es linealmente separable.
</p>
</div>
</div>
</div>
<div id="outline-container-org0b79708" class="outline-2">
<h2 id="org0b79708">Estructura de un Perceptrón Simple</h2>
<div class="outline-text-2" id="text-org0b79708">
</div>
<div id="outline-container-org1aef6fa" class="outline-3">
<h3 id="org1aef6fa">Entradas (Inputs)</h3>
<div class="outline-text-3" id="text-org1aef6fa">
<ul class="org-ul">
<li>Representadas como \(x_1, x_2, ..., x_n\).</li>
<li>Son los datos brutos o características que recibe el modelo.</li>
</ul>
</div>
</div>
<div id="outline-container-org664d7b1" class="outline-3">
<h3 id="org664d7b1">Pesos Sinápticos (Weights)</h3>
<div class="outline-text-3" id="text-org664d7b1">
<ul class="org-ul">
<li>Representados como \(w_1, w_2, ..., w_n\).</li>
<li>Determinan la importancia o influencia de cada entrada en el resultado final.</li>
</ul>
</div>
</div>
<div id="outline-container-orgf9d3f22" class="outline-3">
<h3 id="orgf9d3f22">Suma Ponderada (Weighted Sum)</h3>
<div class="outline-text-3" id="text-orgf9d3f22">
<ul class="org-ul">
<li>Es la combinación lineal de las entradas y los pesos.</li>
<li>La fórmula matemática es:
\[z = \sum_{i=1}^{n} w_i x_i + b\]</li>
</ul>
</div>
</div>
<div id="outline-container-org1e26ea7" class="outline-3">
<h3 id="org1e26ea7">Sesgo (Bias)</h3>
<div class="outline-text-3" id="text-org1e26ea7">
<ul class="org-ul">
<li>Representado generalmente como \(b\) (o \(w_0\)).</li>
<li>Permite desplazar la función de activación hacia la izquierda o derecha para ajustar mejor los datos.</li>
</ul>
</div>
</div>
<div id="outline-container-org78e4b3c" class="outline-3">
<h3 id="org78e4b3c">Función de Activación</h3>
<div class="outline-text-3" id="text-org78e4b3c">
<ul class="org-ul">
<li>Decide si la neurona debe "dispararse" (activarse) o no.</li>
<li>En el perceptrón original de Rosenblatt, se utiliza la <b>Función Escalón</b> (Heaviside):
<ul class="org-ul">
<li>\(f(z) = 1\) si \(z > 0\)</li>
<li>\(f(z) = 0\) en caso contrario.</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org10ecb66" class="outline-3">
<h3 id="org10ecb66">Salida (Output)</h3>
<div class="outline-text-3" id="text-org10ecb66">
<ul class="org-ul">
<li>Es el resultado final del procesamiento (\(\hat{y}\)).</li>
<li>En un perceptrón simple, suele ser un valor binario (0 o 1).</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org283328d" class="outline-2">
<h2 id="org283328d">Ejemplo Tacos</h2>
<div class="outline-text-2" id="text-org283328d">
</div>
<div id="outline-container-org9fb64bf" class="outline-3">
<h3 id="org9fb64bf">1. El Escenario: La Decisión de la Cena</h3>
<div class="outline-text-3" id="text-org9fb64bf">
<p>
Para entender cómo aprende una IA, vamos a usar un ejemplo de la vida real. Queremos que nuestra neurona artificial aprenda cuándo estamos "Satisfechos" (1) o "Inconformes" (0).
</p>
</div>
<div id="outline-container-orgfc964f4" class="outline-4">
<h4 id="orgfc964f4">Nuestras Entradas (Inputs)</h4>
<div class="outline-text-4" id="text-orgfc964f4">
<ul class="org-ul">
<li>\(x_0\): ¿Hay Tacos? (1 = Sí, 0 = No)</li>
<li>\(x_1\): ¿Hay Refresco? (1 = Sí, 0 = No)</li>
</ul>
</div>
</div>
<div id="outline-container-org71fa55b" class="outline-4">
<h4 id="org71fa55b">El Peso (Weight): La Importancia</h4>
<div class="outline-text-4" id="text-org71fa55b">
<p>
No todo nos hace igual de felices. Los <b><b>Pesos</b></b> (\(w_0, w_1\)) representan qué tanto nos importa cada ingrediente. 
</p>
<ul class="org-ul">
<li>Si el peso del taco es alto, el taco es fundamental para nuestra felicidad.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9d90d0f" class="outline-3">
<h3 id="org9d90d0f">2. ¿Cómo toma la decisión? (La Suma y el Sesgo)</h3>
<div class="outline-text-3" id="text-org9d90d0f">
<p>
La neurona hace un cálculo matemático simple:
\[net = (x_0 \cdot w_0) + (x_1 \cdot w_1) - \text{bias}\]
</p>
</div>
<div id="outline-container-orge748a72" class="outline-4">
<h4 id="orge748a72">El Sesgo (Bias)</h4>
<div class="outline-text-4" id="text-orge748a72">
<p>
El <b><b>Bias</b></b> es nuestro "nivel de exigencia". Si el Bias es muy alto, necesitaremos mucha comida (pesos altos) para poder llegar a estar satisfechos.
</p>
</div>
</div>
</div>
<div id="outline-container-org56cecce" class="outline-3">
<h3 id="org56cecce">3. El Descenso del Gradiente: ¿Cómo "Aprende" la Neurona?</h3>
<div class="outline-text-3" id="text-org56cecce">
<p>
Cuando la neurona se equivoca, necesita ajustar sus pesos. Este proceso se llama <b><b>Descenso del Gradiente</b></b>.
</p>
</div>
<div id="outline-container-orgf5167ce" class="outline-4">
<h4 id="orgf5167ce">El Error: La Brújula</h4>
<div class="outline-text-4" id="text-orgf5167ce">
<p>
Si esperábamos estar felices (<code>target = 1</code>) pero la neurona dice que estamos tristes (<code>net = 0</code>), tenemos un <b><b>Error de 1</b></b>.
\[Error = Target - Net\]
</p>
</div>
</div>
<div id="outline-container-org02111c9" class="outline-4">
<h4 id="org02111c9">El Ajuste (La Regla Delta)</h4>
<div class="outline-text-4" id="text-org02111c9">
<p>
Para corregir el error, cambiamos los pesos usando esta lógica:
</p>
<ol class="org-ol">
<li>Miramos el <b><b>Error</b></b>.</li>
<li>Miramos la <b><b>Entrada</b></b> (¿Quién tuvo la culpa? Si no había tacos, el taco no pudo causar el error).</li>
<li>Aplicamos el <b><b>Learning Rate (K)</b></b>: Que es qué tan rápido queremos aprender.</li>
</ol>

<p>
\[Nuevo\_Peso = Peso\_Actual + (K \cdot Error \cdot Entrada)\]
</p>


<p>
Imagina que \(K = 0.1\) y el Peso inicial del taco es \(0.5\).
</p>
<ol class="org-ol">
<li><b><b>Situación:</b></b> Hay tacos (\(x_0=1\)), pero la red dice "Triste" (\(net=0\)). Nosotros queríamos "Feliz" (\(target=1\)).</li>
<li><b><b>Cálculo del Error:</b></b> \(1 - 0 = 1\).</li>
<li><b><b>Ajuste del Peso:</b></b>
<ul class="org-ul">
<li>\(Delta = 0.1 \cdot 1 \cdot 1 = 0.1\)</li>
<li>\(Nuevo\_Peso\_Taco = 0.5 + 0.1 = 0.6\)</li>
</ul></li>
</ol>

<p>
<b><b>Resultado:</b></b> La próxima vez que haya tacos, la neurona estará un poco más cerca de hacernos felices. ¡Eso es el aprendizaje!
</p>

<p>
Puntos importantes
</p>

<ul class="org-ul">
<li>El <b><b>Gradiente</b></b> nos dice en qué dirección mover los pesos para que el error sea cero.</li>
<li>El <b><b>Learning Rate</b></b> controla qué tan grandes son los pasos que damos hacia esa solución.</li>
<li>Si repetimos este proceso miles de veces (Épocas), la neurona encontrará los pesos perfectos para nuestra felicidad.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9bf12b5" class="outline-3">
<h3 id="org9bf12b5">Perceptrón ejemplo (Python)</h3>
<div class="outline-text-3" id="text-org9bf12b5">
<ol class="org-ol">
<li>Recibe entradas (\(x_1, x_2, \dots\)).</li>
<li>Las multiplica por pesos (\(w_1, w_2, \dots\)).</li>
<li>Suma un sesgo (\(b\)).</li>
<li>Aplica una función de activación (ej. Escalón).</li>
</ol>
</div>
<div id="outline-container-orgb76a05f" class="outline-4">
<h4 id="orgb76a05f">Perceptrón para una compuerta "AND"</h4>
<div class="outline-text-4" id="text-orgb76a05f">
<p>
Este código simula una neurona que solo se activa si ambas entradas son 1.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">perceptron_and</span><span style="color: #fe8019;">(</span>x1, x2<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">1. Definimos los Pesos y el Sesgo (Bias)
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Estos valores normalmente se aprenden, aqu&#237; los asignamos manualmente
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">w1</span>, <span style="color: #83a598;">w2</span> = 0.5, 0.5
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">bias</span> = -0.7

<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">2. Suma ponderada: (x1 * w1) + (x2 * w2) + bias
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">suma</span> = <span style="color: #fe8019;">(</span>x1 * w1<span style="color: #fe8019;">)</span> + <span style="color: #fe8019;">(</span>x2 * w2<span style="color: #fe8019;">)</span> + bias

<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">3. Funci&#243;n de activaci&#243;n (Escal&#243;n de Heaviside)
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Si la suma es mayor a 0, la neurona se dispara (1)
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> suma &gt; 0:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> 1
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">else</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> 0

<span style="color: #928374;"># </span><span style="color: #928374;">Prueba de la tabla de verdad AND
</span><span style="color: #83a598;">entradas</span> = <span style="color: #fe8019;">[</span><span style="color: #b16286;">(</span>0, 0<span style="color: #b16286;">)</span>, <span style="color: #b16286;">(</span>0, 1<span style="color: #b16286;">)</span>, <span style="color: #b16286;">(</span>1, 0<span style="color: #b16286;">)</span>, <span style="color: #b16286;">(</span>1, 1<span style="color: #b16286;">)</span><span style="color: #fe8019;">]</span>

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Entrada | Salida"</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"--------|-------"</span><span style="color: #fe8019;">)</span>
<span style="color: #fb4934;">for</span> e <span style="color: #fb4934;">in</span> entradas:
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">resultado</span> = perceptron_and<span style="color: #fe8019;">(</span>e<span style="color: #b16286;">[</span>0<span style="color: #b16286;">]</span>, e<span style="color: #b16286;">[</span>1<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">" </span>{e}<span style="color: #b8bb26;">  |   </span>{resultado}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-org9a53982" class="outline-2">
<h2 id="org9a53982">Codigo C python</h2>
<div class="outline-text-2" id="text-org9a53982">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> math
<span style="color: #fb4934;">import</span> random

<span style="color: #83a598;">EPOCAS</span> = 300000
<span style="color: #83a598;">K</span> = 0.03  <span style="color: #928374;"># </span><span style="color: #928374;">tasa de aprendizaje
</span>
<span style="color: #928374;"># </span><span style="color: #928374;">Pesos y bias globales (como en el c&#243;digo C)
</span><span style="color: #83a598;">Pesos</span> = <span style="color: #fe8019;">[</span>0.0, 0.0<span style="color: #fe8019;">]</span>
<span style="color: #83a598;">bias</span> = 0.5
<span style="color: #83a598;">Error</span> = 0.0


<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">sigmoide</span><span style="color: #fe8019;">(</span>s: <span style="color: #fe8019;">float</span><span style="color: #fe8019;">)</span> -&gt; <span style="color: #fe8019;">float</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Versi&#243;n correcta de la sigmoide log&#237;stica:
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">1 / (1 + e^{-s})
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> 1.0 / <span style="color: #fe8019;">(</span>1.0 + math.exp<span style="color: #b16286;">(</span>-s<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>


<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">pesos_initNt</span><span style="color: #fe8019;">()</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""Inicializa los pesos de forma aleatoria en [0,1)."""</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">global</span> Pesos
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">Pesos</span> = <span style="color: #fe8019;">[</span>random.random<span style="color: #b16286;">()</span> <span style="color: #fb4934;">for</span> _ <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">range</span><span style="color: #b16286;">(</span>2<span style="color: #b16286;">)</span><span style="color: #fe8019;">]</span>


<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">EntNt</span><span style="color: #fe8019;">(</span>x0: <span style="color: #fe8019;">float</span>, x1: <span style="color: #fe8019;">float</span>, target: <span style="color: #fe8019;">float</span><span style="color: #fe8019;">)</span> -&gt; <span style="color: #fe8019;">float</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Funci&#243;n de entrenamiento del perceptr&#243;n (una iteraci&#243;n para un patr&#243;n).
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Modifica Pesos y bias de forma global.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">global</span> Pesos, bias, Error

<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">net = w0*x0 + w1*x1 - bias
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">net</span> = Pesos<span style="color: #fe8019;">[</span>0<span style="color: #fe8019;">]</span> * x0 + Pesos<span style="color: #fe8019;">[</span>1<span style="color: #fe8019;">]</span> * x1 - bias
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">net</span> = sigmoide<span style="color: #fe8019;">(</span>net<span style="color: #fe8019;">)</span>

<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">Error</span> = target - net

<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Actualizaci&#243;n de bias (se asume entrada de bias = 1)
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">bias</span> -= K * Error

<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Variaci&#243;n de los pesos sin&#225;pticos
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">delta0</span> = K * Error * x0
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">delta1</span> = K * Error * x1

<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Ajuste de pesos
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">Pesos</span><span style="color: #fe8019;">[</span>0<span style="color: #fe8019;">]</span> += delta0
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">Pesos</span><span style="color: #fe8019;">[</span>1<span style="color: #fe8019;">]</span> += delta1

<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> net


<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">InitNt</span><span style="color: #fe8019;">(</span>x0: <span style="color: #fe8019;">float</span>, x1: <span style="color: #fe8019;">float</span><span style="color: #fe8019;">)</span> -&gt; <span style="color: #fe8019;">float</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Funci&#243;n que usa pesos fijos (de ejemplo) para calcular la salida.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Equivalente a la parte comentada en C.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">net = 70.934807*x0 + 93.935219*x1 - 187.886169;
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">net</span> = 70.934807 * x0 + 93.935219 * x1 - 187.886169
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">net</span> = sigmoide<span style="color: #fe8019;">(</span>net<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> net


<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">main</span><span style="color: #fe8019;">()</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">global</span> Pesos, bias, Error

<span style="background-color: #3c3836;"> </span>   pesos_initNt<span style="color: #fe8019;">()</span>

<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> i <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">range</span><span style="color: #fe8019;">(</span>EPOCAS<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"------------------------"</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Salida Entrenamiento Epoca </span>{i}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>

<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">apr</span> = EntNt<span style="color: #fe8019;">(</span>1, 1, 0<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"1,1 = </span>{apr:.6f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>

<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">apr</span> = EntNt<span style="color: #fe8019;">(</span>1, 0, 1<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"1,0 = </span>{apr:.6f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>

<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">apr</span> = EntNt<span style="color: #fe8019;">(</span>0, 1, 1<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"0,1 = </span>{apr:.6f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>

<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">apr</span> = EntNt<span style="color: #fe8019;">(</span>0, 0, 0<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"0,0 = </span>{apr:.6f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>

<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">Pesos de cada epoca"</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Peso 0 = </span>{Pesos[0]:.6f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Peso 1 = </span>{Pesos[1]:.6f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Bias   = </span>{bias:.6f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Error  = </span>{Error:.6f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"------------------------"</span><span style="color: #fe8019;">)</span>

<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Si quieres probar con los pesos fijos del comentario de C:
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">print("Resultados con InitNt:")
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">print("1,1 =", InitNt(1, 1))
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">print("1,0 =", InitNt(1, 0))
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">print("0,1 =", InitNt(0, 1))
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">print("0,0 =", InitNt(0, 0))
</span>

<span style="color: #fb4934;">if</span> <span style="color: #fe8019;">__name__</span> == <span style="color: #b8bb26;">"__main__"</span>:
<span style="background-color: #3c3836;"> </span>   main<span style="color: #fe8019;">()</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org25cc032" class="outline-2">
<h2 id="org25cc032">Redes Neuronales Multicapa (Multilayer Perceptron)</h2>
<div class="outline-text-2" id="text-org25cc032">
</div>
<div id="outline-container-orgbd138a4" class="outline-3">
<h3 id="orgbd138a4">Introducción</h3>
<div class="outline-text-3" id="text-orgbd138a4">
<p>
Una <b>red neuronal multicapa</b> o <b>Perceptrón Multicapa (MLP)</b> es un modelo
de aprendizaje supervisado que extiende al perceptrón simple mediante
la inclusión de <b>una o más capas ocultas</b>. Estas capas permiten modelar
<b>relaciones no lineales complejas</b> entre las variables de entrada y la salida.
</p>

<p>
Los MLP constituyen la base conceptual del <b>Deep Learning</b> moderno:
</p>

<ul class="org-ul">
<li>El perceptrón simple solo puede resolver problemas <b>linealmente separables</b>.</li>
<li>Muchos problemas reales (visión, texto, señales) son <b>no lineales</b>.</li>
<li>Agregar capas ocultas + funciones de activación no lineales permite
aproximar funciones mucho más complejas (teorema del aproximador universal).</li>
</ul>

<p>
Ejemplos clásicos (con 2 entradas):
</p>

<ul class="org-ul">
<li>AND  → ✓ separable linealmente</li>
<li>OR   → ✓ separable linealmente</li>
<li>XOR  → ✗ <b>no</b> es separable linealmente</li>
</ul>

<p>
El problema XOR demuestra la necesidad de introducir:
</p>

<ul class="org-ul">
<li><b>Capas ocultas</b> (capacidad de representar interacciones no triviales),</li>
<li><b>Funciones de activación no lineales</b>.</li>
</ul>

<p>
Un MLP típico está compuesto por:
</p>

<ol class="org-ol">
<li><b>Capa de entrada</b>  
Recibe el vector de características \(\mathbf{x}\).</li>

<li><b>Capas ocultas</b>  
Realizan transformaciones lineales + no lineales sobre las
representaciones intermedias.</li>

<li><b>Capa de salida</b>  
Produce la predicción final (clase, probabilidad, valor continuo, etc.).</li>
</ol>

<p>
Estructura conceptual:
</p>

<pre class="example" id="orgcafe8ed">
x → Capa Oculta 1 → Capa Oculta 2 → … → Capa de salida → ŷ
</pre>

<p>
Cada “flecha” representa una transformación lineal (multiplicación por
matriz de pesos + suma de bias) seguida de una función de activación.
</p>
</div>
</div>
<div id="outline-container-org0ff6595" class="outline-3">
<h3 id="org0ff6595">Modelo matemático</h3>
<div class="outline-text-3" id="text-org0ff6595">
</div>
<div id="outline-container-org19f75a2" class="outline-4">
<h4 id="org19f75a2">Neurona individual</h4>
<div class="outline-text-4" id="text-org19f75a2">
<p>
Cada neurona recibe un vector de entrada \(\mathbf{x} \in \mathbb{R}^n\) y calcula:
</p>

<p>
\[
z = \sum_{i=1}^{n} w_i x_i + b
\]
</p>

<p>
\[
a = f(z)
\]
</p>

<p>
Donde:
</p>

<ul class="org-ul">
<li>\(w_i\): pesos sinápticos de la neurona,</li>
<li>\(b\): término de sesgo (bias),</li>
<li>\(f(\cdot)\): función de activación,</li>
<li>\(z\): combinación lineal de las entradas,</li>
<li>\(a\): salida (activación) de la neurona.</li>
</ul>

<p>
En forma vectorial para una neurona:
</p>

<p>
\[
z = \mathbf{w}^\top \mathbf{x} + b
\]
</p>

<p>
\[
a = f(z)
\]
</p>
</div>
</div>
<div id="outline-container-orgc3a2f26" class="outline-4">
<h4 id="orgc3a2f26">Forma matricial de una capa</h4>
<div class="outline-text-4" id="text-orgc3a2f26">
<p>
En una capa con múltiples neuronas, se usa notación matricial:
</p>

<ul class="org-ul">
<li>\(\mathbf{a}^{(l-1)}\): vector de activaciones de la capa anterior,</li>
<li>\(\mathbf{W}^{(l)}\): matriz de pesos de la capa \(l\),</li>
<li>\(\mathbf{b}^{(l)}\): vector de bias de la capa \(l\),</li>
<li>\(\mathbf{z}^{(l)}\): preactivaciones de la capa \(l\),</li>
<li>\(\mathbf{a}^{(l)}\): activaciones de la capa \(l\).</li>
</ul>

<p>
Cálculo:
</p>

<p>
\[
\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}
\]
</p>

<p>
\[
\mathbf{a}^{(l)} = f(\mathbf{z}^{(l)})
\]
</p>

<p>
donde \(f\) se aplica componente a componente.
</p>

<p>
Repitiendo este proceso desde la capa de entrada hasta la salida,
obtenemos la predicción del MLP.
</p>
</div>
</div>
</div>
<div id="outline-container-orgf3554df" class="outline-3">
<h3 id="orgf3554df">Funciones de activación</h3>
<div class="outline-text-3" id="text-orgf3554df">
<p>
Las funciones de activación son componentes fundamentales en las redes
neuronales multicapa. Su función principal es introducir <b>no linealidad</b>
en el modelo.
</p>

<p>
Sin funciones de activación no lineales:
</p>

<ul class="org-ul">
<li>cada capa sería solo una transformación lineal,</li>
<li>y la composición de múltiples transformaciones lineales es <b>otra</b>
transformación lineal,</li>
<li>por lo tanto, una “red profunda” sin no linealidad se comporta como
un <b>modelo lineal simple</b>, independientemente del número de capas.</li>
</ul>
</div>
<div id="outline-container-orgdd6fd9d" class="outline-4">
<h4 id="orgdd6fd9d">¿Para qué sirven las funciones de activación?</h4>
<div class="outline-text-4" id="text-orgdd6fd9d">
<p>
Las funciones de activación permiten:
</p>

<ul class="org-ul">
<li>Introducir <b>no linealidad</b> en la red.</li>
<li>Modelar relaciones complejas entre variables de entrada y salida.</li>
<li>Aprender fronteras de decisión no lineales en problemas de clasificación.</li>
<li>Aproximar cualquier función continua bajo ciertas condiciones
(teorema del aproximador universal).</li>
</ul>

<p>
Recordemos que una neurona realiza:
</p>

<p>
\[
z = \sum_{i=1}^{n} w_i x_i + b
\]
</p>

<p>
\[
a = f(z)
\]
</p>

<p>
Donde \(f\) es la función de activación.
</p>
</div>
</div>
</div>
<div id="outline-container-org0f05bba" class="outline-3">
<h3 id="org0f05bba">Clasificación de las funciones de activación</h3>
<div class="outline-text-3" id="text-org0f05bba">
<p>
Las funciones de activación pueden clasificarse según:
</p>

<ul class="org-ul">
<li>su forma (escalón, sigmoide, lineal por partes, etc.),</li>
<li>su rango de salida,</li>
<li>su uso (capas ocultas vs capa de salida),</li>
<li>su comportamiento para valores grandes de \(|z|\).</li>
</ul>
</div>
<div id="outline-container-org78d849d" class="outline-4">
<h4 id="org78d849d">Funciones de activación clásicas</h4>
<div class="outline-text-4" id="text-org78d849d">
</div>
<ul class="org-ul">
<li><a id="org5d106b3"></a>Función escalón (Step Function)<br />
<div class="outline-text-5" id="text-org5d106b3">
<p>
\[
f(z) =
</p>
\begin{cases}
1 & \text{si } z \ge 0 \\
0 & \text{si } z < 0
\end{cases}
<p>
\]
</p>

<p>
Características:
</p>

<ul class="org-ul">
<li>Usada en el perceptrón simple original.</li>
<li>No es continua ni derivable (no adecuada para descenso de gradiente).</li>
<li>Genera salidas binarias (0/1).</li>
</ul>

<p>
Uso:
</p>

<ul class="org-ul">
<li>Modelos teóricos e históricos.</li>
<li>Introducción al concepto de neurona como “disparar / no disparar”.</li>
<li>No se utiliza en redes multicapa modernas para entrenamiento con
backpropagation.</li>
</ul>
</div>
</li>
<li><a id="org096a41e"></a>Sigmoide logística<br />
<div class="outline-text-5" id="text-org096a41e">
<p>
\[
f(z) = \frac{1}{1 + e^{-z}}
\]
</p>

<p>
Características:
</p>

<ul class="org-ul">
<li>Salida en el intervalo \((0, 1)\).</li>
<li>Puede interpretarse como una probabilidad.</li>
<li>Es suave y derivable en todo \(\mathbb{R}\).</li>
</ul>

<p>
Ventajas:
</p>

<ul class="org-ul">
<li>Interpretación probabilística directa.</li>
<li>Históricamente muy usada en redes neuronales tempranas.</li>
</ul>

<p>
Desventajas:
</p>

<ul class="org-ul">
<li>Para \(|z|\) grandes, la función se <b>satura</b> cerca de 0 o 1:
<ul class="org-ul">
<li>la derivada es muy pequeña,</li>
<li>aparece el problema de <b>vanishing gradient</b>,</li>
<li>el entrenamiento de redes profundas se vuelve lento o ineficaz.</li>
</ul></li>
</ul>

<p>
Uso típico actual:
</p>

<ul class="org-ul">
<li>Capa de salida en algunos modelos de clasificación binaria (aunque
en deep learning moderno también se usan otras combinaciones).</li>
</ul>
</div>
</li>
<li><a id="orgda67b4c"></a>Tangente hiperbólica (tanh)<br />
<div class="outline-text-5" id="text-orgda67b4c">
<p>
\[
f(z) = \tanh(z)
\]
</p>

<p>
Características:
</p>

<ul class="org-ul">
<li>Salida en el intervalo \((-1, 1)\).</li>
<li>Es simétrica alrededor de 0 (centrada en cero).</li>
</ul>

<p>
Ventajas:
</p>

<ul class="org-ul">
<li>En comparación con la sigmoide logística, su salida centrada en cero:
<ul class="org-ul">
<li>puede favorecer una convergencia algo más rápida,</li>
<li>reduce ciertos sesgos en las activaciones.</li>
</ul></li>
</ul>

<p>
Desventajas:
</p>

<ul class="org-ul">
<li>También se satura para \(|z|\) grandes.</li>
<li>Sigue presentando <b>vanishing gradient</b> en redes muy profundas.</li>
</ul>

<p>
Uso clásico:
</p>

<ul class="org-ul">
<li>Capas ocultas en redes no demasiado profundas, antes de la adopción
masiva de ReLU.</li>
</ul>
</div>
</li>
</ul>
</div>
<div id="outline-container-org95ec858" class="outline-4">
<h4 id="org95ec858">Funciones de activación modernas</h4>
<div class="outline-text-4" id="text-org95ec858">
</div>
<ul class="org-ul">
<li><a id="orge271203"></a>ReLU (Rectified Linear Unit)<br />
<div class="outline-text-5" id="text-orge271203">
<p>
\[
f(z) = \max(0, z)
\]
</p>

<p>
Características:
</p>

<ul class="org-ul">
<li>Función lineal por partes:
<ul class="org-ul">
<li>para \(z < 0\): salida 0,</li>
<li>para \(z \ge 0\): salida \(z\).</li>
</ul></li>
<li>Muy sencilla y eficiente de calcular.</li>
</ul>

<p>
Ventajas:
</p>

<ul class="org-ul">
<li>No se satura para valores positivos grandes (derivada constante 1).</li>
<li>Reduce considerablemente el problema del <b>vanishing gradient</b>.</li>
<li>Ha permitido entrenar redes profundas con muchas capas.</li>
</ul>

<p>
Desventajas:
</p>

<ul class="org-ul">
<li><b>Dead neurons</b>: si una neurona recibe valores de \(z\) siempre
negativos, su salida es siempre 0 y el gradiente puede quedar en 0
→ deja de aprender.</li>
</ul>

<p>
Uso típico:
</p>

<ul class="org-ul">
<li>Función estándar en <b>capas ocultas</b> de MLP y CNN modernos.</li>
</ul>
</div>
</li>
<li><a id="orge9dfa53"></a>Leaky ReLU<br />
<div class="outline-text-5" id="text-orge9dfa53">
<p>
\[
f(z) =
</p>
\begin{cases}
z & \text{si } z \ge 0 \\
\alpha z & \text{si } z < 0
\end{cases}
<p>
\]
</p>

<p>
donde \(\alpha\) es un pequeño número positivo (por ejemplo, 0.01).
</p>

<p>
Características:
</p>

<ul class="org-ul">
<li>Variante de ReLU que, en lugar de “apagar” totalmente la neurona para
\(z < 0\), permite un pequeño gradiente negativo.</li>
</ul>

<p>
Ventajas:
</p>

<ul class="org-ul">
<li>Reduce el problema de neuronas muertas (<b>dead ReLU</b>).</li>
<li>Mantiene muchas ventajas de ReLU.</li>
</ul>

<p>
Uso típico:
</p>

<ul class="org-ul">
<li>Alternativa a ReLU cuando se observa que muchas neuronas quedan
inactivas de manera permanente.</li>
</ul>
</div>
</li>
<li><a id="org30c2ba0"></a>ELU (Exponential Linear Unit)<br />
<div class="outline-text-5" id="text-org30c2ba0">
<p>
\[
f(z) =
</p>
\begin{cases}
z & \text{si } z \ge 0 \\
\alpha (e^{z} - 1) & \text{si } z < 0
\end{cases}
<p>
\]
</p>

<p>
Características:
</p>

<ul class="org-ul">
<li>Para \(z \ge 0\): igual que ReLU.</li>
<li>Para \(z < 0\): decae de forma exponencial, con salida negativa acotada.</li>
</ul>

<p>
Ventajas:
</p>

<ul class="org-ul">
<li>Puede acelerar la convergencia en ciertos casos.</li>
<li>Las salidas negativas ayudan a centrar la activación alrededor de 0,
lo que puede mejorar la propagación del gradiente.</li>
</ul>

<p>
Uso típico:
</p>

<ul class="org-ul">
<li>Capas ocultas, en algunos modelos donde se ha observado mejor
rendimiento que con ReLU estándar.</li>
</ul>
</div>
</li>
</ul>
</div>
<div id="outline-container-orge891035" class="outline-4">
<h4 id="orge891035">Funciones de activación en la capa de salida</h4>
<div class="outline-text-4" id="text-orge891035">
<p>
La función de activación de la <b>capa de salida</b> depende del tipo de
problema:
</p>
</div>
<ul class="org-ul">
<li><a id="org8fec604"></a>Clasificación binaria<br />
<div class="outline-text-5" id="text-org8fec604">
<p>
Se usa típicamente una función <b>sigmoide</b> para obtener una probabilidad
en \((0,1)\):
</p>

<p>
\[
\hat{y} = \sigma(z) \in (0,1)
\]
</p>

<p>
donde \(\hat{y}\) se interpreta como la probabilidad de clase “1”.
</p>
</div>
</li>
<li><a id="orgbac8c46"></a>Clasificación multiclase (mutuamente excluyentes)<br />
<div class="outline-text-5" id="text-orgbac8c46">
<p>
Se usa la función <b>softmax</b>:
</p>

<p>
\[
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}
\]
</p>

<ul class="org-ul">
<li>Convierte un vector de puntajes \(\mathbf{z}\) en un vector de
probabilidades que:
<ul class="org-ul">
<li>son positivas,</li>
<li>y suman 1.</li>
</ul></li>
</ul>
</div>
</li>
<li><a id="org2840bbe"></a>Regresión<br />
<div class="outline-text-5" id="text-org2840bbe">
<ul class="org-ul">
<li>Se usa generalmente una función de activación <b>lineal</b> en la salida:
\[
    f(z) = z
  \]</li>
<li>La red puede entonces producir valores reales sin restricción de
rango (o con restricciones adicionales impuestas por el preprocesado).</li>
</ul>
</div>
</li>
</ul>
</div>
<div id="outline-container-org0006919" class="outline-4">
<h4 id="org0006919">Impacto en el entrenamiento</h4>
<div class="outline-text-4" id="text-org0006919">
<p>
La elección de la función de activación afecta:
</p>

<ul class="org-ul">
<li>La <b>velocidad de convergencia</b>.</li>
<li>La <b>estabilidad</b> del entrenamiento.</li>
<li>El <b>flujo del gradiente</b> a través de las capas.</li>
<li>La capacidad de representar ciertas distribuciones de salida.</li>
</ul>

<p>
Una elección inadecuada:
</p>

<ul class="org-ul">
<li>puede causar vanishing/exploding gradient,</li>
<li>puede impedir que la red aprenda adecuadamente,</li>
<li>o requerir tiempos de entrenamiento excesivos.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc6c4f00" class="outline-3">
<h3 id="orgc6c4f00">Propagación hacia adelante (Forward Propagation)</h3>
<div class="outline-text-3" id="text-orgc6c4f00">
<p>
La <b>propagación hacia adelante</b> es el proceso mediante el cual la red
calcula su salida a partir de una entrada dada.
</p>

<p>
Pasos generales:
</p>

<ol class="org-ol">
<li>Se recibe el vector de entrada \(\mathbf{x}\).</li>
<li>Se calcula sucesivamente:
<ul class="org-ul">
<li>\(\mathbf{z}^{(1)}\), \(\mathbf{a}^{(1)}\) (primera capa oculta),</li>
<li>\(\mathbf{z}^{(2)}\), \(\mathbf{a}^{(2)}\), etc.</li>
</ul></li>
<li>Se obtiene la activación de la capa de salida \(\mathbf{a}^{(L)}\),
que corresponde a la predicción \(\hat{\mathbf{y}}\).</li>
</ol>

<p>
Podemos verlo como una composición de funciones:
</p>

<p>
\[
\mathbf{a}^{(L)} = f^{(L)}\left( \mathbf{W}^{(L)} \, f^{(L-1)}\left( \dots f^{(1)}\left(\mathbf{W}^{(1)} \mathbf{x} + \mathbf{b}^{(1)}\right) \dots \right) + \mathbf{b}^{(L)} \right)
\]
</p>

<p>
o, de forma más compacta:
</p>

<p>
\[
\hat{\mathbf{y}} = F(\mathbf{x}; \theta)
\]
</p>

<p>
donde \(\theta\) denota el conjunto de todos los pesos y bias de la red.
</p>
</div>
</div>
<div id="outline-container-org9eb7fa2" class="outline-3">
<h3 id="org9eb7fa2">Funciones de pérdida</h3>
<div class="outline-text-3" id="text-org9eb7fa2">
<p>
Las funciones de pérdida (o <b>funciones de coste</b>) miden el error entre:
</p>

<ul class="org-ul">
<li>la predicción del modelo \(\hat{y}\) (o \(\hat{\mathbf{y}}\)),</li>
<li>y el valor real \(y\) (o \(\mathbf{y}\)).</li>
</ul>

<p>
El objetivo del entrenamiento es encontrar parámetros \(\theta\) que
<b>minimicen</b> la pérdida promedio sobre el conjunto de entrenamiento.
</p>
</div>
<div id="outline-container-orga3cf2ff" class="outline-4">
<h4 id="orga3cf2ff">Error cuadrático medio (MSE)</h4>
<div class="outline-text-4" id="text-orga3cf2ff">
<p>
Común en problemas de regresión:
</p>

<p>
\[
\mathcal{L}_{\text{MSE}} = \frac{1}{n} \sum_{k=1}^{n} (y_k - \hat{y}_k)^2
\]
</p>

<p>
donde:
</p>

<ul class="org-ul">
<li>\(n\) es el número de muestras,</li>
<li>\(y_k\) es el valor real de la muestra \(k\),</li>
<li>\(\hat{y}_k\) es la predicción del modelo.</li>
</ul>
</div>
</div>
<div id="outline-container-org4a6bd31" class="outline-4">
<h4 id="org4a6bd31">Entropía cruzada (Cross-Entropy)</h4>
<div class="outline-text-4" id="text-org4a6bd31">
<p>
Muy utilizada en clasificación.
</p>

<ul class="org-ul">
<li>Para clasificación binaria:</li>
</ul>

<p>
\[
\mathcal{L}_{\text{binaria}} = - \frac{1}{n} \sum_{k=1}^{n} \left[ y_k \log(\hat{y}_k) + (1 - y_k)\log(1 - \hat{y}_k) \right]
\]
</p>

<ul class="org-ul">
<li>Para clasificación multiclase (one-hot \(\mathbf{y}\) y softmax \(\hat{\mathbf{y}}\)):</li>
</ul>

<p>
\[
\mathcal{L}_{\text{multiclase}} = - \frac{1}{n} \sum_{k=1}^{n} \sum_{c=1}^{C} y_{k,c} \log(\hat{y}_{k,c})
\]
</p>

<p>
donde:
</p>

<ul class="org-ul">
<li>\(C\) es el número de clases,</li>
<li>\(y_{k,c}\) es 1 si la muestra \(k\) pertenece a la clase \(c\), y 0 en caso contrario,</li>
<li>\(\hat{y}_{k,c}\) es la probabilidad predicha para la clase \(c\).</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org6954e52" class="outline-3">
<h3 id="org6954e52">Backpropagation</h3>
<div class="outline-text-3" id="text-org6954e52">
<p>
<b>Backpropagation</b> es el algoritmo fundamental para entrenar MLP. Se
basa en la aplicación sistemática de la <b>regla de la cadena</b> del cálculo
diferencial para propagar el error desde la capa de salida hacia las
capas anteriores.
</p>

<p>
Para un peso genérico \(w\), la derivada de la pérdida se expresa como:
</p>

<p>
\[
\frac{\partial \mathcal{L}}{\partial w} =
\frac{\partial \mathcal{L}}{\partial a}
\cdot \frac{\partial a}{\partial z}
\cdot \frac{\partial z}{\partial w}
\]
</p>

<p>
donde:
</p>

<ul class="org-ul">
<li>\(\frac{\partial \mathcal{L}}{\partial a}\): cuánto cambia la pérdida
si cambia la activación \(a\),</li>
<li>\(\frac{\partial a}{\partial z}\): deriva de la función de activación,</li>
<li>\(\frac{\partial z}{\partial w}\): relación lineal entre \(z\) y el
peso \(w\).</li>
</ul>

<p>
El algoritmo:
</p>

<ol class="org-ol">
<li>Calcula un <b>forward pass</b> (de entrada a salida).</li>
<li>Calcula la pérdida \(\mathcal{L}\).</li>
<li>Propaga gradientes hacia atrás usando la regla de la cadena.</li>
<li>Obtiene \(\frac{\partial \mathcal{L}}{\partial w}\) y
\(\frac{\partial \mathcal{L}}{\partial b}\) para todos los pesos y
bias de la red.</li>
<li>Usa estos gradientes para actualizar los parámetros.</li>
</ol>
</div>
</div>
<div id="outline-container-orgad8adcb" class="outline-3">
<h3 id="orgad8adcb">Descenso de gradiente</h3>
<div class="outline-text-3" id="text-orgad8adcb">
<p>
El <b>descenso de gradiente</b> (gradient descent) es la regla de
actualización básica para minimizar la función de pérdida.
</p>

<p>
Para un peso \(w\):
</p>

<p>
\[
w := w - \eta \, \frac{\partial \mathcal{L}}{\partial w}
\]
</p>

<p>
donde:
</p>

<ul class="org-ul">
<li>\(\eta\) es la <b>tasa de aprendizaje</b> (learning rate),</li>
<li>\(\frac{\partial \mathcal{L}}{\partial w}\) es el gradiente de la
pérdida respecto a \(w\).</li>
</ul>

<p>
Interpretación:
</p>

<ul class="org-ul">
<li>Nos movemos en la dirección <b>opuesta</b> al gradiente (descenso),</li>
<li>La magnitud del paso está controlada por \(\eta\).</li>
</ul>

<p>
En la práctica:
</p>

<ul class="org-ul">
<li>Se usan variantes como:
<ul class="org-ul">
<li><b>Stochastic Gradient Descent (SGD)</b>,</li>
<li>SGD con <b>momentum</b>,</li>
<li><b>Adam</b>, <b>RMSProp</b>, etc.</li>
</ul></li>
<li>Estas variantes mejoran:
<ul class="org-ul">
<li>la velocidad de convergencia,</li>
<li>la estabilidad numérica,</li>
<li>la capacidad de escapar de mínimos locales poco profundos.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org78bfea3" class="outline-2">
<h2 id="org78bfea3">Ejemplo Clasificación del dataset Iris con MLP</h2>
<div class="outline-text-2" id="text-org78bfea3">
<p>
Este apartado muestra un ejemplo completo en Python usando el dataset
clásico Iris y una red neuronal feedforward (Perceptrón Multicapa)
usando la librería scikit-learn.
</p>

<p>
El objetivo es clasificar flores Iris en tres clases:
</p>

<ul class="org-ul">
<li>Setosa</li>
<li>Versicolor</li>
<li>Virginica</li>
</ul>


<p>
Importar librerías
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np
<span style="color: #fb4934;">from</span> sklearn.datasets <span style="color: #fb4934;">import</span> load_iris 
<span style="color: #fb4934;">from</span> sklearn.model_selection <span style="color: #fb4934;">import</span> train_test_split 
<span style="color: #fb4934;">from</span> sklearn.preprocessing <span style="color: #fb4934;">import</span> StandardScaler 
<span style="color: #fb4934;">from</span> sklearn.neural_network <span style="color: #fb4934;">import</span> MLPClassifier 
<span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> accuracy_score, classification_report
</pre>
</div>

<p>
Cargar el dataset Iris
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">iris</span> = load_iris<span style="color: #fe8019;">()</span>
<span style="color: #83a598;">X</span> = iris.data <span style="color: #928374;">#</span><span style="color: #928374;">
</span><span style="color: #928374;">#</span><span style="color: #928374;">Caracter&#237;sticas (150 x 4)
</span><span style="color: #83a598;">y</span> = iris.target <span style="color: #928374;"># </span><span style="color: #928374;">Clases (150,)
</span><span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>X.shape<span style="color: #fe8019;">)</span> <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>y.shape<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Las 4 características son:
</p>

<ul class="org-ul">
<li>Largo del sépalo</li>
<li>Ancho del sépalo</li>
<li>Largo del pétalo</li>
<li>Ancho del pétalo</li>
</ul>

<p>
Las clases están codificadas como:
</p>

<ul class="org-ul">
<li>0 → Setosa</li>
<li>1 → Versicolor</li>
<li>2 → Virginica</li>
</ul>

<p>
El siguiente fragmento de código realiza la partición del conjunto de
datos original en dos subconjuntos disjuntos: uno destinado al
entrenamiento del modelo y otro a su evaluación.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">X_train</span>, <span style="color: #83a598;">X_test</span>, <span style="color: #83a598;">y_train</span>, <span style="color: #83a598;">y_test</span> = train_test_split<span style="color: #fe8019;">(</span> X, y, test_size=0.2, random_state=42, stratify=y <span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Propósito de la partición:
</p>

<p>
En aprendizaje automático supervisado, es fundamental evaluar la
capacidad de generalización de un modelo. Para ello, los datos
disponibles se dividen en:
</p>

<ul class="org-ul">
<li><b>Conjunto de entrenamiento</b>: utilizado para ajustar los parámetros del modelo (pesos y sesgos).</li>
<li><b>Conjunto de prueba</b>: utilizado exclusivamente para medir el desempeño
del modelo sobre datos no vistos durante el entrenamiento.</li>
</ul>

<p>
Esta separación permite detectar fenómenos como overfitting y
underfitting, y proporciona una estimación más realista del
rendimiento esperado en producción.
</p>

<p>
<b>El parámetro</b>:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">test_size</span>=0.2
</pre>
</div>
<p>
indica que el 20 % del conjunto total de datos se reserva para el
conjunto de prueba, mientras que el 80 % restante se utiliza para
entrenamiento. Esta proporción es común en la práctica y representa un
compromiso razonable entre:
</p>

<ul class="org-ul">
<li>disponer de suficientes datos para entrenar el modelo, y</li>
<li>contar con una muestra representativa para evaluar su generalización.</li>
</ul>
</div>
<div id="outline-container-orgc5fe42a" class="outline-3">
<h3 id="orgc5fe42a">Reproducibilidad del experimento</h3>
<div class="outline-text-3" id="text-orgc5fe42a">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">random_state</span>=42
</pre>
</div>

<p>
fija la semilla del generador de números aleatorios utilizado durante
la partición.  Esto garantiza que la división de los datos sea
reproducible, es decir, que múltiples ejecuciones del mismo código
produzcan exactamente la misma separación entre entrenamiento y
prueba.
</p>

<p>
La reproducibilidad es un requisito esencial en entornos científicos y
académicos, ya que permite validar y comparar resultados de manera
consistente.
</p>
</div>
</div>
<div id="outline-container-orgb87ed75" class="outline-3">
<h3 id="orgb87ed75">Estratificación de clases</h3>
<div class="outline-text-3" id="text-orgb87ed75">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">stratify</span>=y
</pre>
</div>

<p>
indica que la división debe realizarse de forma estratificada,
conservando la proporción original de cada clase en ambos
subconjuntos.
</p>

<p>
Esto es especialmente importante en problemas de clasificación, ya que
una división aleatoria sin estratificación podría provocar:
</p>

<ul class="org-ul">
<li>conjuntos de entrenamiento o prueba con clases desbalanceadas,</li>
<li>métricas de desempeño engañosas,</li>
<li>modelos que no aprendan adecuadamente clases minoritarias.</li>
</ul>

<p>
Mediante la estratificación, se asegura que tanto el conjunto de
entrenamiento como el de prueba sean representativos de la
distribución real de las clases.
</p>
</div>
</div>
<div id="outline-container-org1b123d7" class="outline-3">
<h3 id="org1b123d7">Importancia en redes neuronales</h3>
<div class="outline-text-3" id="text-org1b123d7">
<p>
En el contexto de redes neuronales (incluyendo MLP):
</p>

<ul class="org-ul">
<li>el entrenamiento ajusta los pesos minimizando una función de pérdida
sobre X<sub>train</sub>,</li>

<li>la evaluación sobre X<sub>test</sub> permite medir la capacidad del modelo
para generalizar,</li>

<li>una mala partición puede conducir a conclusiones erróneas sobre el
desempeño del modelo.</li>
</ul>

<p>
Por esta razón, la división adecuada del conjunto de datos constituye
un paso crítico previo al entrenamiento y no debe considerarse un
detalle menor de implementación.
</p>
</div>
</div>
<div id="outline-container-org04559a5" class="outline-3">
<h3 id="org04559a5">Normalización de los datos</h3>
<div class="outline-text-3" id="text-org04559a5">
<p>
La normalización de los datos de entrada es un paso crítico en el
entrenamiento de redes neuronales, ya que influye directamente en la
estabilidad numérica, la velocidad de convergencia y la eficacia del
aprendizaje.
</p>

<p>
En una red neuronal, los pesos se ajustan mediante métodos de
optimización basados en gradientes. Si las variables de entrada
presentan escalas muy diferentes, el proceso de entrenamiento puede
volverse ineficiente o inestable.
</p>

<p>
En muchos conjuntos de datos, las características pueden tener rangos muy distintos. Por ejemplo:
</p>

<ul class="org-ul">
<li>una variable puede tomar valores entre 0 y 1,</li>
<li>otra entre 0 y 10⁶,</li>
<li>otra puede incluir valores negativos.</li>
</ul>

<p>
Cuando estos datos se introducen directamente en una red neuronal:
</p>

<ul class="org-ul">
<li>los gradientes asociados a variables de gran escala dominan la actualización de los pesos,</li>
<li>las funciones de activación pueden saturarse,</li>
<li>el descenso por gradiente se vuelve lento o errático.</li>
</ul>

<p>
La normalización busca homogeneizar la escala de las entradas,
permitiendo que todas las características contribuyan de manera
equilibrada al aprendizaje.
</p>


<p>
Una de las técnicas más utilizadas es la estandarización, implementada
en scikit-learn mediante la clase StandardScaler.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">scaler</span> = StandardScaler<span style="color: #fe8019;">()</span>
<span style="color: #83a598;">X_train</span> = scaler.fit_transform<span style="color: #fe8019;">(</span>X_train<span style="color: #fe8019;">)</span> <span style="color: #83a598;">X_test</span> = scaler.transform<span style="color: #fe8019;">(</span>X_test<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Este procedimiento transforma cada característica \(x\) según la siguiente expresión:
</p>

<p>
\[
x' = \frac{x - \mu}{\sigma}
\]
</p>

<p>
donde:
</p>

<ul class="org-ul">
<li>\( \mu \) es la media de la característica,</li>
<li>\( \sigma \) es la desviación estándar de la característica.</li>
</ul>

<p>
Como resultado de esta transformación, cada variable queda con:
</p>

<ul class="org-ul">
<li>media aproximadamente igual a 0,</li>
<li>desviación estándar igual a 1.</li>
</ul>
</div>
</div>
<div id="outline-container-org9276b26" class="outline-3">
<h3 id="org9276b26">Definir el Perceptrón Multicapa (MLP)</h3>
<div class="outline-text-3" id="text-org9276b26">
<p>
El siguiente fragmento de código define un <b>Perceptrón Multicapa</b> (Multilayer Perceptron, MLP)
para un problema de clasificación multiclase, utilizando la implementación provista por
la biblioteca <b>scikit-learn</b>.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">mlp</span> = MLPClassifier<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   hidden_layer_sizes=<span style="color: #b16286;">(</span>10, 10<span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   activation=<span style="color: #b8bb26;">'relu'</span>,
<span style="background-color: #3c3836;"> </span>   solver=<span style="color: #b8bb26;">'adam'</span>,
<span style="background-color: #3c3836;"> </span>   learning_rate_init=0.001,
<span style="background-color: #3c3836;"> </span>   max_iter=2000,
<span style="background-color: #3c3836;"> </span>   random_state=42
<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Este modelo corresponde a una red neuronal <b>feedforward completamente conectada</b>,
entrenada mediante <b>backpropagation</b> y optimizada usando métodos de descenso por gradiente.
</p>
</div>
<div id="outline-container-orgcc7f0a9" class="outline-4">
<h4 id="orgcc7f0a9">Arquitectura de la red neuronal</h4>
<div class="outline-text-4" id="text-orgcc7f0a9">
<p>
La arquitectura del MLP queda determinada por el número de características de entrada,
las capas ocultas definidas explícitamente y el número de neuronas en la capa de salida.
</p>
</div>
</div>
<div id="outline-container-org49b240a" class="outline-4">
<h4 id="org49b240a">Capa de entrada</h4>
<div class="outline-text-4" id="text-org49b240a">
<ul class="org-ul">
<li>La capa de entrada está compuesta por <b>4 neuronas</b>.</li>
<li>Cada neurona representa una característica del vector de entrada.</li>
<li>Esta capa no aplica transformaciones, únicamente propaga los valores hacia la primera capa oculta.</li>
</ul>

<p>
Formalmente, el vector de entrada se expresa como:
</p>

<p>
\[
\mathbf{x} = (x_1, x_2, x_3, x_4)
\]
</p>
</div>
</div>
<div id="outline-container-org9c5fd14" class="outline-4">
<h4 id="org9c5fd14">Capas ocultas</h4>
<div class="outline-text-4" id="text-org9c5fd14">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">hidden_layer_sizes</span>=<span style="color: #fe8019;">(</span>10, 10<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
define <b>dos capas ocultas</b>, cada una con <b>10 neuronas</b>.
</p>

<p>
Características principales:
</p>

<ul class="org-ul">
<li>Son capas <b>densas (fully connected)</b>.</li>
<li>Cada neurona recibe como entrada la salida de <b>todas</b> las neuronas de la capa anterior.</li>
<li>Permiten aprender representaciones no lineales del espacio de características.</li>
</ul>

<p>
Cada capa oculta implementa la transformación:
</p>

<p>
\[
\mathbf{h}^{(l)} = f\left( \mathbf{W}^{(l)} \mathbf{h}^{(l-1)} + \mathbf{b}^{(l)} \right)
\]
</p>

<p>
donde:
</p>

<ul class="org-ul">
<li>\( \mathbf{W}^{(l)} \) es la matriz de pesos,</li>
<li>\( \mathbf{b}^{(l)} \) es el vector de sesgos,</li>
<li>\( f(\cdot) \) es la función de activación.</li>
</ul>
</div>
</div>
<div id="outline-container-org0e3bd62" class="outline-4">
<h4 id="org0e3bd62">Función de activación</h4>
<div class="outline-text-4" id="text-org0e3bd62">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">activation</span>=<span style="color: #b8bb26;">'relu'</span>
</pre>
</div>

<p>
indica el uso de la función <b>ReLU (Rectified Linear Unit)</b>, definida como:
</p>

<p>
\[
\text{ReLU}(z) = \max(0, z)
\]
</p>

<p>
Esta función se utiliza porque:
</p>

<ul class="org-ul">
<li>introduce no linealidad,</li>
<li>reduce el problema del <b>vanishing gradient</b>,</li>
<li>mejora la estabilidad del entrenamiento,</li>
<li>es computacionalmente eficiente.</li>
</ul>
</div>
</div>
<div id="outline-container-org072a2f8" class="outline-4">
<h4 id="org072a2f8">Capa de salida</h4>
<div class="outline-text-4" id="text-org072a2f8">
<ul class="org-ul">
<li>La capa de salida está compuesta por <b>3 neuronas</b>.</li>
<li>Cada neurona corresponde a una de las clases del problema.</li>
<li>Internamente, el modelo utiliza una función <b>softmax</b> para obtener probabilidades.</li>
</ul>

<p>
La clase predicha se obtiene mediante la operación <b>argmax</b> sobre las salidas.
</p>
</div>
</div>
<div id="outline-container-org572939d" class="outline-4">
<h4 id="org572939d">Entrenamiento del modelo</h4>
<div class="outline-text-4" id="text-org572939d">
<p>
El entrenamiento se realiza mediante el optimizador <b>Adam</b>:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">solver</span>=<span style="color: #b8bb26;">'adam'</span>
</pre>
</div>

<p>
Adam combina:
</p>
<ul class="org-ul">
<li>momentum</li>
<li>tasas de aprendizaje adaptativas</li>
</ul>

<p>
lo que permite una convergencia más rápida y estable en redes con múltiples capas.
</p>

<p>
La tasa de aprendizaje inicial se define como:
</p>

<p>
\[
\eta = 0.001
\]
</p>

<p>
controlando el tamaño de los pasos durante la actualización de los pesos.
</p>
</div>
</div>
</div>
<div id="outline-container-org399a85b" class="outline-3">
<h3 id="org399a85b">Número de iteraciones</h3>
<div class="outline-text-3" id="text-org399a85b">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">max_iter</span>=2000
</pre>
</div>

<p>
establece el número máximo de épocas de entrenamiento.
Una época corresponde a un pase completo sobre el conjunto de entrenamiento.
</p>

<p>
Un número elevado de épocas favorece la convergencia, aunque incrementa el riesgo de <b>overfitting</b>.
</p>
</div>
</div>
<div id="outline-container-orge3ce6d6" class="outline-3">
<h3 id="orge3ce6d6">Reproducibilidad</h3>
<div class="outline-text-3" id="text-orge3ce6d6">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">random_state</span>=42
</pre>
</div>

<p>
fija la semilla del generador de números aleatorios, garantizando resultados reproducibles
en la inicialización de los pesos y el proceso de entrenamiento.
</p>
</div>
</div>
<div id="outline-container-orgb68a41a" class="outline-3">
<h3 id="orgb68a41a">Entrenamiento del modelo</h3>
<div class="outline-text-3" id="text-orgb68a41a">
<p>
El entrenamiento deñ Perceptrón Multicapa (MLP) consiste en ajustar
los pesos y sesgos de la red para minimizar el error de predicción
sobre los datos de entrenamiento.
</p>

<div class="org-src-container">
<pre class="src src-python">mlp.fit<span style="color: #fe8019;">(</span>X_train, y_train<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Durante este proceso ocurren los siguientes pasos fundamentales:
</p>
</div>
<div id="outline-container-org9e03b80" class="outline-4">
<h4 id="org9e03b80">Propagación hacia adelante (forward pass)</h4>
<div class="outline-text-4" id="text-org9e03b80">
<p>
Cada muestra de entrada x atraviesa la red capa por capa.
</p>

<p>
En cada neurona se calcula una combinación lineal y se aplica una función de activación.
</p>

<p>
Se obtiene una salida y que representa la predicción del modelo.
</p>
</div>
</div>
<div id="outline-container-org8c8e72f" class="outline-4">
<h4 id="org8c8e72f">Cálculo del error</h4>
<div class="outline-text-4" id="text-org8c8e72f">
<p>
La salida predicha se compara con la etiqueta real 𝑦.
Se utiliza una función de pérdida (por ejemplo, log-loss para clasificación multiclase).
</p>
</div>
</div>
<div id="outline-container-orga2eb6c7" class="outline-4">
<h4 id="orga2eb6c7">Backpropagation</h4>
<div class="outline-text-4" id="text-orga2eb6c7">
<p>
El error se propaga desde la capa de salida hacia las capas
anteriores. Se calculan los gradientes del error respecto a cada peso
y sesgo. Se aplica la regla de la cadena del cálculo diferencial.
</p>
</div>
</div>
<div id="outline-container-org97f8834" class="outline-4">
<h4 id="org97f8834">Descenso de gradiente con Adam</h4>
<div class="outline-text-4" id="text-org97f8834">
<ul class="org-ul">
<li>Adam combina Momentum y RMSProp.</li>
<li>Ajusta automáticamente la tasa de aprendizaje para cada parámetro.</li>
<li>Proporciona convergencia rápida y estable.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc2d613e" class="outline-3">
<h3 id="orgc2d613e">Evaluación del modelo</h3>
<div class="outline-text-3" id="text-orgc2d613e">
<p>
Una vez entrenado el modelo, se evalúa su desempeño usando datos no vistos durante el entrenamiento.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">y_pred</span> = mlp.predict<span style="color: #fe8019;">(</span>X_test<span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Accuracy:"</span>, accuracy_score<span style="color: #b16286;">(</span>y_test, y_pred<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span> <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">Reporte de clasificaci&#243;n:</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span> <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>classification_report<span style="color: #b16286;">(</span>y_test, y_pred, target_names=iris.target_names<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
<div id="outline-container-orga395feb" class="outline-4">
<h4 id="orga395feb">Métricas utilizadas</h4>
<div class="outline-text-4" id="text-orga395feb">
<ul class="org-ul">
<li>Accuracy: proporción total de predicciones correctas.</li>
<li>Precision: qué tan confiables son las predicciones positivas.</li>
<li>Recall: capacidad del modelo para encontrar todos los ejemplos de una clase.</li>
<li>F1-score: balance entre precisión y recall.</li>
</ul>

<p>
En el dataset Iris, el accuracy suele estar en el rango del 95% al
100%, debido a su baja dimensionalidad y buena separación entre
clases.
</p>
</div>
</div>
</div>
<div id="outline-container-org43b55d9" class="outline-3">
<h3 id="org43b55d9">Predicción con una nueva flor</h3>
<div class="outline-text-3" id="text-org43b55d9">
<p>
El modelo entrenado puede utilizarse para predecir nuevas muestras.
</p>

<div class="org-src-container">
<pre class="src src-python">
<span style="color: #928374;">#</span><span style="color: #928374;">[largo_sepalo, ancho_sepalo, largo_petalo, ancho_petalo]
</span>
<span style="color: #83a598;">flor_nueva</span> = np.array<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span><span style="color: #b8bb26;">[</span>5.1, 3.5, 1.4, 0.2<span style="color: #b8bb26;">]</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="color: #928374;">#</span><span style="color: #928374;">Normalizaci&#243;n con el mismo scaler del entrenamiento
</span><span style="color: #83a598;">flor_nueva</span> = scaler.transform<span style="color: #fe8019;">(</span>flor_nueva<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">prediccion</span> = mlp.predict<span style="color: #fe8019;">(</span>flor_nueva<span style="color: #fe8019;">)</span> <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Clase predicha:"</span>, iris.target_names<span style="color: #b16286;">[</span>prediccion<span style="color: #b8bb26;">[</span>0<span style="color: #b8bb26;">]</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Es fundamental aplicar la misma normalización usada en el entrenamiento para mantener coherencia en las escalas.
</p>
</div>
</div>
<div id="outline-container-org57eb578" class="outline-3">
<h3 id="org57eb578">Interpretación matemática del MLP</h3>
<div class="outline-text-3" id="text-org57eb578">
<p>
Cada neurona de la red realiza el siguiente cálculo:
</p>

<pre class="example" id="org45e63cd">
z = w · x + b a = f(z)
</pre>

<p>
Donde: 𝑤 es el vector de pesos 𝑥 es el vector de entradas 𝑏 es el sesgo (bias) 𝑓
es la función de activación (ReLU en las capas ocultas). La capa de salida utiliza la función Softmax:
</p>

<div class="latex" id="org229d692">
<p>
\text{softmax}(z<sub>i</sub>) = \frac{e<sup>z<sub>i</sub></sup>}{&sum;<sub>j</sub> e<sup>z<sub>j</sub></sup>}
</p>

</div>

<p>
Esto permite interpretar las salidas como probabilidades para cada clase.
</p>
</div>
</div>
</div>
<div id="outline-container-org7a7506f" class="outline-2">
<h2 id="org7a7506f">Ejemplo Clasificación de Cáncer de Mama con MLP</h2>
<div class="outline-text-2" id="text-org7a7506f">
<p>
Este apartado muestra un ejemplo completo en Python usando el dataset
<b>Breast Cancer Wisconsin (Diagnostic)</b> y un <b>Perceptrón Multicapa (MLP)</b>
usando la librería scikit-learn.
</p>

<p>
El objetivo es clasificar tumores en dos categorías:
</p>

<ul class="org-ul">
<li>0 → Maligno</li>
<li>1 → Benigno</li>
</ul>

<p>
Este problema es un caso típico de <b><b>clasificación binaria</b></b> en el
ámbito médico, donde es crucial:
</p>

<ul class="org-ul">
<li>minimizar falsos negativos (tumor maligno clasificado como benigno),</li>
<li>mantener una buena precisión general del modelo.</li>
</ul>
</div>
<div id="outline-container-orgd5e9dd9" class="outline-3">
<h3 id="orgd5e9dd9">Importar librerías</h3>
<div class="outline-text-3" id="text-orgd5e9dd9">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np
<span style="color: #fb4934;">from</span> sklearn.datasets <span style="color: #fb4934;">import</span> load_breast_cancer
<span style="color: #fb4934;">from</span> sklearn.model_selection <span style="color: #fb4934;">import</span> train_test_split
<span style="color: #fb4934;">from</span> sklearn.preprocessing <span style="color: #fb4934;">import</span> StandardScaler
<span style="color: #fb4934;">from</span> sklearn.neural_network <span style="color: #fb4934;">import</span> MLPClassifier
<span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> accuracy_score, classification_report
</pre>
</div>

<p>
En este bloque:
</p>

<ul class="org-ul">
<li><code>load_breast_cancer</code>: carga el dataset de cáncer de mama.</li>
<li><code>train_test_split</code>: divide en entrenamiento y prueba.</li>
<li><code>StandardScaler</code>: aplica estandarización a las características.</li>
<li><code>MLPClassifier</code>: implementa un Perceptrón Multicapa (MLP).</li>
<li><code>accuracy_score</code> y <code>classification_report</code>: permiten evaluar el modelo.</li>
</ul>
</div>
</div>
<div id="outline-container-org57b2039" class="outline-3">
<h3 id="org57b2039">Cargar el dataset Breast Cancer</h3>
<div class="outline-text-3" id="text-org57b2039">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">data</span> = load_breast_cancer<span style="color: #fe8019;">()</span>
<span style="color: #83a598;">X</span> = data.data      <span style="color: #928374;"># </span><span style="color: #928374;">Caracter&#237;sticas (569 x 30)
</span><span style="color: #83a598;">y</span> = data.target    <span style="color: #928374;"># </span><span style="color: #928374;">Etiquetas (569,)
</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Dimensiones de X:"</span>, X.shape<span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Clases num&#233;ricas:"</span>, np.unique<span style="color: #b16286;">(</span>y<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Nombres de clases:"</span>, data.target_names<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Este dataset contiene:
</p>

<ul class="org-ul">
<li>569 muestras (pacientes).</li>
<li>30 características numéricas que describen propiedades de los tumores
(radio, textura, perímetro, área, suavidad, compacidad, etc.).</li>
<li>2 clases:
<ul class="org-ul">
<li>0 → malignant (maligno)</li>
<li>1 → benign (benigno)</li>
</ul></li>
</ul>

<p>
Cada muestra corresponde a una imagen de tejido mamario analizada
digitalmente. Las 30 características se derivan de medidas estadísticas
de la forma, textura y estructura del tumor.
</p>
</div>
<div id="outline-container-orgbb49222" class="outline-4">
<h4 id="orgbb49222">Importancia del dominio</h4>
<div class="outline-text-4" id="text-orgbb49222">
<p>
En aplicaciones médicas, la interpretación de las predicciones es muy
sensible:
</p>

<ul class="org-ul">
<li>un <b>falso negativo</b> (maligno etiquetado como benigno) puede retrasar
un diagnóstico crítico;</li>
<li>un <b>falso positivo</b> (benigno etiquetado como maligno) puede generar
ansiedad y procedimientos innecesarios.</li>
</ul>

<p>
Por ello, además de la <b>accuracy</b>, suelen analizarse:
</p>

<ul class="org-ul">
<li>sensibilidad (<b>recall</b>) para la clase “maligno”,</li>
<li>especificidad,</li>
<li>matriz de confusión, etc.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgeb76b5d" class="outline-3">
<h3 id="orgeb76b5d">Partición del conjunto de datos</h3>
<div class="outline-text-3" id="text-orgeb76b5d">
<p>
Dividimos el dataset en entrenamiento y prueba:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">X_train</span>, <span style="color: #83a598;">X_test</span>, <span style="color: #83a598;">y_train</span>, <span style="color: #83a598;">y_test</span> = train_test_split<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   X,
<span style="background-color: #3c3836;"> </span>   y,
<span style="background-color: #3c3836;"> </span>   test_size=0.3,
<span style="background-color: #3c3836;"> </span>   random_state=42,
<span style="background-color: #3c3836;"> </span>   stratify=y
<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
<div id="outline-container-org4c986be" class="outline-4">
<h4 id="org4c986be">Significado de los parámetros</h4>
<div class="outline-text-4" id="text-org4c986be">
<ul class="org-ul">
<li><code>test_size=0.3</code>:
<ul class="org-ul">
<li>30 % de los datos se reservan para el <b>conjunto de prueba</b>.</li>
<li>70 % se usan para entrenar el modelo.</li>
<li>En este caso:
<ul class="org-ul">
<li>Entrenamiento: ≈ 398 muestras.</li>
<li>Prueba: ≈ 171 muestras.</li>
</ul></li>
</ul></li>

<li><code>random_state=42</code>:
<ul class="org-ul">
<li>Fija la semilla del generador de números aleatorios.</li>
<li>Permite que la partición sea reproducible: el mismo código genera
siempre la misma división.</li>
</ul></li>

<li><code>stratify=y</code>:
<ul class="org-ul">
<li>Asegura que la proporción de clases (maligno/benigno) sea similar
tanto en entrenamiento como en prueba.</li>
<li>Esto es crucial en problemas médicos, donde el balance de clases
puede influir fuertemente en las métricas.</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org6e2705d" class="outline-4">
<h4 id="org6e2705d">Propósito de la partición</h4>
<div class="outline-text-4" id="text-org6e2705d">
<p>
En aprendizaje automático supervisado:
</p>

<ul class="org-ul">
<li>El <b>conjunto de entrenamiento</b> se usa para ajustar los parámetros
(pesos y sesgos) del modelo.</li>
<li>El <b>conjunto de prueba</b> se usa <b>solo</b> para evaluar la capacidad de
generalización sobre datos no vistos.</li>
</ul>

<p>
Esta separación es esencial para:
</p>

<ul class="org-ul">
<li>detectar <b>overfitting</b> (el modelo memoriza el entrenamiento pero
generaliza mal),</li>
<li>obtener una estimación realista del rendimiento.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org2bf65fb" class="outline-3">
<h3 id="org2bf65fb">Normalización (Estandarización)</h3>
<div class="outline-text-3" id="text-org2bf65fb">
<p>
Las características tienen escalas muy diferentes (áreas grandes,
texturas pequeñas, etc.). Esto puede causar:
</p>

<ul class="org-ul">
<li>problemas numéricos,</li>
<li>gradientes desbalanceados,</li>
<li>convergencia lenta o inestable.</li>
</ul>

<p>
Por ello, aplicamos estandarización:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">scaler</span> = StandardScaler<span style="color: #fe8019;">()</span>
<span style="color: #83a598;">X_train</span> = scaler.fit_transform<span style="color: #fe8019;">(</span>X_train<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">X_test</span> = scaler.transform<span style="color: #fe8019;">(</span>X_test<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Este procedimiento transforma cada característica \(x\) según:
</p>

<div class="latex" id="orgcd4ae67">
<p>
x' = \frac{x - \mu}{\sigma}
</p>

</div>

<p>
donde:
</p>

<ul class="org-ul">
<li>\(\mu\) es la media de la característica calculada sobre el conjunto
de entrenamiento,</li>
<li>\(\sigma\) es la desviación estándar de dicha característica.</li>
</ul>

<p>
Después de la transformación:
</p>

<ul class="org-ul">
<li>cada variable tiene media aproximadamente 0,</li>
<li>y desviación estándar aproximadamente 1.</li>
</ul>
</div>
<div id="outline-container-orgf3bea83" class="outline-4">
<h4 id="orgf3bea83">Importante</h4>
<div class="outline-text-4" id="text-orgf3bea83">
<ul class="org-ul">
<li>Solo se llama a <code>fit_transform</code> en <code>X_train</code>:
<ul class="org-ul">
<li><code>fit</code> calcula \(\mu\) y \(\sigma\) usando <b>solo entrenamiento</b>.</li>
<li><code>transform</code> aplica la transformación.</li>
</ul></li>
<li>Para <code>X_test</code> se usa únicamente <code>transform</code>:
<ul class="org-ul">
<li>se reescalan los datos de prueba con los mismos parámetros
(\(\mu\) y \(\sigma\)) obtenidos del entrenamiento.</li>
</ul></li>
<li>Esto evita <b>filtrar información del conjunto de prueba</b> hacia el
proceso de entrenamiento (data leakage).</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org0ad78e8" class="outline-3">
<h3 id="org0ad78e8">Definición del Perceptrón Multicapa (MLP)</h3>
<div class="outline-text-3" id="text-org0ad78e8">
<p>
Definimos un MLP para clasificación binaria:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">mlp</span> = MLPClassifier<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   hidden_layer_sizes=<span style="color: #b16286;">(</span>30, 15<span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   activation=<span style="color: #b8bb26;">'relu'</span>,
<span style="background-color: #3c3836;"> </span>   solver=<span style="color: #b8bb26;">'adam'</span>,
<span style="background-color: #3c3836;"> </span>   max_iter=1000,
<span style="background-color: #3c3836;"> </span>   random_state=42
<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
<div id="outline-container-orgd83e35f" class="outline-4">
<h4 id="orgd83e35f">Arquitectura del modelo</h4>
<div class="outline-text-4" id="text-orgd83e35f">
<p>
El MLP es una red neuronal <b>feedforward</b> completamente conectada.
</p>

<ul class="org-ul">
<li><b>Capa de entrada</b>:
<ul class="org-ul">
<li>Tiene tantas neuronas como características de entrada: 30.</li>
<li>Cada componente del vector \(\mathbf{x} \in \mathbb{R}^{30}\)
representa una característica del tumor.</li>
</ul></li>

<li><p>
<b>Capas ocultas</b>:
</p>
<ul class="org-ul">
<li>Primer capa oculta: 30 neuronas.</li>
<li>Segunda capa oculta: 15 neuronas.</li>
<li><p>
Se especifican con el parámetro:
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">hidden_layer_sizes</span> = <span style="color: #fe8019;">(</span>30, 15<span style="color: #fe8019;">)</span>
</pre>
</div></li>
</ul>

<p>
Cada neurona en una capa oculta:
</p>
<ul class="org-ul">
<li>recibe como entrada la salida de todas las neuronas de la capa
anterior (capas densas),</li>
<li>aplica una transformación lineal seguida de una función de
activación no lineal.</li>
</ul></li>

<li><b>Capa de salida</b>:
<ul class="org-ul">
<li>Para clasificación binaria, internamente el MLP de scikit-learn
puede usar:
<ul class="org-ul">
<li>1 neurona con activación logística (sigmoide),</li>
<li>o una representación equivalente a 2 clases.</li>
</ul></li>
<li>La salida se interpreta como una probabilidad de pertenecer a la
clase “1” (benigno).</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgd231633" class="outline-4">
<h4 id="orgd231633">Función de activación ReLU</h4>
<div class="outline-text-4" id="text-orgd231633">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">activation</span> = <span style="color: #b8bb26;">'relu'</span>
</pre>
</div>

<p>
indica el uso de la función <b>ReLU (Rectified Linear Unit)</b> en las capas
ocultas:
</p>

<div class="latex" id="org95c58fe">
<p>
\text{ReLU}(z) = max(0, z)
</p>

</div>

<p>
Ventajas de ReLU:
</p>

<ul class="org-ul">
<li>Introduce no linealidad (permite aproximar funciones no lineales).</li>
<li>Reduce el problema del <b>vanishing gradient</b> en comparación con
funciones como sigmoide o tanh.</li>
<li>Es simple y eficiente de calcular.</li>
</ul>
</div>
</div>
<div id="outline-container-org34da567" class="outline-4">
<h4 id="org34da567">Optimizador Adam</h4>
<div class="outline-text-4" id="text-org34da567">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">solver</span> = <span style="color: #b8bb26;">'adam'</span>
</pre>
</div>

<p>
selecciona el optimizador <b>Adam</b> (Adaptive Moment Estimation), que:
</p>

<ul class="org-ul">
<li>combina ideas de Momentum y RMSProp,</li>
<li>mantiene promedios móviles de:
<ul class="org-ul">
<li>los gradientes,</li>
<li>los gradientes al cuadrado,</li>
</ul></li>
<li>adapta la tasa de aprendizaje para cada parámetro.</li>
</ul>

<p>
Esto suele producir:
</p>

<ul class="org-ul">
<li>convergencia rápida,</li>
<li>estabilidad numérica,</li>
<li>buen desempeño sin necesidad de mucha sintonía manual.</li>
</ul>
</div>
</div>
<div id="outline-container-org24820ea" class="outline-4">
<h4 id="org24820ea">Número máximo de iteraciones</h4>
<div class="outline-text-4" id="text-org24820ea">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">max_iter</span> = 1000
</pre>
</div>

<ul class="org-ul">
<li>Indica el número máximo de épocas (o iteraciones sobre los datos)
para entrenar la red.</li>
<li>Un valor alto permite que el modelo converja, aunque si es excesivo
puede aumentar el riesgo de <b>overfitting</b> (la red se ajusta demasiado
al entrenamiento).</li>
</ul>
</div>
</div>
<div id="outline-container-org57241e7" class="outline-4">
<h4 id="org57241e7">Reproducibilidad</h4>
<div class="outline-text-4" id="text-org57241e7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">random_state</span> = 42
</pre>
</div>

<ul class="org-ul">
<li>Fija la semilla para la inicialización de pesos y el muestreo interno.</li>
<li>Permite reproducir exactamente los mismos resultados entre ejecuciones.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org16c99ca" class="outline-3">
<h3 id="org16c99ca">Entrenamiento del modelo</h3>
<div class="outline-text-3" id="text-org16c99ca">
<p>
Entrenamos el MLP ajustando pesos y sesgos para minimizar el error de
clasificación en el conjunto de entrenamiento:
</p>

<div class="org-src-container">
<pre class="src src-python">mlp.fit<span style="color: #fe8019;">(</span>X_train, y_train<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
<div id="outline-container-orga737dff" class="outline-4">
<h4 id="orga737dff">Proceso interno (visión conceptual)</h4>
<div class="outline-text-4" id="text-orga737dff">
<ol class="org-ol">
<li><b>Propagación hacia adelante</b>:
<ul class="org-ul">
<li>Cada muestra \(\mathbf{x}\) pasa por las capas:
\[
       \mathbf{h}^{(1)} = f_1(W^{(1)} \mathbf{x} + \mathbf{b}^{(1)})
     \]
\[
       \mathbf{h}^{(2)} = f_2(W^{(2)} \mathbf{h}^{(1)} + \mathbf{b}^{(2)})
     \]
\[
       \hat{y} = \sigma(W^{(3)} \mathbf{h}^{(2)} + \mathbf{b}^{(3)})
     \]</li>
<li>\(\hat{y}\) es la probabilidad estimada de que el tumor sea benigno
(clase 1).</li>
</ul></li>

<li><b>Cálculo del error</b>:
<ul class="org-ul">
<li>La salida \(\hat{y}\) se compara con la etiqueta real \(y \in \{0, 1\}\).</li>
<li>En problemas binarios, se usa típicamente la <b>entropía cruzada
binaria</b> (o log-loss):
\[
       L(y, \hat{y}) = -\left[y \log(\hat{y}) + (1 - y)\log(1 - \hat{y})\right]
     \]</li>
</ul></li>

<li><b>Backpropagation</b>:
<ul class="org-ul">
<li>Se calculan las derivadas parciales de la pérdida con respecto a
todos los pesos y sesgos mediante la regla de la cadena.</li>
<li>Se propaga el error desde la capa de salida hacia las capas
ocultas.</li>
</ul></li>

<li><b>Actualización de pesos</b>:
<ul class="org-ul">
<li>El optimizador Adam actualiza cada parámetro en la dirección que
reduce la pérdida:
\[
       \theta \leftarrow \theta - \eta \cdot \hat{g}
     \]
donde \(\hat{g}\) es una versión adaptada del gradiente, y
\(\eta\) la tasa de aprendizaje efectiva.</li>
</ul></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org72e3b1e" class="outline-3">
<h3 id="org72e3b1e">Evaluación del modelo</h3>
<div class="outline-text-3" id="text-org72e3b1e">
<p>
Una vez entrenado, evaluamos el modelo sobre el conjunto de prueba:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #928374;"># </span><span style="color: #928374;">Predicci&#243;n
</span><span style="color: #83a598;">y_pred</span> = mlp.predict<span style="color: #fe8019;">(</span>X_test<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">M&#233;tricas
</span><span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Accuracy:"</span>, accuracy_score<span style="color: #b16286;">(</span>y_test, y_pred<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">Reporte de clasificaci&#243;n:</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>classification_report<span style="color: #b16286;">(</span>y_test, y_pred, target_names=data.target_names<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
<div id="outline-container-org383afd9" class="outline-4">
<h4 id="org383afd9">Métricas principales</h4>
<div class="outline-text-4" id="text-org383afd9">
<ul class="org-ul">
<li><b>Accuracy</b>:
<ul class="org-ul">
<li>Proporción de predicciones correctas:
\[
      \text{Accuracy} = \frac{\text{número de aciertos}}{\text{número total de muestras}}
    \]</li>
</ul></li>
<li><b>Precision</b>:
<ul class="org-ul">
<li>De todos los ejemplos predichos como positivos, qué fracción son
realmente positivos.</li>
<li>Importante para evitar falsos positivos.</li>
</ul></li>

<li><b>Recall (Sensibilidad)</b>:
<ul class="org-ul">
<li>De todos los ejemplos realmente positivos, qué fracción se detecta
correctamente.</li>
<li>En diagnóstico médico, el recall para la clase “maligno” es crítico
(minimizar falsos negativos).</li>
</ul></li>

<li><b>F1-score</b>:
<ul class="org-ul">
<li>Media armónica de precision y recall:
\[
      F1 = 2 \cdot \frac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}
    \]</li>
<li>Útil cuando hay cierto desbalance entre clases.</li>
</ul></li>
</ul>

<p>
El dataset Breast Cancer suele producir <b>accuracy</b> muy altas (por
encima de 95 %) con modelos bien entrenados, debido a que las
características están relativamente bien separadas.
</p>
</div>
</div>
</div>
<div id="outline-container-org2933617" class="outline-3">
<h3 id="org2933617">Interpretación matemática de la salida binaria</h3>
<div class="outline-text-3" id="text-org2933617">
<p>
En este modelo binario, la capa de salida puede verse como una neurona
con activación <b>sigmoide (logística)</b>:
</p>

<div class="latex" id="orgd660712">
<p>
&sigma;(z) = \frac{1}{1 + e<sup>-z</sup>}
</p>

</div>

<p>
donde:
</p>

<ul class="org-ul">
<li>\(z = \mathbf{w} \cdot \mathbf{h} + b\),</li>
<li>\(\mathbf{h}\) es el vector de activaciones de la última capa oculta.</li>
</ul>

<p>
La salida \(\sigma(z)\) se interpreta como:
</p>

<ul class="org-ul">
<li>\(\sigma(z) \approx 1\): alta probabilidad de clase 1 (benigno),</li>
<li>\(\sigma(z) \approx 0\): alta probabilidad de clase 0 (maligno).</li>
</ul>

<p>
En scikit-learn, la predicción de clase se realiza típicamente como:
</p>

<ul class="org-ul">
<li>Si \(\sigma(z) \geq 0.5\) → clase 1 (benigno).</li>
<li>Si \(\sigma(z) < 0.5\) → clase 0 (maligno).</li>
</ul>

<p>
Este umbral puede modificarse en contextos médicos, por ejemplo:
</p>

<ul class="org-ul">
<li>usar un umbral menor que 0.5 para aumentar la sensibilidad a tumores
malignos (aceptando más falsos positivos).</li>
</ul>
</div>
</div>
<div id="outline-container-orgb59e385" class="outline-3">
<h3 id="orgb59e385">Predicción de una nueva muestra</h3>
<div class="outline-text-3" id="text-orgb59e385">
<p>
Podemos usar el modelo entrenado para predecir el diagnóstico de un
nuevo paciente.
</p>

<p>
En este ejemplo, tomamos la primera muestra del set de prueba (ya
normalizada) y realizamos la predicción:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #928374;"># </span><span style="color: #928374;">Ejemplo con la primera fila del set de prueba
</span><span style="color: #83a598;">nuevo_paciente</span> = X_test<span style="color: #fe8019;">[</span>0:1<span style="color: #fe8019;">]</span>     <span style="color: #928374;"># </span><span style="color: #928374;">forma (1, 30)
</span><span style="color: #83a598;">pred</span> = mlp.predict<span style="color: #fe8019;">(</span>nuevo_paciente<span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Resultado del diagn&#243;stico:"</span>, data.target_names<span style="color: #b16286;">[</span>pred<span style="color: #b8bb26;">[</span>0<span style="color: #b8bb26;">]</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
<div id="outline-container-org23aa0ee" class="outline-4">
<h4 id="org23aa0ee">Comentarios importantes</h4>
<div class="outline-text-4" id="text-org23aa0ee">
<ul class="org-ul">
<li>Es fundamental que la nueva muestra haya sido procesada con el mismo:

<ol class="org-ol">
<li>Conjunto de características (mismas columnas y orden).</li>
<li>Mismo procedimiento de normalización (mismo <code>scaler</code>, con las
medias y desviaciones aprendidas en el entrenamiento).</li>
</ol></li>

<li>En la práctica, se suele:

<ul class="org-ul">
<li>guardar el modelo entrenado (por ejemplo con <code>joblib</code>),</li>
<li>guardar también el objeto <code>StandardScaler</code>,</li>
<li>aplicar ambos de manera coherente a los nuevos datos.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5b3b989" class="outline-3">
<h3 id="org5b3b989">Resumen conceptual</h3>
<div class="outline-text-3" id="text-org5b3b989">
<p>
Este ejemplo ilustra varios conceptos clave en el uso de redes
neuronales (MLP) para clasificación binaria en un contexto médico:
</p>

<ul class="org-ul">
<li>Importancia de:
<ul class="org-ul">
<li>Partición entrenamiento/prueba estratificada.</li>
<li>Normalización de características.</li>
<li>Arquitectura de red (capas y neuronas).</li>
<li>Función de activación (ReLU).</li>
<li>Optimizador (Adam) y número de iteraciones.</li>
</ul></li>

<li>Interpretación de la salida:
<ul class="org-ul">
<li>Probabilidad generada por una función sigmoide.</li>
<li>Decisión de clase basada en un umbral.</li>
</ul></li>

<li>Evaluación:
<ul class="org-ul">
<li>No basta con accuracy: hay que considerar precision, recall y F1,
especialmente para la clase de interés (por ejemplo, “maligno”).</li>
</ul></li>
</ul>

<p>
Este mismo flujo (carga, partición, normalización, definición de modelo,
entrenamiento, evaluación, predicción) puede adaptarse a otros modelos
(árboles, SVM, LSTM, etc.) y a otros datasets de clasificación binaria
o multiclase.
</p>
</div>
</div>
</div>
<div id="outline-container-org71f1a3e" class="outline-2">
<h2 id="org71f1a3e">Juego de Bala y Salto con MLP</h2>
<div class="outline-text-2" id="text-org71f1a3e">
</div>
<div id="outline-container-orge715c10" class="outline-3">
<h3 id="orge715c10">Introducción</h3>
<div class="outline-text-3" id="text-orge715c10">
</div>
<div id="outline-container-org152d922" class="outline-4">
<h4 id="org152d922">¿Qué es este juego?</h4>
<div class="outline-text-4" id="text-org152d922">
<p>
Este es un juego que combina mecánicas de juego simples con
aprendizaje automático (Machine Learning). El objetivo es entrenar una
red neuronal (MLP - Multi-Layer Perceptron) para que aprenda a jugar
imitando tu estilo de juego.
</p>
</div>
</div>
<div id="outline-container-org524dc9e" class="outline-4">
<h4 id="org524dc9e">Concepto principal</h4>
<div class="outline-text-4" id="text-org524dc9e">
<ul class="org-ul">
<li>Tú juegas en modo MANUAL y el juego registra tus decisiones.</li>
<li>El modelo MLP aprende de tus patrones de juego.</li>
<li>En modo AUTO, el MLP juega por ti usando lo que aprendió.</li>
</ul>
</div>
</div>
<div id="outline-container-org92cde8f" class="outline-4">
<h4 id="org92cde8f">Objetivo del juego</h4>
<div class="outline-text-4" id="text-org92cde8f">
<p>
Esquivar las balas que vienen desde la derecha saltando en el momento adecuado. El MLP aprende cuándo saltar basándose en:
</p>
<ul class="org-ul">
<li>La velocidad de la bala</li>
<li>La distancia entre el jugador y la bala</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org13d5d50" class="outline-3">
<h3 id="org13d5d50">Requisitos e Instalación</h3>
<div class="outline-text-3" id="text-org13d5d50">
</div>
<div id="outline-container-org3d87e59" class="outline-4">
<h4 id="org3d87e59">Dependencias necesarias</h4>
<div class="outline-text-4" id="text-org3d87e59">
<p>
El juego requiere las siguientes librerías de Python:
</p>

<div class="org-src-container">
<pre class="src src-python">pygame &gt;= 2.6.0
scikit-learn &gt;= 1.0.0
matplotlib &gt;= 3.5.0
numpy &gt;= 1.21.0
</pre>
</div>
</div>
</div>
<div id="outline-container-orgbffb2cf" class="outline-4">
<h4 id="orgbffb2cf">Instalación</h4>
<div class="outline-text-4" id="text-orgbffb2cf">
<div class="org-src-container">
<pre class="src src-bash">pip install pygame scikit-learn matplotlib numpy
</pre>
</div>
</div>
</div>
<div id="outline-container-org7aa224c" class="outline-4">
<h4 id="org7aa224c">Estructura de archivos</h4>
<div class="outline-text-4" id="text-org7aa224c">
<p>
El proyecto contiene:
</p>

<dl class="org-dl">
<dt><code>juego_pygame_mlp.py</code></dt><dd>Juego principal con MLP</dd>
<dt><code>juego_pygame_mlp_plot.py</code></dt><dd>Script para visualizar datos del CSV</dd>
<dt><code>datos_mlp.csv</code></dt><dd>Datos exportados (se genera al usar la opción C)</dd>
<dt><code>assets/</code></dt><dd>Carpeta con sprites y fondos del juego</dd>
</dl>
</div>
</div>
</div>
<div id="outline-container-org27f95ba" class="outline-3">
<h3 id="org27f95ba">Cómo Jugar</h3>
<div class="outline-text-3" id="text-org27f95ba">
</div>
<div id="outline-container-org3ee1a2b" class="outline-4">
<h4 id="org3ee1a2b">Iniciar el juego</h4>
<div class="outline-text-4" id="text-org3ee1a2b">
<div class="org-src-container">
<pre class="src src-bash">python juego_pygame_mlp.py
</pre>
</div>
</div>
</div>
<div id="outline-container-org0c69b59" class="outline-4">
<h4 id="org0c69b59">Menú principal</h4>
<div class="outline-text-4" id="text-org0c69b59">
<p>
Al iniciar verás un menú con las siguientes opciones:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Tecla</th>
<th scope="col" class="org-left">Acción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">M</td>
<td class="org-left">Modo Manual (reinicia dataset y borra modelo)</td>
</tr>

<tr>
<td class="org-left">A</td>
<td class="org-left">Modo Auto (usa MLP; sin modelo NO salta)</td>
</tr>

<tr>
<td class="org-left">T</td>
<td class="org-left">Entrenar MLP</td>
</tr>

<tr>
<td class="org-left">C</td>
<td class="org-left">Exportar datos a CSV</td>
</tr>

<tr>
<td class="org-left">F</td>
<td class="org-left">Fullscreen (toggle)</td>
</tr>

<tr>
<td class="org-left">Q</td>
<td class="org-left">Salir</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-org8554341" class="outline-4">
<h4 id="org8554341">Controles durante el juego</h4>
<div class="outline-text-4" id="text-org8554341">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Tecla</th>
<th scope="col" class="org-left">Acción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">ESPACIO</td>
<td class="org-left">Saltar (solo en modo manual)</td>
</tr>

<tr>
<td class="org-left">ESC / P</td>
<td class="org-left">Volver al menú</td>
</tr>

<tr>
<td class="org-left">F</td>
<td class="org-left">Alternar pantalla completa</td>
</tr>

<tr>
<td class="org-left">Q</td>
<td class="org-left">Salir del juego</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="outline-container-org82be7ab" class="outline-3">
<h3 id="org82be7ab">Modo Manual: Recolectando Datos</h3>
<div class="outline-text-3" id="text-org82be7ab">
</div>
<div id="outline-container-org0ca9650" class="outline-4">
<h4 id="org0ca9650">¿Qué hace el modo manual?</h4>
<div class="outline-text-4" id="text-org0ca9650">
<p>
En modo manual, tú controlas al personaje y el juego registra automáticamente:
</p>
<ul class="org-ul">
<li>La velocidad de cada bala</li>
<li>La distancia entre el jugador y la bala</li>
<li>Si decidiste saltar (1) o no saltar (0) en cada frame</li>
</ul>
</div>
</div>
<div id="outline-container-org6c3e704" class="outline-4">
<h4 id="org6c3e704">Cómo jugar en modo manual</h4>
<div class="outline-text-4" id="text-org6c3e704">
<ol class="org-ol">
<li>Presiona <code>M</code> en el menú para entrar en modo manual</li>
<li>El juego se reinicia y borra cualquier modelo anterior</li>
<li>Juega normalmente usando ESPACIO para saltar</li>
<li>El juego registra tus decisiones en cada frame donde hay una bala activa</li>
</ol>
</div>
</div>
<div id="outline-container-org36bdcd5" class="outline-4">
<h4 id="org36bdcd5">Consejos para recolectar buenos datos</h4>
<div class="outline-text-4" id="text-org36bdcd5">
<ul class="org-ul">
<li>Juega de forma natural, como lo harías normalmente</li>
<li>Mezcla situaciones: a veces salta temprano, a veces tarde, a veces no saltes</li>
<li>Juega varias partidas para tener más datos</li>
<li>Intenta tener al menos 80+ muestras antes de entrenar (verás el contador en el menú)</li>
</ul>
</div>
</div>
<div id="outline-container-org3fd0398" class="outline-4">
<h4 id="org3fd0398">Registro de datos</h4>
<div class="outline-text-4" id="text-org3fd0398">
<p>
El juego registra datos en cada frame donde:
</p>
<ul class="org-ul">
<li>La bala está disparada</li>
<li>El jugador está en el suelo (para decisiones de salto)</li>
<li>O está en el aire (marcado como salto=1 durante todo el tiempo en el aire)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org98d0421" class="outline-3">
<h3 id="org98d0421">Entrenamiento del Modelo MLP</h3>
<div class="outline-text-3" id="text-org98d0421">
</div>
<div id="outline-container-org12fa1cc" class="outline-4">
<h4 id="org12fa1cc">¿Qué es un MLP?</h4>
<div class="outline-text-4" id="text-org12fa1cc">
<p>
MLP (Multi-Layer Perceptron) es un tipo de red neuronal artificial que:
</p>
<ul class="org-ul">
<li>Tiene capas ocultas entre la entrada y la salida</li>
<li>Puede aprender patrones no lineales</li>
<li>En este juego: aprende a predecir cuándo saltar basándose en velocidad y distancia</li>
</ul>
</div>
</div>
<div id="outline-container-org37c0128" class="outline-4">
<h4 id="org37c0128">Arquitectura del modelo</h4>
<div class="outline-text-4" id="text-org37c0128">
<p>
El MLP usado en este juego tiene:
</p>
<ul class="org-ul">
<li>Entrada: 2 características (velocidad<sub>bala</sub>, distancia)</li>
<li>Capas ocultas: (24, 12) neuronas</li>
<li>Salida: 1 neurona (probabilidad de salto: 0 o 1)</li>
<li>Activación: ReLU</li>
<li>Optimizador: Adam</li>
</ul>
</div>
</div>
<div id="outline-container-org37465a7" class="outline-4">
<h4 id="org37465a7">Cómo entrenar</h4>
<div class="outline-text-4" id="text-org37465a7">
<ol class="org-ol">
<li>Recolecta datos en modo manual (al menos 80 muestras)</li>
<li>Presiona <code>T</code> en el menú para entrenar</li>
<li>El modelo se entrena automáticamente:
<ul class="org-ul">
<li>Divide los datos en entrenamiento (80%) y prueba (20%)</li>
<li>Normaliza las características con StandardScaler</li>
<li>Entrena el MLP con hasta 3000 iteraciones</li>
</ul></li>
<li>Verás un mensaje con la precisión (accuracy) del modelo</li>
</ol>
</div>
</div>
<div id="outline-container-orge348a56" class="outline-4">
<h4 id="orge348a56">Casos especiales</h4>
<div class="outline-text-4" id="text-orge348a56">
<ul class="org-ul">
<li>Si tienes menos de 80 muestras: el entrenamiento fallará con un mensaje</li>
<li>Si solo tienes una clase (solo 0s o solo 1s): se crea un "modelo trivial" que siempre devuelve esa clase</li>
<li>Para un modelo útil: necesitas datos con ambas clases (0 y 1)</li>
</ul>
</div>
</div>
<div id="outline-container-org84721c1" class="outline-4">
<h4 id="org84721c1">Interpretando los resultados</h4>
<div class="outline-text-4" id="text-org84721c1">
<ul class="org-ul">
<li>Accuracy ≈ 0.5-0.6: El modelo no está aprendiendo bien, necesitas más datos variados</li>
<li>Accuracy ≈ 0.7-0.8: El modelo está aprendiendo, pero puede mejorar</li>
<li>Accuracy ≈ 0.8-0.9: Buen modelo, está capturando tus patrones</li>
<li>Accuracy &gt; 0.9: Excelente, el modelo imita muy bien tu estilo</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgec493b5" class="outline-3">
<h3 id="orgec493b5">Modo Auto: El MLP Juega Solo</h3>
<div class="outline-text-3" id="text-orgec493b5">
</div>
<div id="outline-container-org4205575" class="outline-4">
<h4 id="org4205575">¿Qué hace el modo auto?</h4>
<div class="outline-text-4" id="text-org4205575">
<p>
En modo auto, el MLP toma las decisiones de salto basándose en lo que aprendió de ti.
</p>
</div>
</div>
<div id="outline-container-org0baba3b" class="outline-4">
<h4 id="org0baba3b">Cómo activar modo auto</h4>
<div class="outline-text-4" id="text-org0baba3b">
<ol class="org-ol">
<li>Primero debes entrenar un modelo (presiona <code>T</code>)</li>
<li>Luego presiona <code>A</code> en el menú</li>
<li>El juego se reinicia y el MLP controla los saltos</li>
</ol>
</div>
</div>
<div id="outline-container-org087f401" class="outline-4">
<h4 id="org087f401">Visualización en tiempo real</h4>
<div class="outline-text-4" id="text-org087f401">
<p>
Mientras juegas en modo auto, verás en la esquina superior izquierda:
</p>
<dl class="org-dl">
<dt><code>proba_salto≈0.XX</code></dt><dd>La probabilidad que el modelo calcula de que debería saltar</dd>
</dl>
</div>
</div>
<div id="outline-container-org3ae4d01" class="outline-4">
<h4 id="org3ae4d01">Limitaciones del modo auto</h4>
<div class="outline-text-4" id="text-org3ae4d01">
<ul class="org-ul">
<li>Si no hay modelo entrenado, el modo auto no saltará nunca</li>
<li>El modelo solo puede hacer lo que aprendió de tus datos</li>
<li>Si tus datos son inconsistentes, el modelo también lo será</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgcb82d65" class="outline-3">
<h3 id="orgcb82d65">Exportación y Visualización de Datos</h3>
<div class="outline-text-3" id="text-orgcb82d65">
</div>
<div id="outline-container-org9125d21" class="outline-4">
<h4 id="org9125d21">Exportar a CSV</h4>
<div class="outline-text-4" id="text-org9125d21">
<ol class="org-ol">
<li>En el menú, presiona <code>C</code></li>
<li>Se crea/sobrescribe el archivo <code>datos_mlp.csv</code></li>
<li>El CSV contiene tres columnas:
<dl class="org-dl">
<dt><code>velocidad_bala</code></dt><dd>Velocidad de la bala (negativa, en píxeles/frame)</dd>
<dt><code>distancia</code></dt><dd>Distancia entre jugador y bala (en píxeles)</dd>
<dt><code>salto</code></dt><dd>1 si saltaste, 0 si no saltaste</dd>
</dl></li>
</ol>
</div>
</div>
<div id="outline-container-org9425b97" class="outline-4">
<h4 id="org9425b97">Visualizar los datos</h4>
<div class="outline-text-4" id="text-org9425b97">
<p>
Para ver gráficas de tus datos:
</p>

<div class="org-src-container">
<pre class="src src-bash">python juego_pygame_mlp_plot.py
</pre>
</div>

<p>
Esto abre dos ventanas:
</p>
<ul class="org-ul">
<li>Gráfica 2D: Distancia vs Velocidad (colores: rojo=salto, azul=no salto)</li>
<li>Gráfica 3D: Distancia, Velocidad y Clase (0 abajo, 1 arriba)</li>
</ul>
</div>
</div>
<div id="outline-container-org29adcfc" class="outline-4">
<h4 id="org29adcfc">Interpretando las gráficas</h4>
<div class="outline-text-4" id="text-org29adcfc">
<ul class="org-ul">
<li>Si ves dos nubes bien separadas: tus datos son consistentes, el modelo debería aprender bien</li>
<li>Si las nubes están mezcladas: tus decisiones son más variadas, el modelo puede tener más dificultad</li>
<li>Si solo ves una nube: solo tienes una clase, necesitas más variedad en tus datos</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org1ef95ca" class="outline-3">
<h3 id="org1ef95ca">Arquitectura del Código</h3>
<div class="outline-text-3" id="text-org1ef95ca">
</div>
<div id="outline-container-org3cd0b95" class="outline-4">
<h4 id="org3cd0b95">Estructura principal</h4>
<div class="outline-text-4" id="text-org3cd0b95">
<p>
El código está organizado en una clase <code>Juego</code> con los siguientes módulos:
</p>

<dl class="org-dl">
<dt><code>__init__</code></dt><dd>Inicialización de pygame, ventana, estado del juego</dd>
<dt><code>_apply_resolution</code></dt><dd>Manejo de escalado y resolución</dd>
<dt><code>_cargar_assets</code></dt><dd>Carga de sprites e imágenes</dd>
<dt><code>_reset_estado_juego</code></dt><dd>Reinicia posiciones y estado</dd>
<dt><code>disparar_bala</code> / <code>reset_bala</code></dt><dd>Lógica de las balas</dd>
<dt><code>iniciar_salto</code> / <code>manejar_salto</code></dt><dd>Física del salto</dd>
<dt><code>registrar_decision_manual</code></dt><dd>Guarda datos mientras juegas</dd>
<dt><code>entrenar_modelo</code></dt><dd>Entrena el MLP con los datos recolectados</dd>
<dt><code>decision_auto_saltar</code></dt><dd>El MLP decide si saltar o no</dd>
<dt><code>mostrar_menu</code></dt><dd>Menú principal</dd>
<dt><code>loop</code></dt><dd>Bucle principal del juego</dd>
</dl>
</div>
</div>
<div id="outline-container-org16d0ca5" class="outline-4">
<h4 id="org16d0ca5">Clase Sample</h4>
<div class="outline-text-4" id="text-org16d0ca5">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fabd2f;">@dataclass</span>
<span style="color: #fb4934;">class</span> <span style="color: #fabd2f;">Sample</span>:
<span style="background-color: #3c3836;"> </span>   velocidad_bala: <span style="color: #fe8019;">float</span>
<span style="background-color: #3c3836;"> </span>   distancia: <span style="color: #fe8019;">float</span>
<span style="background-color: #3c3836;"> </span>   salto: <span style="color: #fe8019;">int</span>  <span style="color: #928374;"># </span><span style="color: #928374;">1 si salt&#243; EN ESE FRAME, 0 si no</span>
</pre>
</div>

<p>
Cada muestra representa una decisión en un frame específico.
</p>
</div>
</div>
<div id="outline-container-orgaef5915" class="outline-4">
<h4 id="orgaef5915">Flujo de datos</h4>
<div class="outline-text-4" id="text-orgaef5915">
<ol class="org-ol">
<li>Modo Manual:
<ul class="org-ul">
<li>Juegas → <code>registrar_decision_manual()</code> → <code>datos_modelo.append(Sample(...))</code></li>
</ul></li>

<li>Entrenamiento:
<ul class="org-ul">
<li><code>datos_modelo</code> → <code>entrenar_modelo()</code> → MLP entrenado guardado en <code>self.modelo</code></li>
</ul></li>

<li>Modo Auto:
<ul class="org-ul">
<li>Cada frame → <code>decision_auto_saltar()</code> → MLP predice → Salta o no salta</li>
</ul></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orga63029c" class="outline-3">
<h3 id="orga63029c">Parámetros Configurables</h3>
<div class="outline-text-3" id="text-orga63029c">
</div>
<div id="outline-container-org1bccb08" class="outline-4">
<h4 id="org1bccb08">Parámetros del juego</h4>
<div class="outline-text-4" id="text-org1bccb08">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Variable</th>
<th scope="col" class="org-right">Valor</th>
<th scope="col" class="org-left">Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><code>BASE_W, BASE_H</code></td>
<td class="org-right">1080, 720</td>
<td class="org-left">Tamaño base de la ventana</td>
</tr>

<tr>
<td class="org-left"><code>velocidad_bala</code></td>
<td class="org-right">-12 a -6</td>
<td class="org-left">Rango de velocidad de las balas</td>
</tr>

<tr>
<td class="org-left"><code>salto_vel_inicial</code></td>
<td class="org-right">15.0</td>
<td class="org-left">Velocidad inicial del salto</td>
</tr>

<tr>
<td class="org-left"><code>gravedad</code></td>
<td class="org-right">1.0</td>
<td class="org-left">Fuerza de gravedad</td>
</tr>

<tr>
<td class="org-left"><code>fondo_speed</code></td>
<td class="org-right">3</td>
<td class="org-left">Velocidad de desplazamiento del fondo</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-orgc332bc3" class="outline-4">
<h4 id="orgc332bc3">Parámetros del MLP</h4>
<div class="outline-text-4" id="text-orgc332bc3">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Variable</th>
<th scope="col" class="org-left">Valor</th>
<th scope="col" class="org-left">Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><code>hidden_layer_sizes</code></td>
<td class="org-left">(24, 12)</td>
<td class="org-left">Neuronas en cada capa oculta</td>
</tr>

<tr>
<td class="org-left"><code>activation</code></td>
<td class="org-left">"relu"</td>
<td class="org-left">Función de activación</td>
</tr>

<tr>
<td class="org-left"><code>solver</code></td>
<td class="org-left">"adam"</td>
<td class="org-left">Algoritmo de optimización</td>
</tr>

<tr>
<td class="org-left"><code>max_iter</code></td>
<td class="org-left">3000</td>
<td class="org-left">Máximo de iteraciones de entrenamiento</td>
</tr>

<tr>
<td class="org-left"><code>test_size</code></td>
<td class="org-left">0.2</td>
<td class="org-left">20% de los datos para prueba</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-org3781b79" class="outline-4">
<h4 id="org3781b79">Parámetros de registro</h4>
<div class="outline-text-4" id="text-org3781b79">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Variable</th>
<th scope="col" class="org-right">Valor</th>
<th scope="col" class="org-left">Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><code>decision_window</code></td>
<td class="org-right">500</td>
<td class="org-left">Ventana de decisión (ya no se usa, registra todo)</td>
</tr>

<tr>
<td class="org-left"><code>min_samples</code></td>
<td class="org-right">80</td>
<td class="org-left">Mínimo de muestras para entrenar</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="outline-container-org7c78b18" class="outline-3">
<h3 id="org7c78b18">Mejores Prácticas</h3>
<div class="outline-text-3" id="text-org7c78b18">
</div>
<div id="outline-container-orgf150d15" class="outline-4">
<h4 id="orgf150d15">Recolectando datos de calidad</h4>
<div class="outline-text-4" id="text-orgf150d15">
<ul class="org-ul">
<li>Juega varias partidas (no solo una)</li>
<li>Varía tu estilo: a veces conservador, a veces agresivo</li>
<li>Asegúrate de tener ejemplos de ambas clases (saltos y no-saltos)</li>
<li>Recolecta al menos 200-300 muestras para un modelo robusto</li>
</ul>
</div>
</div>
<div id="outline-container-orgdc25001" class="outline-4">
<h4 id="orgdc25001">Entrenando el modelo</h4>
<div class="outline-text-4" id="text-orgdc25001">
<ul class="org-ul">
<li>Siempre revisa el accuracy: si es muy bajo (&lt;0.6), recolecta más datos</li>
<li>Si el accuracy es perfecto (1.0), puede ser sobreajuste: prueba con más datos de prueba</li>
<li>Exporta el CSV y visualiza los datos para ver si hay patrones claros</li>
</ul>
</div>
</div>
<div id="outline-container-orgf00d02b" class="outline-4">
<h4 id="orgf00d02b">Jugando en modo auto</h4>
<div class="outline-text-4" id="text-orgf00d02b">
<ul class="org-ul">
<li>Observa la probabilidad en tiempo real (<code>proba_salto≈XX</code>)</li>
<li>Si el modelo nunca salta o siempre salta, revisa tus datos</li>
<li>Compara el comportamiento del modelo con cómo tú jugarías</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org05f7242" class="outline-3">
<h3 id="org05f7242">Solución de Problemas</h3>
<div class="outline-text-3" id="text-org05f7242">
</div>
<div id="outline-container-org0c10d19" class="outline-4">
<h4 id="org0c10d19">El modelo no aprende (accuracy &lt; 0.5)</h4>
<div class="outline-text-4" id="text-org0c10d19">
<ul class="org-ul">
<li>Posibles causas:
<ul class="org-ul">
<li>Datos insuficientes (&lt; 80 muestras)</li>
<li>Solo una clase en los datos (solo 0s o solo 1s)</li>
<li>Datos muy inconsistentes o aleatorios</li>
</ul></li>
<li>Solución:
<ul class="org-ul">
<li>Recolecta más datos variados</li>
<li>Asegúrate de tener ejemplos de ambas clases</li>
<li>Juega de forma más consistente</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org82515a1" class="outline-4">
<h4 id="org82515a1">El modo auto no salta nunca</h4>
<div class="outline-text-4" id="text-org82515a1">
<ul class="org-ul">
<li>Verifica que el modelo esté entrenado (<code>Modelo: sí</code> en el menú)</li>
<li>Si el modelo es trivial de clase 0, siempre dirá "no saltar"</li>
<li>Solución: recolecta datos donde sí saltas y reentrena</li>
</ul>
</div>
</div>
<div id="outline-container-org21ad150" class="outline-4">
<h4 id="org21ad150">El modo auto salta demasiado</h4>
<div class="outline-text-4" id="text-org21ad150">
<ul class="org-ul">
<li>El modelo aprendió que siempre debes saltar</li>
<li>Solución: recolecta más datos donde NO saltas y reentrena</li>
</ul>
</div>
</div>
<div id="outline-container-org6f04c16" class="outline-4">
<h4 id="org6f04c16">Las gráficas no se muestran</h4>
<div class="outline-text-4" id="text-org6f04c16">
<ul class="org-ul">
<li>Verifica que tengas <code>matplotlib</code> instalado</li>
<li>Verifica que el CSV tenga datos válidos</li>
<li>Ejecuta <code>juego_pygame_mlp_plot.py</code> desde la terminal</li>
</ul>
</div>
</div>
<div id="outline-container-org6da0f21" class="outline-4">
<h4 id="org6da0f21">El juego se ve lento o con lag</h4>
<div class="outline-text-4" id="text-org6da0f21">
<ul class="org-ul">
<li>Reduce los FPS en <code>reloj.tick(45)</code> a un valor menor (ej: 30)</li>
<li>Cierra otras aplicaciones que consuman recursos</li>
<li>Verifica que tu sistema tenga aceleración gráfica habilitada</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org70e46b7" class="outline-3">
<h3 id="org70e46b7">Conceptos Técnicos Avanzados</h3>
<div class="outline-text-3" id="text-org70e46b7">
</div>
<div id="outline-container-org504f3b5" class="outline-4">
<h4 id="org504f3b5">¿Por qué MLP y no otro algoritmo?</h4>
<div class="outline-text-4" id="text-org504f3b5">
<ul class="org-ul">
<li>MLP puede aprender patrones no lineales (la relación velocidad-distancia-salto no es lineal)</li>
<li>Es relativamente simple y rápido de entrenar</li>
<li>Funciona bien con pocas características (solo 2 en este caso)</li>
</ul>
</div>
</div>
<div id="outline-container-org753a247" class="outline-4">
<h4 id="org753a247">Normalización (StandardScaler)</h4>
<div class="outline-text-4" id="text-org753a247">
<p>
Las características se normalizan porque:
</p>
<ul class="org-ul">
<li>La velocidad de la bala y la distancia tienen escalas muy diferentes</li>
<li>El MLP funciona mejor con datos normalizados</li>
<li>Ayuda a que el entrenamiento converja más rápido</li>
</ul>
</div>
</div>
<div id="outline-container-orgad31a25" class="outline-4">
<h4 id="orgad31a25">División train/test</h4>
<div class="outline-text-4" id="text-orgad31a25">
<ul class="org-ul">
<li>80% entrenamiento, 20% prueba</li>
<li>Estratificado (<code>stratify=y</code>) para mantener proporción de clases</li>
<li>El accuracy en test es más confiable que en entrenamiento</li>
</ul>
</div>
</div>
<div id="outline-container-org7690aa4" class="outline-4">
<h4 id="org7690aa4">Overfitting y Underfitting</h4>
<div class="outline-text-4" id="text-org7690aa4">
<ul class="org-ul">
<li>Overfitting: El modelo memoriza los datos de entrenamiento pero falla en nuevos datos</li>
<li>Underfitting: El modelo no aprende lo suficiente</li>
<li>En este juego: si accuracy test &lt;&lt; accuracy train → overfitting</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org355b6df" class="outline-3">
<h3 id="org355b6df">Código de Ejemplo</h3>
<div class="outline-text-3" id="text-org355b6df">
</div>
<div id="outline-container-org697a364" class="outline-4">
<h4 id="org697a364">Cargar y visualizar datos manualmente</h4>
<div class="outline-text-4" id="text-org697a364">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> csv
<span style="color: #fb4934;">import</span> matplotlib.pyplot <span style="color: #fb4934;">as</span> plt

<span style="color: #928374;"># </span><span style="color: #928374;">Cargar CSV
</span><span style="color: #83a598;">xs</span>, <span style="color: #83a598;">ys</span>, <span style="color: #83a598;">cs</span> = <span style="color: #fe8019;">[]</span>, <span style="color: #fe8019;">[]</span>, <span style="color: #fe8019;">[]</span>
<span style="color: #fb4934;">with</span> <span style="color: #fe8019;">open</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"datos_mlp.csv"</span>, <span style="color: #b8bb26;">"r"</span><span style="color: #fe8019;">)</span> <span style="color: #fb4934;">as</span> f:
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">reader</span> = csv.DictReader<span style="color: #fe8019;">(</span>f<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> row <span style="color: #fb4934;">in</span> reader:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   xs.append<span style="color: #fe8019;">(</span><span style="color: #fe8019;">float</span><span style="color: #b16286;">(</span>row<span style="color: #b8bb26;">[</span><span style="color: #b8bb26;">"distancia"</span><span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   ys.append<span style="color: #fe8019;">(</span><span style="color: #fe8019;">float</span><span style="color: #b16286;">(</span>row<span style="color: #b8bb26;">[</span><span style="color: #b8bb26;">"velocidad_bala"</span><span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   cs.append<span style="color: #fe8019;">(</span><span style="color: #fe8019;">int</span><span style="color: #b16286;">(</span>row<span style="color: #b8bb26;">[</span><span style="color: #b8bb26;">"salto"</span><span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Separar por clases
</span><span style="color: #83a598;">xs_0</span> = <span style="color: #fe8019;">[</span>x <span style="color: #fb4934;">for</span> x, c <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">zip</span><span style="color: #b16286;">(</span>xs, cs<span style="color: #b16286;">)</span> <span style="color: #fb4934;">if</span> c == 0<span style="color: #fe8019;">]</span>
<span style="color: #83a598;">ys_0</span> = <span style="color: #fe8019;">[</span>y <span style="color: #fb4934;">for</span> y, c <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">zip</span><span style="color: #b16286;">(</span>ys, cs<span style="color: #b16286;">)</span> <span style="color: #fb4934;">if</span> c == 0<span style="color: #fe8019;">]</span>
<span style="color: #83a598;">xs_1</span> = <span style="color: #fe8019;">[</span>x <span style="color: #fb4934;">for</span> x, c <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">zip</span><span style="color: #b16286;">(</span>xs, cs<span style="color: #b16286;">)</span> <span style="color: #fb4934;">if</span> c == 1<span style="color: #fe8019;">]</span>
<span style="color: #83a598;">ys_1</span> = <span style="color: #fe8019;">[</span>y <span style="color: #fb4934;">for</span> y, c <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">zip</span><span style="color: #b16286;">(</span>ys, cs<span style="color: #b16286;">)</span> <span style="color: #fb4934;">if</span> c == 1<span style="color: #fe8019;">]</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Graficar
</span>plt.scatter<span style="color: #fe8019;">(</span>xs_0, ys_0, c=<span style="color: #b8bb26;">"blue"</span>, label=<span style="color: #b8bb26;">"No salto"</span><span style="color: #fe8019;">)</span>
plt.scatter<span style="color: #fe8019;">(</span>xs_1, ys_1, c=<span style="color: #b8bb26;">"red"</span>, label=<span style="color: #b8bb26;">"Salto"</span><span style="color: #fe8019;">)</span>
plt.xlabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Distancia"</span><span style="color: #fe8019;">)</span>
plt.ylabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Velocidad"</span><span style="color: #fe8019;">)</span>
plt.legend<span style="color: #fe8019;">()</span>
plt.show<span style="color: #fe8019;">()</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org593659f" class="outline-4">
<h4 id="org593659f">Entrenar modelo desde CSV</h4>
<div class="outline-text-4" id="text-org593659f">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> sklearn.neural_network <span style="color: #fb4934;">import</span> MLPClassifier
<span style="color: #fb4934;">from</span> sklearn.preprocessing <span style="color: #fb4934;">import</span> StandardScaler
<span style="color: #fb4934;">import</span> csv

<span style="color: #928374;"># </span><span style="color: #928374;">Cargar datos
</span><span style="color: #83a598;">X</span>, <span style="color: #83a598;">y</span> = <span style="color: #fe8019;">[]</span>, <span style="color: #fe8019;">[]</span>
<span style="color: #fb4934;">with</span> <span style="color: #fe8019;">open</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"datos_mlp.csv"</span>, <span style="color: #b8bb26;">"r"</span><span style="color: #fe8019;">)</span> <span style="color: #fb4934;">as</span> f:
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">reader</span> = csv.DictReader<span style="color: #fe8019;">(</span>f<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> row <span style="color: #fb4934;">in</span> reader:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   X.append<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span><span style="color: #fe8019;">float</span><span style="color: #b8bb26;">(</span>row<span style="color: #83a598;">[</span><span style="color: #b8bb26;">"velocidad_bala"</span><span style="color: #83a598;">]</span><span style="color: #b8bb26;">)</span>, <span style="color: #fe8019;">float</span><span style="color: #b8bb26;">(</span>row<span style="color: #83a598;">[</span><span style="color: #b8bb26;">"distancia"</span><span style="color: #83a598;">]</span><span style="color: #b8bb26;">)</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   y.append<span style="color: #fe8019;">(</span><span style="color: #fe8019;">int</span><span style="color: #b16286;">(</span>row<span style="color: #b8bb26;">[</span><span style="color: #b8bb26;">"salto"</span><span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Normalizar
</span><span style="color: #83a598;">scaler</span> = StandardScaler<span style="color: #fe8019;">()</span>
<span style="color: #83a598;">X_scaled</span> = scaler.fit_transform<span style="color: #fe8019;">(</span>X<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Entrenar
</span><span style="color: #83a598;">modelo</span> = MLPClassifier<span style="color: #fe8019;">(</span>hidden_layer_sizes=<span style="color: #b16286;">(</span>24, 12<span style="color: #b16286;">)</span>, max_iter=3000<span style="color: #fe8019;">)</span>
modelo.fit<span style="color: #fe8019;">(</span>X_scaled, y<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Predecir
</span><span style="color: #83a598;">nueva_velocidad</span> = -8.5
<span style="color: #83a598;">nueva_distancia</span> = 250.0
<span style="color: #83a598;">X_nuevo</span> = scaler.transform<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span><span style="color: #b8bb26;">[</span>nueva_velocidad, nueva_distancia<span style="color: #b8bb26;">]</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="color: #83a598;">probabilidad</span> = modelo.predict_proba<span style="color: #fe8019;">(</span>X_nuevo<span style="color: #fe8019;">)[</span>0<span style="color: #fe8019;">][</span>1<span style="color: #fe8019;">]</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Probabilidad de salto: </span>{probabilidad:.2f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-orge9b21eb" class="outline-2">
<h2 id="orge9b21eb">Métricas de Evaluación para Machine Learning</h2>
<div class="outline-text-2" id="text-orge9b21eb">
</div>
<div id="outline-container-org4ad9e76" class="outline-3">
<h3 id="org4ad9e76">Introducción</h3>
<div class="outline-text-3" id="text-org4ad9e76">
</div>
<div id="outline-container-org9305658" class="outline-4">
<h4 id="org9305658">¿Qué son las métricas de evaluación?</h4>
<div class="outline-text-4" id="text-org9305658">
<p>
Las métricas de evaluación son medidas numéricas que nos permiten cuantificar qué tan bien está funcionando un modelo de Machine Learning. Nos ayudan a:
</p>
<ul class="org-ul">
<li>Comparar diferentes modelos</li>
<li>Entender las fortalezas y debilidades del modelo</li>
<li>Decidir si un modelo es útil para nuestro problema</li>
<li>Detectar problemas como sobreajuste o sesgo</li>
</ul>
</div>
</div>
<div id="outline-container-org1e48330" class="outline-4">
<h4 id="org1e48330">¿Por qué son importantes?</h4>
<div class="outline-text-4" id="text-org1e48330">
<p>
Un modelo puede tener un accuracy alto pero aún así tener problemas graves. Por ejemplo:
</p>
<ul class="org-ul">
<li>Un modelo que siempre predice "no salto" tendría 90% accuracy si el 90% de los casos son "no salto"</li>
<li>Pero sería inútil porque nunca saltaría cuando debería</li>
</ul>

<p>
Las métricas nos ayudan a detectar estos problemas.
</p>
</div>
</div>
</div>
<div id="outline-container-org1ce3a0e" class="outline-3">
<h3 id="org1ce3a0e">Matriz de Confusión: La Base de Todo</h3>
<div class="outline-text-3" id="text-org1ce3a0e">
</div>
<div id="outline-container-orgebc2286" class="outline-4">
<h4 id="orgebc2286">¿Qué es una matriz de confusión?</h4>
<div class="outline-text-4" id="text-orgebc2286">
<p>
La matriz de confusión es una tabla que muestra cómo se clasificaron las predicciones del modelo comparadas con los valores reales.
</p>
</div>
</div>
<div id="outline-container-org1fc891c" class="outline-4">
<h4 id="org1fc891c">Estructura de la matriz (2 clases)</h4>
<div class="outline-text-4" id="text-org1fc891c">
<p>
Para un problema de clasificación binaria (como nuestro juego: salto=1, no salto=0):
</p>

<pre class="example" id="org2368cb7">
                    Predicción
                 No Salto  Salto
Real  No Salto     TN      FP
      Salto        FN      TP
</pre>

<p>
Donde:
</p>
<ul class="org-ul">
<li><code>TP</code> (True Positive): Predijo salto y era salto ✓</li>
<li><code>TN</code> (True Negative): Predijo no salto y era no salto ✓</li>
<li><code>FP</code> (False Positive): Predijo salto pero era no salto ✗</li>
<li><code>FN</code> (False Negative): Predijo no salto pero era salto ✗</li>
</ul>
</div>
</div>
<div id="outline-container-org97b91fd" class="outline-4">
<h4 id="org97b91fd">Interpretación en el contexto del juego</h4>
<div class="outline-text-4" id="text-org97b91fd">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Caso</th>
<th scope="col" class="org-left">Significado en el juego</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">TP</td>
<td class="org-left">El modelo saltó y era correcto hacerlo</td>
</tr>

<tr>
<td class="org-left">TN</td>
<td class="org-left">El modelo no saltó y era correcto no saltar</td>
</tr>

<tr>
<td class="org-left">FP</td>
<td class="org-left">El modelo saltó innecesariamente (gasto de salto)</td>
</tr>

<tr>
<td class="org-left">FN</td>
<td class="org-left">El modelo NO saltó cuando debería haber saltado (¡colisión!)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-org3e1c3ed" class="outline-4">
<h4 id="org3e1c3ed">Ejemplo práctico</h4>
<div class="outline-text-4" id="text-org3e1c3ed">
<p>
Supongamos que el modelo hizo 100 predicciones:
</p>

<pre class="example" id="org3e39daa">
                    Predicción
                 No Salto  Salto  Total
Real  No Salto      70      10     80
      Salto          5      15     20
      Total          75      25    100
</pre>

<ul class="org-ul">
<li>TP = 15 (saltó correctamente 15 veces)</li>
<li>TN = 70 (no saltó correctamente 70 veces)</li>
<li>FP = 10 (saltó innecesariamente 10 veces)</li>
<li>FN = 5 (no saltó cuando debía 5 veces → ¡5 colisiones!)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd7257bb" class="outline-3">
<h3 id="orgd7257bb">Accuracy (Precisión General)</h3>
<div class="outline-text-3" id="text-orgd7257bb">
</div>
<div id="outline-container-orged575be" class="outline-4">
<h4 id="orged575be">Definición</h4>
<div class="outline-text-4" id="text-orged575be">
<p>
Accuracy mide la proporción de predicciones correctas sobre el total:
</p>

<p>
\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} = \frac{\text{Predicciones correctas}}{\text{Total de predicciones}}
\]
</p>
</div>
</div>
<div id="outline-container-org037682a" class="outline-4">
<h4 id="org037682a">Cálculo del ejemplo anterior</h4>
<div class="outline-text-4" id="text-org037682a">
<p>
\[
\text{Accuracy} = \frac{15 + 70}{100} = \frac{85}{100} = 0.85 = 85\%
\]
</p>
</div>
</div>
<div id="outline-container-org358761b" class="outline-4">
<h4 id="org358761b">Ventajas</h4>
<div class="outline-text-4" id="text-org358761b">
<ul class="org-ul">
<li>Fácil de entender: "¿Qué porcentaje acertó?"</li>
<li>Útil cuando las clases están balanceadas</li>
<li>Buena métrica general para comparar modelos</li>
</ul>
</div>
</div>
<div id="outline-container-org83c5a06" class="outline-4">
<h4 id="org83c5a06">Desventajas</h4>
<div class="outline-text-4" id="text-org83c5a06">
<ul class="org-ul">
<li>Puede ser engañosa con clases desbalanceadas</li>
<li>No distingue entre tipos de errores</li>
<li>Un modelo que siempre predice la clase mayoritaria puede tener buen accuracy</li>
</ul>
</div>
</div>
<div id="outline-container-orgd04aa5e" class="outline-4">
<h4 id="orgd04aa5e">Ejemplo del problema</h4>
<div class="outline-text-4" id="text-orgd04aa5e">
<p>
Si en el juego el 90% de los casos son "no salto":
</p>
<ul class="org-ul">
<li>Un modelo que siempre dice "no salto" tendría 90% accuracy</li>
<li>Pero sería inútil porque nunca saltaría</li>
<li>Accuracy alto ≠ modelo bueno</li>
</ul>
</div>
</div>
<div id="outline-container-org3047b21" class="outline-4">
<h4 id="org3047b21">Cuándo usar Accuracy</h4>
<div class="outline-text-4" id="text-org3047b21">
<ul class="org-ul">
<li>Clases balanceadas (50-50 o similar)</li>
<li>Todos los errores tienen el mismo costo</li>
<li>Quieres una métrica simple y general</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org3e6f22e" class="outline-3">
<h3 id="org3e6f22e">Precision (Precisión)</h3>
<div class="outline-text-3" id="text-org3e6f22e">
</div>
<div id="outline-container-org6faf81f" class="outline-4">
<h4 id="org6faf81f">Definición</h4>
<div class="outline-text-4" id="text-org6faf81f">
<p>
Precision mide: "De todas las veces que predije salto, ¿cuántas eran correctas?"
</p>

<p>
\[
\text{Precision} = \frac{TP}{TP + FP} = \frac{\text{Verdaderos positivos}}{\text{Todos los positivos predichos}}
\]
</p>
</div>
</div>
<div id="outline-container-orgd2c416e" class="outline-4">
<h4 id="orgd2c416e">Cálculo del ejemplo</h4>
<div class="outline-text-4" id="text-orgd2c416e">
<p>
\[
\text{Precision} = \frac{15}{15 + 10} = \frac{15}{25} = 0.60 = 60\%
\]
</p>
</div>
</div>
<div id="outline-container-orgc9c755a" class="outline-4">
<h4 id="orgc9c755a">Interpretación</h4>
<div class="outline-text-4" id="text-orgc9c755a">
<ul class="org-ul">
<li>De las 25 veces que el modelo decidió saltar, solo 15 eran correctas</li>
<li>10 veces saltó innecesariamente (FP)</li>
<li>"Cuando el modelo dice que hay que saltar, ¿qué tan confiable es?"</li>
</ul>
</div>
</div>
<div id="outline-container-org32135d7" class="outline-4">
<h4 id="org32135d7">En el contexto del juego</h4>
<div class="outline-text-4" id="text-org32135d7">
<ul class="org-ul">
<li>Precision alta: Cuando el modelo decide saltar, casi siempre es correcto</li>
<li>Precision baja: El modelo salta demasiado, muchas veces innecesariamente</li>
<li>Costo: Saltos innecesarios no son críticos, pero desperdician recursos</li>
</ul>
</div>
</div>
<div id="outline-container-org0901f2e" class="outline-4">
<h4 id="org0901f2e">Cuándo es importante</h4>
<div class="outline-text-4" id="text-org0901f2e">
<ul class="org-ul">
<li>Los falsos positivos son costosos</li>
<li>Quieres minimizar acciones innecesarias</li>
<li>Ejemplo: Sistema de spam (no quieres marcar emails legítimos como spam)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc9c7b48" class="outline-3">
<h3 id="orgc9c7b48">Recall (Sensibilidad o Exhaustividad)</h3>
<div class="outline-text-3" id="text-orgc9c7b48">
</div>
<div id="outline-container-org2da609b" class="outline-4">
<h4 id="org2da609b">Definición</h4>
<div class="outline-text-4" id="text-org2da609b">
<p>
Recall mide: "De todos los casos donde realmente debía saltar, ¿cuántos detecté?"
</p>

<p>
\[
\text{Recall} = \frac{TP}{TP + FN} = \frac{\text{Verdaderos positivos}}{\text{Todos los positivos reales}}
\]
</p>
</div>
</div>
<div id="outline-container-orgfefe95e" class="outline-4">
<h4 id="orgfefe95e">Cálculo del ejemplo</h4>
<div class="outline-text-4" id="text-orgfefe95e">
<p>
\[
\text{Recall} = \frac{15}{15 + 5} = \frac{15}{20} = 0.75 = 75\%
\]
</p>
</div>
</div>
<div id="outline-container-org9b67850" class="outline-4">
<h4 id="org9b67850">Interpretación</h4>
<div class="outline-text-4" id="text-org9b67850">
<ul class="org-ul">
<li>De las 20 veces que realmente debía saltar, el modelo detectó 15</li>
<li>5 veces no saltó cuando debía (FN) → ¡5 colisiones!</li>
<li>"¿Qué porcentaje de las situaciones peligrosas detecta el modelo?"</li>
</ul>
</div>
</div>
<div id="outline-container-orgcd63016" class="outline-4">
<h4 id="orgcd63016">En el contexto del juego</h4>
<div class="outline-text-4" id="text-orgcd63016">
<ul class="org-ul">
<li>Recall alto: El modelo detecta casi todas las situaciones donde debe saltar</li>
<li>Recall bajo: El modelo se pierde muchas situaciones peligrosas → muchas colisiones</li>
<li>Costo: Falsos negativos son MUY costosos (colisiones = perder)</li>
</ul>
</div>
</div>
<div id="outline-container-org84adcf3" class="outline-4">
<h4 id="org84adcf3">Cuándo es crítico</h4>
<div class="outline-text-4" id="text-org84adcf3">
<ul class="org-ul">
<li>Los falsos negativos son muy costosos</li>
<li>Es mejor "sobre-detectar" que "sub-detectar"</li>
<li>Ejemplos: Detección de cáncer, detección de fraude, nuestro juego</li>
</ul>
</div>
</div>
<div id="outline-container-org4bd0c8e" class="outline-4">
<h4 id="org4bd0c8e">Trade-off Precision vs Recall</h4>
<div class="outline-text-4" id="text-org4bd0c8e">
<p>
Generalmente hay un trade-off:
</p>
<ul class="org-ul">
<li>Si aumentas el umbral de decisión → más Precision, menos Recall</li>
<li>Si disminuyes el umbral → más Recall, menos Precision</li>
</ul>

<p>
En el juego:
</p>
<ul class="org-ul">
<li>Umbral alto (0.7): Solo salta cuando está muy seguro → alta Precision, bajo Recall</li>
<li>Umbral bajo (0.3): Salta con más frecuencia → bajo Precision, alto Recall</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgdd7a2d2" class="outline-3">
<h3 id="orgdd7a2d2">F1-Score: El Balance Perfecto</h3>
<div class="outline-text-3" id="text-orgdd7a2d2">
</div>
<div id="outline-container-org518f7cd" class="outline-4">
<h4 id="org518f7cd">Definición</h4>
<div class="outline-text-4" id="text-org518f7cd">
<p>
F1-Score es la media armónica de Precision y Recall:
</p>

<p>
\[
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = \frac{2 \times TP}{2 \times TP + FP + FN}
\]
</p>
</div>
</div>
<div id="outline-container-org14461a6" class="outline-4">
<h4 id="org14461a6">Cálculo del ejemplo</h4>
<div class="outline-text-4" id="text-org14461a6">
<p>
\[
F1 = 2 \times \frac{0.60 \times 0.75}{0.60 + 0.75} = 2 \times \frac{0.45}{1.35} = 0.667 = 66.7\%
\]
</p>
</div>
</div>
<div id="outline-container-orge03020b" class="outline-4">
<h4 id="orge03020b">¿Por qué media armónica y no aritmética?</h4>
<div class="outline-text-4" id="text-orge03020b">
<p>
La media armónica penaliza más cuando una métrica es muy baja:
</p>
<ul class="org-ul">
<li>Si Precision = 0.1 y Recall = 0.9 → F1 = 0.18 (bajo)</li>
<li>Si Precision = 0.5 y Recall = 0.5 → F1 = 0.5 (mejor balance)</li>
</ul>
</div>
</div>
<div id="outline-container-org546072d" class="outline-4">
<h4 id="org546072d">Ventajas</h4>
<div class="outline-text-4" id="text-org546072d">
<ul class="org-ul">
<li>Balancea Precision y Recall</li>
<li>Útil cuando necesitas ambas métricas</li>
<li>No se ve afectado por clases desbalanceadas tanto como Accuracy</li>
</ul>
</div>
</div>
<div id="outline-container-orgcad701c" class="outline-4">
<h4 id="orgcad701c">Desventajas</h4>
<div class="outline-text-4" id="text-orgcad701c">
<ul class="org-ul">
<li>Puede ocultar problemas si una métrica es muy baja</li>
<li>No siempre es la métrica más importante</li>
</ul>
</div>
</div>
<div id="outline-container-org2e433dc" class="outline-4">
<h4 id="org2e433dc">Cuándo usar F1-Score</h4>
<div class="outline-text-4" id="text-org2e433dc">
<ul class="org-ul">
<li>Necesitas balance entre Precision y Recall</li>
<li>Las clases están desbalanceadas</li>
<li>Quieres una métrica única que considere ambos aspectos</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org187bf49" class="outline-3">
<h3 id="org187bf49">Especificidad</h3>
<div class="outline-text-3" id="text-org187bf49">
</div>
<div id="outline-container-orga14ec63" class="outline-4">
<h4 id="orga14ec63">Definición</h4>
<div class="outline-text-4" id="text-orga14ec63">
<p>
Especificidad mide: "De todos los casos donde NO debía saltar, ¿cuántos detecté correctamente?"
</p>

<p>
\[
\text{Especificidad} = \frac{TN}{TN + FP} = \frac{\text{Verdaderos negativos}}{\text{Todos los negativos reales}}
\]
</p>
</div>
</div>
<div id="outline-container-org0e19282" class="outline-4">
<h4 id="org0e19282">Cálculo del ejemplo</h4>
<div class="outline-text-4" id="text-org0e19282">
<p>
\[
\text{Especificidad} = \frac{70}{70 + 10} = \frac{70}{80} = 0.875 = 87.5\%
\]
</p>
</div>
</div>
<div id="outline-container-org9fc0481" class="outline-4">
<h4 id="org9fc0481">Interpretación</h4>
<div class="outline-text-4" id="text-org9fc0481">
<ul class="org-ul">
<li>De las 80 veces que NO debía saltar, el modelo acertó 70</li>
<li>10 veces saltó innecesariamente</li>
<li>Es el "Recall de la clase negativa"</li>
</ul>
</div>
</div>
<div id="outline-container-org57b6b08" class="outline-4">
<h4 id="org57b6b08">En el contexto del juego</h4>
<div class="outline-text-4" id="text-org57b6b08">
<ul class="org-ul">
<li>Especificidad alta: El modelo rara vez salta innecesariamente</li>
<li>Especificidad baja: El modelo salta demasiado cuando no es necesario</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org8f024a0" class="outline-3">
<h3 id="org8f024a0">Comparación de Métricas: Tabla Resumen</h3>
<div class="outline-text-3" id="text-org8f024a0">
</div>
<div id="outline-container-orgad3745f" class="outline-4">
<h4 id="orgad3745f">Valores del ejemplo</h4>
<div class="outline-text-4" id="text-orgad3745f">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Métrica</th>
<th scope="col" class="org-right">Valor</th>
<th scope="col" class="org-left">Interpretación</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Accuracy</td>
<td class="org-right">85%</td>
<td class="org-left">85 de cada 100 predicciones fueron correctas</td>
</tr>

<tr>
<td class="org-left">Precision</td>
<td class="org-right">60%</td>
<td class="org-left">De cada 10 saltos predichos, 6 eran correctos</td>
</tr>

<tr>
<td class="org-left">Recall</td>
<td class="org-right">75%</td>
<td class="org-left">De cada 10 situaciones peligrosas, detectó 7.5</td>
</tr>

<tr>
<td class="org-left">F1-Score</td>
<td class="org-right">66.7%</td>
<td class="org-left">Balance entre Precision y Recall</td>
</tr>

<tr>
<td class="org-left">Especificidad</td>
<td class="org-right">87.5%</td>
<td class="org-left">De cada 10 casos seguros, detectó 8.75 correctamente</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-org7b36f1d" class="outline-4">
<h4 id="org7b36f1d">¿Qué métrica usar?</h4>
<div class="outline-text-4" id="text-org7b36f1d">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Situación</th>
<th scope="col" class="org-left">Métrica recomendada</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Clases balanceadas, errores igual costo</td>
<td class="org-left">Accuracy</td>
</tr>

<tr>
<td class="org-left">Falsos positivos muy costosos</td>
<td class="org-left">Precision</td>
</tr>

<tr>
<td class="org-left">Falsos negativos muy costosos</td>
<td class="org-left">Recall</td>
</tr>

<tr>
<td class="org-left">Necesitas balance Precision/Recall</td>
<td class="org-left">F1-Score</td>
</tr>

<tr>
<td class="org-left">Clases muy desbalanceadas</td>
<td class="org-left">F1-Score o Recall</td>
</tr>

<tr>
<td class="org-left">Quieres ver todo el panorama</td>
<td class="org-left">Matriz de confusión + todas</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="outline-container-orgf93ae1d" class="outline-3">
<h3 id="orgf93ae1d">Casos de Uso en el Juego</h3>
<div class="outline-text-3" id="text-orgf93ae1d">
</div>
<div id="outline-container-org58294cb" class="outline-4">
<h4 id="org58294cb">Escenario 1: Modelo Conservador</h4>
<div class="outline-text-4" id="text-org58294cb">
<p>
Un modelo que casi nunca salta:
</p>

<pre class="example" id="org8a8f1a5">
                    Predicción
                 No Salto  Salto
Real  No Salto      75       5
      Salto         15       5
</pre>

<ul class="org-ul">
<li>Accuracy: 80% (80/100)</li>
<li>Precision: 50% (5/10) - Cuando salta, acierta la mitad</li>
<li>Recall: 25% (5/20) - Solo detecta 1 de cada 4 peligros → ¡MUCHAS COLISIONES!</li>
<li>F1: 33.3%</li>
</ul>

<p>
<b><b>Veredicto</b></b>: Mal modelo para el juego. Aunque tiene buen accuracy, tiene muy bajo Recall → muchas colisiones.
</p>
</div>
</div>
<div id="outline-container-orgc9eb7a7" class="outline-4">
<h4 id="orgc9eb7a7">Escenario 2: Modelo Agresivo</h4>
<div class="outline-text-4" id="text-orgc9eb7a7">
<p>
Un modelo que salta muy frecuentemente:
</p>

<pre class="example" id="org9b36fdc">
                    Predicción
                 No Salto  Salto
Real  No Salto      50      30
      Salto           2      18
</pre>

<ul class="org-ul">
<li>Accuracy: 68% (68/100)</li>
<li>Precision: 37.5% (18/48) - Muchos saltos innecesarios</li>
<li>Recall: 90% (18/20) - Detecta casi todos los peligros</li>
<li>F1: 53.3%</li>
</ul>

<p>
<b><b>Veredicto</b></b>: Mejor que el conservador. Aunque tiene muchos saltos innecesarios, evita casi todas las colisiones.
</p>
</div>
</div>
<div id="outline-container-orgff6c6df" class="outline-4">
<h4 id="orgff6c6df">Escenario 3: Modelo Balanceado (Ideal)</h4>
<div class="outline-text-4" id="text-orgff6c6df">
<p>
Un modelo bien entrenado:
</p>

<pre class="example" id="orgda871ac">
                    Predicción
                 No Salto  Salto
Real  No Salto      70      10
      Salto           3      17
</pre>

<ul class="org-ul">
<li>Accuracy: 87% (87/100)</li>
<li>Precision: 63% (17/27)</li>
<li>Recall: 85% (17/20) - Detecta la mayoría de peligros</li>
<li>F1: 72.3%</li>
</ul>

<p>
<b><b>Veredicto</b></b>: Buen modelo. Balance entre evitar colisiones y no saltar innecesariamente.
</p>
</div>
</div>
</div>
<div id="outline-container-orgf6543cc" class="outline-3">
<h3 id="orgf6543cc">Implementación en Python</h3>
<div class="outline-text-3" id="text-orgf6543cc">
</div>
<div id="outline-container-orgdba9236" class="outline-4">
<h4 id="orgdba9236">Cálculo manual de métricas</h4>
<div class="outline-text-4" id="text-orgdba9236">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

<span style="color: #928374;"># </span><span style="color: #928374;">Ejemplo con predicciones y valores reales
</span><span style="color: #83a598;">y_real</span> = <span style="color: #fe8019;">[</span>0, 0, 0, 1, 1, 1, 0, 1, 0, 1<span style="color: #fe8019;">]</span>
<span style="color: #83a598;">y_pred</span> = <span style="color: #fe8019;">[</span>0, 0, 1, 1, 1, 0, 0, 1, 0, 1<span style="color: #fe8019;">]</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Matriz de confusi&#243;n
</span><span style="color: #83a598;">cm</span> = confusion_matrix<span style="color: #fe8019;">(</span>y_real, y_pred<span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Matriz de confusi&#243;n:"</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>cm<span style="color: #fe8019;">)</span>
<span style="color: #928374;"># </span><span style="color: #928374;">[[4 1]   # TN=4, FP=1
</span><span style="color: #928374;">#  </span><span style="color: #928374;">[1 4]]  # FN=1, TP=4
</span>
<span style="color: #928374;"># </span><span style="color: #928374;">M&#233;tricas
</span><span style="color: #83a598;">accuracy</span> = accuracy_score<span style="color: #fe8019;">(</span>y_real, y_pred<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">precision</span> = precision_score<span style="color: #fe8019;">(</span>y_real, y_pred<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">recall</span> = recall_score<span style="color: #fe8019;">(</span>y_real, y_pred<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">f1</span> = f1_score<span style="color: #fe8019;">(</span>y_real, y_pred<span style="color: #fe8019;">)</span>

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Accuracy: </span>{accuracy:.2%}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Precision: </span>{precision:.2%}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Recall: </span>{recall:.2%}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"F1-Score: </span>{f1:.2%}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org5f3568f" class="outline-4">
<h4 id="org5f3568f">Reporte completo de clasificación</h4>
<div class="outline-text-4" id="text-org5f3568f">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> classification_report

<span style="color: #83a598;">y_real</span> = <span style="color: #fe8019;">[</span>0, 0, 0, 1, 1, 1, 0, 1, 0, 1<span style="color: #fe8019;">]</span>
<span style="color: #83a598;">y_pred</span> = <span style="color: #fe8019;">[</span>0, 0, 1, 1, 1, 0, 0, 1, 0, 1<span style="color: #fe8019;">]</span>

<span style="color: #83a598;">report</span> = classification_report<span style="color: #fe8019;">(</span>y_real, y_pred, target_names=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'No Salto'</span>, <span style="color: #b8bb26;">'Salto'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>report<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Salida esperada:
</p>
<pre class="example" id="orgb7b4b15">
              precision    recall  f1-score   support

    No Salto       0.80      0.80      0.80         5
       Salto       0.80      0.80      0.80         5

    accuracy                           0.80        10
   macro avg       0.80      0.80      0.80        10
weighted avg       0.80      0.80      0.80        10
</pre>
</div>
</div>
<div id="outline-container-orgb3a34f7" class="outline-4">
<h4 id="orgb3a34f7">Visualización de la matriz de confusión</h4>
<div class="outline-text-4" id="text-orgb3a34f7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> matplotlib.pyplot <span style="color: #fb4934;">as</span> plt
<span style="color: #fb4934;">import</span> seaborn <span style="color: #fb4934;">as</span> sns
<span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> confusion_matrix

<span style="color: #83a598;">y_real</span> = <span style="color: #fe8019;">[</span>0, 0, 0, 1, 1, 1, 0, 1, 0, 1<span style="color: #fe8019;">]</span>
<span style="color: #83a598;">y_pred</span> = <span style="color: #fe8019;">[</span>0, 0, 1, 1, 1, 0, 0, 1, 0, 1<span style="color: #fe8019;">]</span>

<span style="color: #83a598;">cm</span> = confusion_matrix<span style="color: #fe8019;">(</span>y_real, y_pred<span style="color: #fe8019;">)</span>
sns.heatmap<span style="color: #fe8019;">(</span>cm, annot=<span style="color: #d3869b;">True</span>, fmt=<span style="color: #b8bb26;">'d'</span>, cmap=<span style="color: #b8bb26;">'Blues'</span>, 
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   xticklabels=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'No Salto'</span>, <span style="color: #b8bb26;">'Salto'</span><span style="color: #b16286;">]</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   yticklabels=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'No Salto'</span>, <span style="color: #b8bb26;">'Salto'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
plt.ylabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'Real'</span><span style="color: #fe8019;">)</span>
plt.xlabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'Predicci&#243;n'</span><span style="color: #fe8019;">)</span>
plt.title<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'Matriz de Confusi&#243;n'</span><span style="color: #fe8019;">)</span>
plt.show<span style="color: #fe8019;">()</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org20f96ad" class="outline-3">
<h3 id="org20f96ad">Mejorando el Juego con Métricas</h3>
<div class="outline-text-3" id="text-org20f96ad">
</div>
<div id="outline-container-org4c0e601" class="outline-4">
<h4 id="org4c0e601">Añadir métricas al entrenamiento</h4>
<div class="outline-text-4" id="text-org4c0e601">
<p>
Podemos modificar <code>entrenar_modelo()</code> para mostrar más métricas:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> classification_report, confusion_matrix

<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">entrenar_modelo_mejorado</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span><span style="color: #fe8019;">)</span> -&gt; Tuple<span style="color: #fe8019;">[</span><span style="color: #fe8019;">bool</span>, <span style="color: #fe8019;">str</span><span style="color: #fe8019;">]</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">... c&#243;digo de entrenamiento existente ...
</span><span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Predicciones en el conjunto de prueba
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">y_pred</span> = clf.predict<span style="color: #fe8019;">(</span>X_test<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Matriz de confusi&#243;n
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">cm</span> = confusion_matrix<span style="color: #fe8019;">(</span>y_test, y_pred<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">Matriz de Confusi&#243;n:"</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>cm<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Reporte completo
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">report</span> = classification_report<span style="color: #fe8019;">(</span>y_test, y_pred, 
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>  target_names=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'No Salto'</span>, <span style="color: #b8bb26;">'Salto'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">Reporte de Clasificaci&#243;n:"</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>report<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">M&#233;tricas individuales
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> precision_score, recall_score, f1_score
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">precision</span> = precision_score<span style="color: #fe8019;">(</span>y_test, y_pred<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">recall</span> = recall_score<span style="color: #fe8019;">(</span>y_test, y_pred<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">f1</span> = f1_score<span style="color: #fe8019;">(</span>y_test, y_pred<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> <span style="color: #d3869b;">True</span>, <span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"MLP entrenado. Accuracy: </span>{acc:.3f}<span style="color: #b8bb26;">, "</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span> f<span style="color: #b8bb26;">"Precision: </span>{precision:.3f}<span style="color: #b8bb26;">, "</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span> f<span style="color: #b8bb26;">"Recall: </span>{recall:.3f}<span style="color: #b8bb26;">, "</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span> f<span style="color: #b8bb26;">"F1: </span>{f1:.3f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org0bb293c" class="outline-4">
<h4 id="org0bb293c">Interpretar resultados en el juego</h4>
<div class="outline-text-4" id="text-org0bb293c">
<p>
Si el modelo tiene:
</p>
<ul class="org-ul">
<li>Recall bajo (&lt; 0.6): Muchas colisiones → recolecta más datos donde saltas</li>
<li>Precision bajo (&lt; 0.5): Muchos saltos innecesarios → recolecta más datos donde NO saltas</li>
<li>F1 bajo (&lt; 0.6): El modelo no está aprendiendo bien → más datos variados</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org15a3216" class="outline-3">
<h3 id="org15a3216">Curvas ROC y AUC</h3>
<div class="outline-text-3" id="text-org15a3216">
</div>
<div id="outline-container-org4b7c4be" class="outline-4">
<h4 id="org4b7c4be">¿Qué es la curva ROC?</h4>
<div class="outline-text-4" id="text-org4b7c4be">
<p>
ROC (Receiver Operating Characteristic) muestra el trade-off entre:
</p>
<ul class="org-ul">
<li>Tasa de Verdaderos Positivos (Recall/TPR) en el eje Y</li>
<li>Tasa de Falsos Positivos (FPR = FP/(FP+TN)) en el eje X</li>
</ul>
</div>
</div>
<div id="outline-container-org58ec9a3" class="outline-4">
<h4 id="org58ec9a3">¿Qué es AUC?</h4>
<div class="outline-text-4" id="text-org58ec9a3">
<p>
AUC (Area Under Curve) es el área bajo la curva ROC:
</p>
<ul class="org-ul">
<li>AUC = 1.0: Clasificador perfecto</li>
<li>AUC = 0.5: Clasificador aleatorio (no mejor que adivinar)</li>
<li>AUC &gt; 0.7: Buen clasificador</li>
<li>AUC &gt; 0.9: Excelente clasificador</li>
</ul>
</div>
</div>
<div id="outline-container-org62fcf92" class="outline-4">
<h4 id="org62fcf92">Código para generar curva ROC</h4>
<div class="outline-text-4" id="text-org62fcf92">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> roc_curve, roc_auc_score
<span style="color: #fb4934;">import</span> matplotlib.pyplot <span style="color: #fb4934;">as</span> plt

<span style="color: #928374;"># </span><span style="color: #928374;">Obtener probabilidades (no solo predicciones)
</span><span style="color: #83a598;">y_proba</span> = modelo.predict_proba<span style="color: #fe8019;">(</span>X_test<span style="color: #fe8019;">)[</span>:, 1<span style="color: #fe8019;">]</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Calcular curva ROC
</span><span style="color: #83a598;">fpr</span>, <span style="color: #83a598;">tpr</span>, <span style="color: #83a598;">thresholds</span> = roc_curve<span style="color: #fe8019;">(</span>y_test, y_proba<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">auc</span> = roc_auc_score<span style="color: #fe8019;">(</span>y_test, y_proba<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Graficar
</span>plt.figure<span style="color: #fe8019;">(</span>figsize=<span style="color: #b16286;">(</span>8, 6<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
plt.plot<span style="color: #fe8019;">(</span>fpr, tpr, label=f<span style="color: #b8bb26;">'ROC curve (AUC = </span>{auc:.2f}<span style="color: #b8bb26;">)'</span><span style="color: #fe8019;">)</span>
plt.plot<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>0, 1<span style="color: #b16286;">]</span>, <span style="color: #b16286;">[</span>0, 1<span style="color: #b16286;">]</span>, <span style="color: #b8bb26;">'k--'</span>, label=<span style="color: #b8bb26;">'Random classifier'</span><span style="color: #fe8019;">)</span>
plt.xlabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'False Positive Rate'</span><span style="color: #fe8019;">)</span>
plt.ylabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'True Positive Rate'</span><span style="color: #fe8019;">)</span>
plt.title<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'ROC Curve'</span><span style="color: #fe8019;">)</span>
plt.legend<span style="color: #fe8019;">()</span>
plt.grid<span style="color: #fe8019;">(</span><span style="color: #d3869b;">True</span><span style="color: #fe8019;">)</span>
plt.show<span style="color: #fe8019;">()</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org728b922" class="outline-4">
<h4 id="org728b922">Interpretación</h4>
<div class="outline-text-4" id="text-org728b922">
<ul class="org-ul">
<li>Curva cerca de la esquina superior izquierda → mejor modelo</li>
<li>AUC alto → modelo puede distinguir bien entre clases</li>
<li>Útil para comparar diferentes modelos o umbrales</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc518504" class="outline-3">
<h3 id="orgc518504">Métricas para Clases Desbalanceadas</h3>
<div class="outline-text-3" id="text-orgc518504">
</div>
<div id="outline-container-org999d632" class="outline-4">
<h4 id="org999d632">El problema</h4>
<div class="outline-text-4" id="text-org999d632">
<p>
Cuando una clase es mucho más frecuente que la otra:
</p>
<ul class="org-ul">
<li>Accuracy puede ser engañoso</li>
<li>Un modelo que siempre predice la clase mayoritaria puede tener buen accuracy</li>
</ul>
</div>
</div>
<div id="outline-container-org4b39f31" class="outline-4">
<h4 id="org4b39f31">Soluciones</h4>
<div class="outline-text-4" id="text-org4b39f31">
<ol class="org-ol">
<li><b><b>F1-Score</b></b>: Ya lo vimos, balancea Precision y Recall</li>

<li><b><b>Precision-Recall Curve</b></b>: Similar a ROC pero mejor para clases desbalanceadas</li>
</ol>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> precision_recall_curve, auc

<span style="color: #83a598;">precision_vals</span>, <span style="color: #83a598;">recall_vals</span>, <span style="color: #83a598;">thresholds</span> = precision_recall_curve<span style="color: #fe8019;">(</span>y_test, y_proba<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">pr_auc</span> = auc<span style="color: #fe8019;">(</span>recall_vals, precision_vals<span style="color: #fe8019;">)</span>

plt.plot<span style="color: #fe8019;">(</span>recall_vals, precision_vals<span style="color: #fe8019;">)</span>
plt.xlabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'Recall'</span><span style="color: #fe8019;">)</span>
plt.ylabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'Precision'</span><span style="color: #fe8019;">)</span>
plt.title<span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">'Precision-Recall Curve (AUC = </span>{pr_auc:.2f}<span style="color: #b8bb26;">)'</span><span style="color: #fe8019;">)</span>
plt.show<span style="color: #fe8019;">()</span>
</pre>
</div>

<ol class="org-ol">
<li><b><b>Matthews Correlation Coefficient (MCC)</b></b>:</li>
</ol>

<p>
\[
MCC = \frac{TP \times TN - FP \times FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}
\]
</p>

<ul class="org-ul">
<li>Rango: -1 a +1</li>
<li>+1: Predicción perfecta</li>
<li>0: Predicción aleatoria</li>
<li>-1: Predicción inversa perfecta</li>
<li>Útil para clases desbalanceadas</li>
</ul>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> matthews_corrcoef

<span style="color: #83a598;">mcc</span> = matthews_corrcoef<span style="color: #fe8019;">(</span>y_test, y_pred<span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"MCC: </span>{mcc:.3f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orga4070a2" class="outline-3">
<h3 id="orga4070a2">Resumen: Guía Rápida</h3>
<div class="outline-text-3" id="text-orga4070a2">
</div>
<div id="outline-container-org91f537e" class="outline-4">
<h4 id="org91f537e">Tabla de métricas clave</h4>
<div class="outline-text-4" id="text-org91f537e">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Métrica</th>
<th scope="col" class="org-left">Fórmula</th>
<th scope="col" class="org-right">Rango</th>
<th scope="col" class="org-left">¿Qué mide?</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Accuracy</td>
<td class="org-left">(TP+TN)/(TP+TN+FP+FN)</td>
<td class="org-right">0-1</td>
<td class="org-left">Proporción de aciertos totales</td>
</tr>

<tr>
<td class="org-left">Precision</td>
<td class="org-left">TP/(TP+FP)</td>
<td class="org-right">0-1</td>
<td class="org-left">Confiabilidad de predicciones positivas</td>
</tr>

<tr>
<td class="org-left">Recall</td>
<td class="org-left">TP/(TP+FN)</td>
<td class="org-right">0-1</td>
<td class="org-left">Detección de casos positivos reales</td>
</tr>

<tr>
<td class="org-left">F1-Score</td>
<td class="org-left">2×(P×R)/(P+R)</td>
<td class="org-right">0-1</td>
<td class="org-left">Balance Precision/Recall</td>
</tr>

<tr>
<td class="org-left">Especificidad</td>
<td class="org-left">TN/(TN+FP)</td>
<td class="org-right">0-1</td>
<td class="org-left">Detección de casos negativos reales</td>
</tr>

<tr>
<td class="org-left">AUC-ROC</td>
<td class="org-left">Área bajo curva ROC</td>
<td class="org-right">0-1</td>
<td class="org-left">Capacidad de distinguir clases</td>
</tr>

<tr>
<td class="org-left">MCC</td>
<td class="org-left">(TP×TN-FP×FN)/√(&#x2026;)</td>
<td class="org-right">-1 a +1</td>
<td class="org-left">Correlación general (balanceada)</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-org43dd4cb" class="outline-4">
<h4 id="org43dd4cb">Decisión rápida: ¿Qué métrica usar?</h4>
<div class="outline-text-4" id="text-org43dd4cb">
<pre class="example" id="orgbddeed8">
¿Las clases están balanceadas?
├─ SÍ → Accuracy es útil
└─ NO → Usa F1-Score o MCC

¿Los falsos negativos son críticos?
├─ SÍ → Recall es la más importante
└─ NO → Precision puede ser más importante

¿Necesitas una métrica única?
├─ SÍ → F1-Score o MCC
└─ NO → Revisa Precision, Recall y Accuracy juntas
</pre>
</div>
</div>
<div id="outline-container-org8dd0506" class="outline-4">
<h4 id="org8dd0506">Checklist de evaluación</h4>
<div class="outline-text-4" id="text-org8dd0506">
<p>
Antes de aceptar un modelo, verifica:
</p>

<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> Accuracy &gt; umbral mínimo (ej: 0.7)</li>
<li class="off"><code>[&#xa0;]</code> Recall &gt; umbral mínimo (ej: 0.7) - especialmente si FN son críticos</li>
<li class="off"><code>[&#xa0;]</code> Precision &gt; umbral mínimo (ej: 0.6) - si FP son costosos</li>
<li class="off"><code>[&#xa0;]</code> F1-Score muestra buen balance</li>
<li class="off"><code>[&#xa0;]</code> Matriz de confusión no muestra patrones extraños</li>
<li class="off"><code>[&#xa0;]</code> Métricas en test son similares a entrenamiento (no overfitting)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgfe9763b" class="outline-3">
<h3 id="orgfe9763b">Ejercicios Prácticos</h3>
<div class="outline-text-3" id="text-orgfe9763b">
</div>
<div id="outline-container-org8f64854" class="outline-4">
<h4 id="org8f64854">Ejercicio 1: Calcular métricas manualmente</h4>
<div class="outline-text-4" id="text-org8f64854">
<p>
Dada esta matriz de confusión:
</p>

<pre class="example" id="orga58e2b8">
                    Predicción
                 No Salto  Salto
Real  No Salto      60      20
      Salto         10      10
</pre>

<p>
Calcula:
</p>
<ul class="org-ul">
<li>TP, TN, FP, FN</li>
<li>Accuracy</li>
<li>Precision</li>
<li>Recall</li>
<li>F1-Score</li>
<li>Especificidad</li>
</ul>

<p>
<b><b>Solución</b></b>:
</p>
<ul class="org-ul">
<li>TP = 10, TN = 60, FP = 20, FN = 10</li>
<li>Accuracy = 70/100 = 0.70</li>
<li>Precision = 10/30 = 0.33</li>
<li>Recall = 10/20 = 0.50</li>
<li>F1 = 2×(0.33×0.50)/(0.33+0.50) = 0.40</li>
<li>Especificidad = 60/80 = 0.75</li>
</ul>
</div>
</div>
<div id="outline-container-org25b125d" class="outline-4">
<h4 id="org25b125d">Ejercicio 2: Interpretar resultados</h4>
<div class="outline-text-4" id="text-org25b125d">
<p>
Un modelo tiene:
</p>
<ul class="org-ul">
<li>Accuracy: 85%</li>
<li>Precision: 40%</li>
<li>Recall: 90%</li>
</ul>

<p>
¿Es un buen modelo para el juego? ¿Por qué?
</p>

<p>
<b><b>Solución</b></b>: 
</p>
<ul class="org-ul">
<li>Recall alto (90%) es bueno → detecta casi todos los peligros</li>
<li>Precision bajo (40%) → muchos saltos innecesarios</li>
<li>Para el juego: Es aceptable porque evitar colisiones (Recall) es más importante que saltos innecesarios (Precision)</li>
</ul>
</div>
</div>
<div id="outline-container-orge9b9df8" class="outline-4">
<h4 id="orge9b9df8">Ejercicio 3: Mejorar un modelo</h4>
<div class="outline-text-4" id="text-orge9b9df8">
<p>
Un modelo tiene Recall = 0.5. ¿Qué puedes hacer para mejorarlo?
</p>

<p>
<b><b>Solución</b></b>:
</p>
<ul class="org-ul">
<li>Recolectar más datos donde realmente debes saltar</li>
<li>Disminuir el umbral de decisión (de 0.5 a 0.3, por ejemplo)</li>
<li>Ajustar hiperparámetros del MLP</li>
<li>Añadir más características al modelo</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org41135ad" class="outline-3">
<h3 id="org41135ad">Referencias y Recursos</h3>
<div class="outline-text-3" id="text-org41135ad">
</div>
<div id="outline-container-orga74b109" class="outline-4">
<h4 id="orga74b109">Documentación oficial</h4>
<div class="outline-text-4" id="text-orga74b109">
<ul class="org-ul">
<li>scikit-learn metrics: <a href="https://scikit-learn.org/stable/modules/model_evaluation.html">https://scikit-learn.org/stable/modules/model_evaluation.html</a></li>
<li>Confusion matrix: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html</a></li>
</ul>
</div>
</div>
<div id="outline-container-org6ce5dee" class="outline-4">
<h4 id="org6ce5dee">Lecturas recomendadas</h4>
<div class="outline-text-4" id="text-org6ce5dee">
<ul class="org-ul">
<li>"Hands-On Machine Learning" - Aurélien Géron (Capítulo sobre evaluación)</li>
<li>"Pattern Recognition and Machine Learning" - Christopher Bishop</li>
<li>"The Elements of Statistical Learning" - Hastie, Tibshirani, Friedman</li>
</ul>
</div>
</div>
<div id="outline-container-orgf5ad7e4" class="outline-4">
<h4 id="orgf5ad7e4">Herramientas útiles</h4>
<div class="outline-text-4" id="text-orgf5ad7e4">
<ul class="org-ul">
<li>scikit-learn: Métricas implementadas</li>
<li>Yellowbrick: Visualizaciones de métricas</li>
<li>Weka: Suite completa de ML con evaluación</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org192bbfb" class="outline-3">
<h3 id="org192bbfb">Conclusión</h3>
<div class="outline-text-3" id="text-org192bbfb">
<p>
Las métricas de evaluación son esenciales para entender y mejorar modelos de Machine Learning. No hay una métrica "perfecta" - la elección depende de:
</p>
<ul class="org-ul">
<li>Tu problema específico</li>
<li>El costo de diferentes tipos de errores</li>
<li>El balance de clases</li>
<li>Tus objetivos</li>
</ul>

<p>
Para el juego de salto:
</p>
<ul class="org-ul">
<li><b><b>Recall es crítico</b></b> (evitar colisiones)</li>
<li><b><b>Precision es importante</b></b> (no saltar innecesariamente)</li>
<li><b><b>F1-Score</b></b> da un buen balance general</li>
<li><b><b>Accuracy</b></b> puede ser engañoso si las clases están desbalanceadas</li>
</ul>

<p>
Recuerda: Un modelo con 90% accuracy puede ser inútil si tiene 10% Recall (muchas colisiones). Siempre revisa múltiples métricas.
</p>
</div>
</div>
</div>
<div id="outline-container-org8c7aef8" class="outline-2">
<h2 id="org8c7aef8">Redes Neuronales Recurrentes (RNN)</h2>
<div class="outline-text-2" id="text-org8c7aef8">
</div>
<div id="outline-container-org48f4c30" class="outline-3">
<h3 id="org48f4c30">Introducción</h3>
<div class="outline-text-3" id="text-org48f4c30">
</div>
<div id="outline-container-org61a69fa" class="outline-4">
<h4 id="org61a69fa">¿Qué son las Redes Recurrentes?</h4>
<div class="outline-text-4" id="text-org61a69fa">
<p>
Las Redes Neuronales Recurrentes (RNN - Recurrent Neural Networks) son
un tipo de arquitectura de redes neuronales diseñadas específicamente
para procesar <b><b>secuencias de datos</b></b>. A diferencia de las redes
feedforward tradicionales, las RNN tienen conexiones que forman
ciclos, permitiéndoles mantener una "memoria" de información procesada
anteriormente.
</p>
</div>
</div>
<div id="outline-container-orgb297444" class="outline-4">
<h4 id="orgb297444">Características Fundamentales</h4>
<div class="outline-text-4" id="text-orgb297444">
<ol class="org-ol">
<li><b><b>Procesamiento secuencial</b></b>: Procesan datos uno a la vez, manteniendo información del pasado</li>
<li><b><b>Memoria temporal</b></b>: Pueden recordar información de pasos anteriores</li>
<li><b><b>Parámetros compartidos</b></b>: Los mismos pesos se usan en cada paso temporal</li>
<li><b><b>Longitud variable</b></b>: Pueden procesar secuencias de diferentes longitudes</li>
</ol>
</div>
</div>
<div id="outline-container-org40daabd" class="outline-4">
<h4 id="org40daabd">Aplicaciones Comunes</h4>
<div class="outline-text-4" id="text-org40daabd">
<ul class="org-ul">
<li><b><b>Procesamiento de lenguaje natural</b></b>: Traducción, generación de texto, análisis de sentimientos</li>
<li><b><b>Reconocimiento de voz</b></b>: Transcripción de audio a texto</li>
<li><b><b>Series temporales</b></b>: Predicción de valores futuros (precios, temperatura, etc.)</li>
<li><b><b>Análisis de video</b></b>: Reconocimiento de acciones, seguimiento de objetos</li>
<li><b><b>Música</b></b>: Generación de melodías, clasificación de géneros</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org9f75a96" class="outline-3">
<h3 id="org9f75a96">El Problema que Resuelven las RNN</h3>
<div class="outline-text-3" id="text-org9f75a96">
</div>
<div id="outline-container-org288cd58" class="outline-4">
<h4 id="org288cd58">Limitaciones de las Redes Feedforward</h4>
<div class="outline-text-4" id="text-org288cd58">
<p>
Las redes neuronales tradicionales (feedforward) tienen limitaciones importantes:
</p>

<p>
<b><b>Problema 1: Tamaño fijo de entrada</b></b>
</p>
<ul class="org-ul">
<li>Una red feedforward requiere que todas las entradas tengan el mismo tamaño</li>
<li>No puede manejar secuencias de longitud variable directamente</li>
</ul>

<p>
<b><b>Problema 2: Sin memoria</b></b>
</p>
<ul class="org-ul">
<li>Cada predicción es independiente</li>
<li>No puede usar información de predicciones anteriores</li>
<li>No entiende el contexto temporal</li>
</ul>

<p>
<b><b>Ejemplo</b></b>: Predecir la siguiente palabra en una oración
</p>
<ul class="org-ul">
<li>Feedforward: Solo ve la palabra actual → predicción limitada</li>
<li>RNN: Ve todas las palabras anteriores → predicción más inteligente</li>
</ul>
</div>
</div>
<div id="outline-container-org1ddbc95" class="outline-4">
<h4 id="org1ddbc95">El Concepto de Secuencias</h4>
<div class="outline-text-4" id="text-org1ddbc95">
<p>
Una secuencia es una serie ordenada de elementos donde:
</p>
<ul class="org-ul">
<li>El orden importa</li>
<li>Cada elemento puede depender de los anteriores</li>
<li>La longitud puede variar</li>
</ul>

<p>
<b><b>Ejemplos de secuencias</b></b>:
</p>
<ul class="org-ul">
<li>Palabras en una oración: ["El", "gato", "está", "durmiendo"]</li>
<li>Valores de temperatura: [20, 22, 21, 23, 25, &#x2026;]</li>
<li>Píxeles en una imagen (si se procesan fila por fila)</li>
<li>Notas musicales: [Do, Re, Mi, Fa, Sol, &#x2026;]</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org4f6da19" class="outline-3">
<h3 id="org4f6da19">Arquitectura Básica de RNN</h3>
<div class="outline-text-3" id="text-org4f6da19">
</div>
<div id="outline-container-orgf46e076" class="outline-4">
<h4 id="orgf46e076">Estructura Fundamental</h4>
<div class="outline-text-4" id="text-orgf46e076">
<p>
Una RNN básica tiene la siguiente estructura:
</p>

<pre class="example" id="org85ce3a9">
        h[t-1] ──┐
                 │
        x[t] ────┼──→ RNN Cell ──→ h[t] ──→ y[t]
                 │                    │
                 └────────────────────┘
                 (bucle de retroalimentación)
</pre>

<p>
<b><b>Componentes</b></b>:
</p>
<ul class="org-ul">
<li><code>x[t]</code> : Vector de entrada en el tiempo t</li>
<li><code>h[t]</code> : Estado oculto (hidden state) en el tiempo t (la "memoria")</li>
<li><code>y[t]</code> : Vector de salida en el tiempo t</li>
<li><code>h[t-1]</code> : Estado oculto del paso anterior</li>
</ul>
</div>
</div>
<div id="outline-container-org7fdc11a" class="outline-4">
<h4 id="org7fdc11a">La Ecuación Matemática Fundamental</h4>
<div class="outline-text-4" id="text-org7fdc11a">
<p>
La operación básica de una RNN se puede expresar como:
</p>

<p>
\[
h_t = f(W_{xh} \cdot x_t + W_{hh} \cdot h_{t-1} + b_h)
\]
</p>

<p>
\[
y_t = g(W_{hy} \cdot h_t + b_y)
\]
</p>

<p>
Donde:
</p>
<ul class="org-ul">
<li><code>f</code> y <code>g</code> son funciones de activación (típicamente tanh y sigmoid/softmax)</li>
<li><code>W_{xh}</code> : Matriz de pesos de entrada a estado oculto</li>
<li><code>W_{hh}</code> : Matriz de pesos de estado oculto a estado oculto (la "memoria")</li>
<li><code>W_{hy}</code> : Matriz de pesos de estado oculto a salida</li>
<li><code>b_h</code>, <code>b_y</code> : Vectores de sesgo (bias)</li>
</ul>
</div>
</div>
<div id="outline-container-org8f2801b" class="outline-4">
<h4 id="org8f2801b">Desglose Detallado de la Ecuación</h4>
<div class="outline-text-4" id="text-org8f2801b">
<p>
Vamos a analizar cada componente:
</p>

<p>
<b>1. Término de entrada: \[W_{xh} \cdot x_t\]</b>
</p>
<ul class="org-ul">
<li>Transforma la entrada actual a un espacio de dimensión oculta</li>
<li>Captura información del presente</li>
</ul>

<p>
<b><b>2. Término recurrente: \[W_{hh} \cdot h_{t-1}\]</b></b>
</p>
<ul class="org-ul">
<li>Transforma la memoria anterior</li>
<li>Captura información del pasado</li>
<li><b><b>Esta es la clave de la "memoria"</b></b></li>
</ul>

<p>
<b><b>3. Suma y activación: <code>f(...)</code></b></b>
</p>
<ul class="org-ul">
<li>Combina información presente y pasada</li>
<li>La función de activación introduce no-linealidad</li>
<li>Típicamente se usa tanh para mantener valores acotados</li>
</ul>
</div>
</div>
<div id="outline-container-org4d02370" class="outline-4">
<h4 id="org4d02370">Ejemplo Numérico Simple</h4>
<div class="outline-text-4" id="text-org4d02370">
<p>
Vamos a calcular manualmente un paso de una RNN.
</p>

<p>
<b><b>Configuración</b></b>:
</p>
<ul class="org-ul">
<li>Dimensión de entrada: 2</li>
<li>Dimensión oculta: 3</li>
<li>Dimensión de salida: 1</li>
</ul>

<p>
<b><b>Paso 1: Inicialización (t=0)</b></b>
\[
h_0 = \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}
\]
</p>

<p>
<b><b>Paso 2: Primer paso temporal (t=1)</b></b>
</p>

<p>
<b><b>Entrada</b></b>: \[x_1 = \begin{bmatrix} 1 \\ 2 \end{bmatrix}\]
</p>

<p>
<b><b>Pesos</b></b> (ejemplo):
\[
W_{xh} = \begin{bmatrix}
0.1 & 0.3 \\
0.2 & 0.4 \\
0.3 & 0.5
\end{bmatrix}, \quad
W_{hh} = \begin{bmatrix}
0.6 & 0.1 & 0.2 \\
0.1 & 0.7 & 0.3 \\
0.2 & 0.3 & 0.8
\end{bmatrix}, \quad
b_h = \begin{bmatrix}
0.1 \\
0.2 \\
0.3
\end{bmatrix}
\]
</p>

<p>
<b><b>Cálculo del estado oculto</b></b>:
</p>

<ol class="org-ol">
<li><p>
\[W_{xh} \cdot x_1\]
</p>
\begin{align*}
\begin{bmatrix}
0.1 & 0.3 \\
0.2 & 0.4 \\
0.3 & 0.5
\end{bmatrix}
\quad
\begin{bmatrix}
1 \\
2
\end{bmatrix}
 \quad  =  \quad
\begin{bmatrix}
0.1(1) + 0.3(2) \\
0.2(1) + 0.4(2) \\
0.3(1) + 0.5(2)
\end{bmatrix}
\quad  =  \quad
 \begin{bmatrix}
0.7 \\
1.0 \\
1.3
\end{bmatrix}
\end{align*}</li>

<li><p>
\[W_{hh} \cdot h_0:\]
</p>
\begin{align*}
\begin{bmatrix}
0.6 & 0.1 & 0.2 \\
0.1 & 0.7 & 0.3 \\
0.2 & 0.3 & 0.8
\end{bmatrix}
\quad
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}
\quad=\quad
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}
\end{align*}</li>
</ol>


<ol class="org-ol">
<li><p>
Suma con bias:
</p>
\begin{align*}
\begin{bmatrix} 0.7 \\ 1.0 \\ 1.3 \end{bmatrix} 
&\quad+\quad 
\begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix} 
\quad+\quad 
\begin{bmatrix} 0.1 \\ 0.2 \\ 0.3 \end{bmatrix} 
&\quad=\quad 
\begin{bmatrix} 0.8 \\ 1.2 \\ 1.6 \end{bmatrix}
\end{align*}</li>

<li>Aplicar tanh:
\[
    h_1 = \tanh\left(\begin{bmatrix} 0.8 \\ 1.2 \\ 1.6 \end{bmatrix}\right) \approx \begin{bmatrix} 0.664 \\ 0.834 \\ 0.922 \end{bmatrix}
   \]</li>
</ol>

<p>
<b><b>Cálculo de la salida</b></b>:
</p>
\begin{align*}
W_{hy} =
\quad
\begin{bmatrix}
0.5 & 0.3 & 0.2
\end{bmatrix},
\quad
b_y = 0.1
\end{align*}

\begin{align*}
y_1 = W_{hy} \cdot h_1 + b_y
=
\quad
\begin{bmatrix} 0.5 & 0.3 & 0.2
\end{bmatrix}
\begin{bmatrix}
0.664 \\
0.834 \\
0.922
\end{bmatrix}
+
0.1
\end{align*}

<p>
\[
= 0.5(0.664) + 0.3(0.834) + 0.2(0.922) + 0.1\\
= 0.332 + 0.250 + 0.184 + 0.1\\
= 0.866\\
\]
</p>

<p>
<b><b>Paso 3: Segundo paso temporal (t=2)</b></b>
</p>

<p>
<b><b>Entrada</b></b>: \[x_2 = \begin{bmatrix} 3 \\ 4 \end{bmatrix}\]
</p>

<p>
<b><b>Cálculo</b></b>:
</p>

<ol class="org-ol">
<li><p>
\[W_{xh} \cdot x_2:\]
</p>
\begin{align*}
\begin{bmatrix}
0.1 & 0.3 \\
0.2 & 0.4 \\
0.3 & 0.5
\end{bmatrix}
\quad
\begin{bmatrix}
3 \\
4
\end{bmatrix}
\quad
=
\quad
\begin{bmatrix}
1.5 \\
2.2 \\
2.9
\end{bmatrix}
\end{align*}</li>

<li><p>
\[W_{hh} \cdot h_1\] (¡Ahora usamos la memoria!):
</p>
\begin{align*}
\begin{bmatrix}
0.6 & 0.1 & 0.2 \\
0.1 & 0.7 & 0.3 \\
0.2 & 0.3 & 0.8
\end{bmatrix}
\quad
\begin{bmatrix}
0.664 \\
0.834 \\
0.922
\end{bmatrix}
\quad
=
\quad
\begin{bmatrix}
0.6(0.664) + 0.1(0.834) + 0.2(0.922) \\
0.1(0.664) + 0.7(0.834) + 0.3(0.922) \\
0.2(0.664) + 0.3(0.834) + 0.8(0.922)
\end{bmatrix}
\quad
=
\quad
\begin{bmatrix}
0.398 + 0.083 + 0.184 \\
0.066 + 0.584 + 0.277 \\
0.133 + 0.250 + 0.738
\end{bmatrix}
\quad
=
\quad
\begin{bmatrix}
0.665 \\
0.927 \\
1.121
\end{bmatrix}
\end{align*}</li>

<li><p>
Suma:
</p>

\begin{align*}
\begin{bmatrix}
1.5 \\
2.2 \\
2.9
\end{bmatrix}
\quad
+
\quad  
\begin{bmatrix}
0.665 \\
0.927 \\
1.121
\end{bmatrix}
\quad
+
\quad  
\begin{bmatrix}
0.1 \\
0.2 \\
0.3
\end{bmatrix}
\quad
=
\quad
\begin{bmatrix}
2.265 \\
3.327 \\
4.321
\end{bmatrix}
\end{align*}</li>

<li><p>
Aplicar tanh:
</p>
\begin{align*}
h_2
\quad=
\tanh\left(
\quad
\begin{bmatrix}
2.265 \\
3.327 \\
4.321
\end{bmatrix}
\quad
\right)
\quad
\approx
\quad
\begin{bmatrix}
0.978 \\
0.997 \\
0.999
\end{bmatrix}
\end{align*}</li>
</ol>

<p>
<b><b>Observación clave</b></b>: El estado <code>h_2</code> es diferente de <code>h_1</code> porque:
</p>
<ol class="org-ol">
<li>La entrada cambió (<code>x_2 ≠ x_1</code>)</li>
<li>La memoria anterior (<code>h_1</code>) influyó en el cálculo</li>
<li>La combinación de ambos crea un nuevo estado que refleja tanto el presente como el pasado</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgbda53d1" class="outline-3">
<h3 id="orgbda53d1">Propagación hacia Atrás en el Tiempo (BPTT)</h3>
<div class="outline-text-3" id="text-orgbda53d1">
</div>
<div id="outline-container-orgf74bab2" class="outline-4">
<h4 id="orgf74bab2">¿Qué es BPTT?</h4>
<div class="outline-text-4" id="text-orgf74bab2">
<p>
Backpropagation Through Time (BPTT) es el algoritmo de entrenamiento
para RNN. Es una extensión del backpropagation estándar que propaga el
error no solo a través de las capas, sino también <b><b>a través del
tiempo</b></b>.
</p>
</div>
</div>
<div id="outline-container-org1a34082" class="outline-4">
<h4 id="org1a34082">Analogía</h4>
<div class="outline-text-4" id="text-org1a34082">
<p>
Imagina que tienes una secuencia de 5 pasos:
</p>
<ul class="org-ul">
<li>En backpropagation normal: El error se propaga capa por capa</li>
<li>En BPTT: El error se propaga capa por capa Y paso temporal por paso temporal</li>
</ul>
</div>
</div>
<div id="outline-container-org449f5aa" class="outline-4">
<h4 id="org449f5aa">Cálculo de Gradientes</h4>
<div class="outline-text-4" id="text-org449f5aa">
<p>
Para entrenar una RNN, necesitamos calcular los gradientes de la función de pérdida respecto a todos los parámetros.
</p>

<p>
<b><b>Pérdida total</b></b>:
\[
L = \sum_{t=1}^{T} L_t(y_t, \hat{y}_t)
\]
</p>

<p>
Donde <code>L_t</code> es la pérdida en el tiempo t y <code>T</code> es la longitud de la
secuencia.
</p>

<p>
<b><b>Gradiente respecto a <code>W_{hh}</code></b></b>:
</p>

<p>
El gradiente es más complejo porque <code>h_t</code> depende de <code>h_{t-1}</code>, que
depende de <code>h_{t-2}</code>, etc.
</p>

<p>
\[
\frac{\partial L}{\partial W_{hh}} = \sum_{t=1}^{T} \sum_{k=1}^{t} \frac{\partial L_t}{\partial y_t} \frac{\partial y_t}{\partial h_t} \frac{\partial h_t}{\partial h_k} \frac{\partial h_k}{\partial W_{hh}}
\]
</p>

<p>
Donde <code>∂h_t/∂h_k</code> requiere calcular la cadena completa:
</p>

<p>
\[
\frac{\partial h_t}{\partial h_k} = \prod_{j=k+1}^{t} \frac{\partial h_j}{\partial h_{j-1}}
\]
</p>
</div>
</div>
<div id="outline-container-org45d1dee" class="outline-4">
<h4 id="org45d1dee">El Problema del Gradiente que Desaparece</h4>
<div class="outline-text-4" id="text-org45d1dee">
<p>
<b><b>¿Por qué ocurre?</b></b>
</p>

<p>
La derivada <code>∂h_j/∂h_{j-1}</code> típicamente tiene valores menores que 1. Cuando multiplicamos muchas de estas derivadas, el resultado se acerca a cero.
</p>

<p>
<b><b>Ejemplo numérico</b></b>:
</p>

<p>
Supongamos que <code>∂h_j/∂h_{j-1} = 0.5</code> (valor típico).
</p>

<p>
Para una secuencia de longitud 10:
\[
\frac{\partial h_{10}}{\partial h_1} = 0.5^9 \approx 0.002
\]
</p>

<p>
Para una secuencia de longitud 50:
\[
\frac{\partial h_{50}}{\partial h_1} = 0.5^{49} \approx 1.8 \times 10^{-15}
\]
</p>

<p>
¡El gradiente es prácticamente cero! El modelo no puede aprender dependencias largas.
</p>
</div>
</div>
<div id="outline-container-org1d44e7f" class="outline-4">
<h4 id="org1d44e7f">El Problema del Gradiente que Explota</h4>
<div class="outline-text-4" id="text-org1d44e7f">
<p>
A veces ocurre lo contrario: los valores son mayores que 1 y al multiplicarlos explotan.
</p>

<p>
<b><b>Ejemplo</b></b>:
Si <code>∂h_j/∂h_{j-1} = 1.5</code>:
\[
\frac{\partial h_{50}}{\partial h_1} = 1.5^{49} \approx 6.3 \times 10^8
\]
</p>

<p>
El gradiente es enorme, causando actualizaciones de pesos muy grandes y entrenamiento inestable.
</p>
</div>
</div>
<div id="outline-container-org11df123" class="outline-4">
<h4 id="org11df123">Soluciones</h4>
<div class="outline-text-4" id="text-org11df123">
<ol class="org-ol">
<li><b><b>Gradient Clipping</b></b>: Limitar el valor máximo del gradiente</li>
<li><b><b>LSTM/GRU</b></b>: Arquitecturas diseñadas para solucionar estos problemas</li>
<li><b><b>Skip Connections</b></b>: Conexiones que saltan pasos temporales</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orgbfae015" class="outline-3">
<h3 id="orgbfae015">Tipos de Redes Recurrentes</h3>
<div class="outline-text-3" id="text-orgbfae015">
</div>
<div id="outline-container-org68fc8de" class="outline-4">
<h4 id="org68fc8de">RNN Vanilla (SimpleRNN)</h4>
<div class="outline-text-4" id="text-org68fc8de">
<p>
La RNN más básica, con la estructura que hemos estado describiendo.
</p>

<p>
<b><b>Ecuación</b></b>:
\[
h_t = \tanh(W_{xh} x_t + W_{hh} h_{t-1} + b_h)
\]
</p>

<p>
<b><b>Ventajas</b></b>:
</p>
<ul class="org-ul">
<li>Simple de entender e implementar</li>
<li>Computacionalmente eficiente</li>
<li>Buena para secuencias cortas</li>
</ul>

<p>
<b><b>Desventajas</b></b>:
</p>
<ul class="org-ul">
<li>Problema del gradiente que desaparece</li>
<li>Memoria limitada</li>
<li>Dificultad para capturar dependencias largas</li>
</ul>

<p>
<b><b>Uso típico</b></b>: Secuencias cortas (5-10 pasos), problemas simples.
</p>
</div>
</div>
<div id="outline-container-orge17fefe" class="outline-4">
<h4 id="orge17fefe">LSTM (Long Short-Term Memory)</h4>
<div class="outline-text-4" id="text-orge17fefe">
<p>
LSTM fue diseñada específicamente para solucionar el problema del gradiente que desaparece.
</p>

<p>
<b><b>Estructura clave</b></b>: La LSTM tiene "puertas" (gates) que controlan el flujo de información:
</p>

<ol class="org-ol">
<li><b><b>Forget Gate</b></b> (Puerta de olvido): Decide qué información olvidar del estado anterior</li>
<li><b><b>Input Gate</b></b> (Puerta de entrada): Decide qué nueva información guardar</li>
<li><b><b>Output Gate</b></b> (Puerta de salida): Decide qué información usar para la salida</li>
</ol>

<p>
<b><b>Ecuaciones</b></b>:
</p>

<p>
<b><b>Forget Gate</b></b>:
\[
f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)
\]
</p>

<p>
<b><b>Input Gate</b></b>:
\[
i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)
\]
</p>

<p>
<b><b>Candidato a memoria</b></b>:
\[
\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)
\]
</p>

<p>
<b><b>Estado de celda</b></b> (la memoria a largo plazo):
\[
C_t = f_t * C_{t-1} + i_t * \tilde{C}_t
\]
</p>

<p>
<b><b>Output Gate</b></b>:
\[
o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)
\]
</p>

<p>
<b><b>Estado oculto</b></b>:
\[
h_t = o_t * \tanh(C_t)
\]
</p>

<p>
Donde <code>*</code> denota multiplicación elemento por elemento (Hadamard product).
</p>

<p>
<b><b>Interpretación</b></b>:
</p>
<ul class="org-ul">
<li><code>C_t</code> es la "memoria a largo plazo" que puede persistir por muchos pasos</li>
<li>Las puertas controlan qué se recuerda y qué se olvida</li>
<li>Esto permite que la información fluya sin degradarse</li>
</ul>

<p>
<b><b>Ventajas</b></b>:
</p>
<ul class="org-ul">
<li>Puede recordar información por mucho tiempo</li>
<li>Soluciona el problema del gradiente que desaparece</li>
<li>Muy efectiva para secuencias largas</li>
</ul>

<p>
<b><b>Desventajas</b></b>:
</p>
<ul class="org-ul">
<li>Más compleja computacionalmente</li>
<li>Más parámetros que entrenar</li>
<li>Más lenta que RNN vanilla</li>
</ul>

<p>
<b><b>Uso típico</b></b>: Secuencias largas (20+ pasos), problemas complejos que requieren memoria a largo plazo.
</p>
</div>
</div>
<div id="outline-container-orgdba46a0" class="outline-4">
<h4 id="orgdba46a0">GRU (Gated Recurrent Unit)</h4>
<div class="outline-text-4" id="text-orgdba46a0">
<p>
GRU es una versión simplificada de LSTM que combina algunas operaciones.
</p>

<p>
<b><b>Estructura</b></b>: Solo 2 puertas en lugar de 3:
</p>

<ol class="org-ol">
<li><b><b>Reset Gate</b></b>: Decide qué información del pasado ignorar</li>
<li><b><b>Update Gate</b></b>: Decide qué información actualizar</li>
</ol>

<p>
<b><b>Ecuaciones</b></b>:
</p>

<p>
<b><b>Reset Gate</b></b>:
\[
r_t = \sigma(W_r \cdot [h_{t-1}, x_t] + b_r)
\]
</p>

<p>
<b><b>Update Gate</b></b>:
\[
z_t = \sigma(W_z \cdot [h_{t-1}, x_t] + b_z)
\]
</p>

<p>
<b><b>Candidato a estado oculto</b></b>:
\[
\tilde{h}_t = \tanh(W \cdot [r_t * h_{t-1}, x_t] + b)
\]
</p>

<p>
<b><b>Estado oculto</b></b>:
\[
h_t = (1 - z_t) * h_{t-1} + z_t * \tilde{h}_t
\]
</p>

<p>
<b><b>Interpretación</b></b>:
</p>
<ul class="org-ul">
<li><code>z_t</code> controla cuánta información nueva vs. antigua usar</li>
<li><code>r_t</code> controla cuánta información del pasado considerar</li>
<li>Más simple que LSTM pero a menudo igual de efectiva</li>
</ul>

<p>
<b><b>Ventajas</b></b>:
</p>
<ul class="org-ul">
<li>Más simple que LSTM</li>
<li>Menos parámetros</li>
<li>A menudo funciona tan bien como LSTM</li>
<li>Más rápida de entrenar</li>
</ul>

<p>
<b><b>Desventajas</b></b>:
</p>
<ul class="org-ul">
<li>Menos flexible que LSTM para casos muy complejos</li>
<li>Puede tener problemas con secuencias muy largas</li>
</ul>

<p>
<b><b>Uso típico</b></b>: Balance entre simplicidad y poder. Recomendada para la mayoría de casos.
</p>
</div>
</div>
</div>
<div id="outline-container-org389ab2b" class="outline-3">
<h3 id="org389ab2b">Implementación Práctica</h3>
<div class="outline-text-3" id="text-org389ab2b">
</div>
<div id="outline-container-org13b73d1" class="outline-4">
<h4 id="org13b73d1">Implementación desde Cero (NumPy)</h4>
<div class="outline-text-4" id="text-org13b73d1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np

<span style="color: #fb4934;">class</span> <span style="color: #fabd2f;">SimpleRNN</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">__init__</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>, input_size, hidden_size, output_size<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Inicializa una RNN simple.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Args:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   input_size: Dimensi&#243;n de la entrada
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   hidden_size: Dimensi&#243;n del estado oculto
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   output_size: Dimensi&#243;n de la salida
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Inicializar pesos con valores peque&#241;os aleatorios
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">W_xh</span> = np.random.randn<span style="color: #fe8019;">(</span>hidden_size, input_size<span style="color: #fe8019;">)</span> * 0.01
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">W_hh</span> = np.random.randn<span style="color: #fe8019;">(</span>hidden_size, hidden_size<span style="color: #fe8019;">)</span> * 0.01
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">W_hy</span> = np.random.randn<span style="color: #fe8019;">(</span>output_size, hidden_size<span style="color: #fe8019;">)</span> * 0.01
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Inicializar sesgos
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">b_h</span> = np.zeros<span style="color: #fe8019;">(</span><span style="color: #b16286;">(</span>hidden_size, 1<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">b_y</span> = np.zeros<span style="color: #fe8019;">(</span><span style="color: #b16286;">(</span>output_size, 1<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">hidden_size</span> = hidden_size
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">forward</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>, x_sequence<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Forward pass: procesa una secuencia completa.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Args:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   x_sequence: Lista de vectores de entrada [x_1, x_2, ..., x_T]
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Returns:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   h_states: Lista de estados ocultos
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   y_outputs: Lista de salidas
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">h_states</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">y_outputs</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">h_prev</span> = np.zeros<span style="color: #fe8019;">(</span><span style="color: #b16286;">(</span><span style="color: #fb4934;">self</span>.hidden_size, 1<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Inicializar h_0
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> x_t <span style="color: #fb4934;">in</span> x_sequence:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Convertir entrada a columna si es necesario
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> x_t.ndim == 1:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">x_t</span> = x_t.reshape<span style="color: #fe8019;">(</span>-1, 1<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Calcular estado oculto
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">h_t</span> = np.tanh<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.W_xh @ x_t +      <span style="color: #928374;"># </span><span style="color: #928374;">Entrada actual
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.W_hh @ h_prev +  <span style="color: #928374;"># </span><span style="color: #928374;">Memoria anterior
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.b_h               <span style="color: #928374;"># </span><span style="color: #928374;">Sesgo
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Calcular salida
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">y_t</span> = <span style="color: #fb4934;">self</span>.W_hy @ h_t + <span style="color: #fb4934;">self</span>.b_y
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   h_states.append<span style="color: #fe8019;">(</span>h_t<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   y_outputs.append<span style="color: #fe8019;">(</span>y_t<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">h_prev</span> = h_t  <span style="color: #928374;"># </span><span style="color: #928374;">Actualizar para el siguiente paso
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> h_states, y_outputs

<span style="color: #928374;"># </span><span style="color: #928374;">Ejemplo de uso
</span><span style="color: #83a598;">rnn</span> = SimpleRNN<span style="color: #fe8019;">(</span>input_size=2, hidden_size=3, output_size=1<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Secuencia de ejemplo
</span><span style="color: #83a598;">x_seq</span> = <span style="color: #fe8019;">[</span>
<span style="background-color: #3c3836;"> </span>   np.array<span style="color: #b16286;">(</span><span style="color: #b8bb26;">[</span>1, 2<span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   np.array<span style="color: #b16286;">(</span><span style="color: #b8bb26;">[</span>3, 4<span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   np.array<span style="color: #b16286;">(</span><span style="color: #b8bb26;">[</span>5, 6<span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span>
<span style="color: #fe8019;">]</span>

<span style="color: #83a598;">h_states</span>, <span style="color: #83a598;">y_outputs</span> = rnn.forward<span style="color: #fe8019;">(</span>x_seq<span style="color: #fe8019;">)</span>

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Estados ocultos:"</span><span style="color: #fe8019;">)</span>
<span style="color: #fb4934;">for</span> i, h <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">enumerate</span><span style="color: #fe8019;">(</span>h_states<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"h_</span>{i+1}<span style="color: #b8bb26;"> = </span>{h.flatten()}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">Salidas:"</span><span style="color: #fe8019;">)</span>
<span style="color: #fb4934;">for</span> i, y <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">enumerate</span><span style="color: #fe8019;">(</span>y_outputs<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"y_</span>{i+1}<span style="color: #b8bb26;"> = </span>{y.flatten()}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgdbe8dbc" class="outline-4">
<h4 id="orgdbe8dbc">Implementación con Keras/TensorFlow</h4>
<div class="outline-text-4" id="text-orgdbe8dbc">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> tensorflow <span style="color: #fb4934;">import</span> keras
<span style="color: #fb4934;">from</span> tensorflow.keras <span style="color: #fb4934;">import</span> layers
<span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np

<span style="color: #928374;"># </span><span style="color: #928374;">Crear datos de ejemplo
</span><span style="color: #928374;"># </span><span style="color: #928374;">Secuencias de longitud 10, cada elemento tiene 5 caracter&#237;sticas
</span><span style="color: #83a598;">X_train</span> = np.random.randn<span style="color: #fe8019;">(</span>100, 10, 5<span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">(muestras, tiempo, caracter&#237;sticas)
</span><span style="color: #83a598;">y_train</span> = np.random.randint<span style="color: #fe8019;">(</span>0, 2, <span style="color: #b16286;">(</span>100, 1<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Clasificaci&#243;n binaria
</span>
<span style="color: #928374;"># </span><span style="color: #928374;">Crear modelo RNN
</span><span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>10, 5<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">(tiempo, caracter&#237;sticas)
</span><span style="background-color: #3c3836;"> </span>   layers.SimpleRNN<span style="color: #b8bb26;">(</span>32, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">32 neuronas ocultas
</span><span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>16, activation=<span style="color: #b8bb26;">'relu'</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b8bb26;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Salida binaria
</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Compilar modelo
</span>modelo.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   optimizer=<span style="color: #b8bb26;">'adam'</span>,
<span style="background-color: #3c3836;"> </span>   loss=<span style="color: #b8bb26;">'binary_crossentropy'</span>,
<span style="background-color: #3c3836;"> </span>   metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'accuracy'</span><span style="color: #b16286;">]</span>
<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Entrenar
</span>modelo.fit<span style="color: #fe8019;">(</span>X_train, y_train, epochs=10, batch_size=32, verbose=1<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Predecir
</span><span style="color: #83a598;">predicciones</span> = modelo.predict<span style="color: #fe8019;">(</span>X_train<span style="color: #b16286;">[</span>:5<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Predicciones:"</span>, predicciones<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgd02aa86" class="outline-4">
<h4 id="orgd02aa86">Implementación con LSTM</h4>
<div class="outline-text-4" id="text-orgd02aa86">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> tensorflow <span style="color: #fb4934;">import</span> keras
<span style="color: #fb4934;">from</span> tensorflow.keras <span style="color: #fb4934;">import</span> layers

<span style="color: #928374;"># </span><span style="color: #928374;">Modelo LSTM
</span><span style="color: #83a598;">modelo_lstm</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>10, 5<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.LSTM<span style="color: #b8bb26;">(</span>64, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">64 neuronas LSTM
</span><span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>32, activation=<span style="color: #b8bb26;">'relu'</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dropout<span style="color: #b8bb26;">(</span>0.2<span style="color: #b8bb26;">)</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">Regularizaci&#243;n
</span><span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

modelo_lstm.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   optimizer=<span style="color: #b8bb26;">'adam'</span>,
<span style="background-color: #3c3836;"> </span>   loss=<span style="color: #b8bb26;">'binary_crossentropy'</span>,
<span style="background-color: #3c3836;"> </span>   metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'accuracy'</span><span style="color: #b16286;">]</span>
<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org32ff645" class="outline-4">
<h4 id="org32ff645">Implementación con GRU</h4>
<div class="outline-text-4" id="text-org32ff645">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #928374;"># </span><span style="color: #928374;">Modelo GRU
</span><span style="color: #83a598;">modelo_gru</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>10, 5<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.GRU<span style="color: #b8bb26;">(</span>64, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">64 neuronas GRU
</span><span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>32, activation=<span style="color: #b8bb26;">'relu'</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dropout<span style="color: #b8bb26;">(</span>0.2<span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

modelo_gru.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   optimizer=<span style="color: #b8bb26;">'adam'</span>,
<span style="background-color: #3c3836;"> </span>   loss=<span style="color: #b8bb26;">'binary_crossentropy'</span>,
<span style="background-color: #3c3836;"> </span>   metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'accuracy'</span><span style="color: #b16286;">]</span>
<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org38e7b5c" class="outline-3">
<h3 id="org38e7b5c">Ejemplos Prácticos</h3>
<div class="outline-text-3" id="text-org38e7b5c">
</div>
<div id="outline-container-orga6d867e" class="outline-4">
<h4 id="orga6d867e">Ejemplo 1: Predicción de Series Temporales</h4>
<div class="outline-text-4" id="text-orga6d867e">
<p>
Predecir el siguiente valor en una serie temporal.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np
<span style="color: #fb4934;">from</span> tensorflow <span style="color: #fb4934;">import</span> keras
<span style="color: #fb4934;">from</span> tensorflow.keras <span style="color: #fb4934;">import</span> layers

<span style="color: #928374;"># </span><span style="color: #928374;">Generar datos sint&#233;ticos: funci&#243;n seno con ruido
</span><span style="color: #83a598;">t</span> = np.linspace<span style="color: #fe8019;">(</span>0, 4*np.pi, 1000<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">serie</span> = np.sin<span style="color: #fe8019;">(</span>t<span style="color: #fe8019;">)</span> + 0.1 * np.random.randn<span style="color: #fe8019;">(</span>1000<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Crear secuencias: usar 20 valores para predecir el siguiente
</span><span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">crear_secuencias</span><span style="color: #fe8019;">(</span>datos, longitud_secuencia=20<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X</span>, <span style="color: #83a598;">y</span> = <span style="color: #fe8019;">[]</span>, <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> i <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">range</span><span style="color: #fe8019;">(</span><span style="color: #fe8019;">len</span><span style="color: #b16286;">(</span>datos<span style="color: #b16286;">)</span> - longitud_secuencia<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   X.append<span style="color: #fe8019;">(</span>datos<span style="color: #b16286;">[</span>i:i+longitud_secuencia<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   y.append<span style="color: #fe8019;">(</span>datos<span style="color: #b16286;">[</span>i+longitud_secuencia<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> np.array<span style="color: #fe8019;">(</span>X<span style="color: #fe8019;">)</span>, np.array<span style="color: #fe8019;">(</span>y<span style="color: #fe8019;">)</span>

<span style="color: #83a598;">X</span>, <span style="color: #83a598;">y</span> = crear_secuencias<span style="color: #fe8019;">(</span>serie, longitud_secuencia=20<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">X</span> = X.reshape<span style="color: #fe8019;">(</span>X.shape<span style="color: #b16286;">[</span>0<span style="color: #b16286;">]</span>, X.shape<span style="color: #b16286;">[</span>1<span style="color: #b16286;">]</span>, 1<span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">A&#241;adir dimensi&#243;n de caracter&#237;sticas
</span>
<span style="color: #928374;"># </span><span style="color: #928374;">Dividir en train/test
</span><span style="color: #83a598;">split</span> = <span style="color: #fe8019;">int</span><span style="color: #fe8019;">(</span>0.8 * <span style="color: #fe8019;">len</span><span style="color: #b16286;">(</span>X<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="color: #83a598;">X_train</span>, <span style="color: #83a598;">X_test</span> = X<span style="color: #fe8019;">[</span>:split<span style="color: #fe8019;">]</span>, X<span style="color: #fe8019;">[</span>split:<span style="color: #fe8019;">]</span>
<span style="color: #83a598;">y_train</span>, <span style="color: #83a598;">y_test</span> = y<span style="color: #fe8019;">[</span>:split<span style="color: #fe8019;">]</span>, y<span style="color: #fe8019;">[</span>split:<span style="color: #fe8019;">]</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Crear modelo
</span><span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>20, 1<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.LSTM<span style="color: #b8bb26;">(</span>50, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1<span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

modelo.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>optimizer=<span style="color: #b8bb26;">'adam'</span>, loss=<span style="color: #b8bb26;">'mse'</span>, metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'mae'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Entrenar
</span>modelo.fit<span style="color: #fe8019;">(</span>X_train, y_train, epochs=50, batch_size=32, 
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>  validation_data=<span style="color: #b16286;">(</span>X_test, y_test<span style="color: #b16286;">)</span>, verbose=1<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Predecir
</span><span style="color: #83a598;">predicciones</span> = modelo.predict<span style="color: #fe8019;">(</span>X_test<span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"Error promedio: </span>{np.mean(np.<span style="color: #fe8019;">abs</span>(predicciones.flatten() - y_test)):.4f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org7a97e20" class="outline-4">
<h4 id="org7a97e20">Ejemplo 2: Clasificación de Texto</h4>
<div class="outline-text-4" id="text-org7a97e20">
<p>
Clasificar oraciones como positivas o negativas.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> tensorflow <span style="color: #fb4934;">import</span> keras
<span style="color: #fb4934;">from</span> tensorflow.keras <span style="color: #fb4934;">import</span> layers
<span style="color: #fb4934;">from</span> tensorflow.keras.preprocessing.text <span style="color: #fb4934;">import</span> Tokenizer
<span style="color: #fb4934;">from</span> tensorflow.keras.preprocessing.sequence <span style="color: #fb4934;">import</span> pad_sequences
<span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np

<span style="color: #928374;"># </span><span style="color: #928374;">Datos de ejemplo
</span><span style="color: #83a598;">textos</span> = <span style="color: #fe8019;">[</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">"Me encanta este producto"</span>,
<span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">"No me gusta para nada"</span>,
<span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">"Excelente calidad"</span>,
<span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">"Muy malo, no lo recomiendo"</span>,
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">... m&#225;s textos
</span><span style="color: #fe8019;">]</span>

<span style="color: #83a598;">etiquetas</span> = <span style="color: #fe8019;">[</span>1, 0, 1, 0, ...<span style="color: #fe8019;">]</span>  <span style="color: #928374;"># </span><span style="color: #928374;">1=positivo, 0=negativo
</span>
<span style="color: #928374;"># </span><span style="color: #928374;">Tokenizar y convertir a secuencias
</span><span style="color: #83a598;">tokenizer</span> = Tokenizer<span style="color: #fe8019;">(</span>num_words=1000<span style="color: #fe8019;">)</span>
tokenizer.fit_on_texts<span style="color: #fe8019;">(</span>textos<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">secuencias</span> = tokenizer.texts_to_sequences<span style="color: #fe8019;">(</span>textos<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Padding para que todas tengan la misma longitud
</span><span style="color: #83a598;">X</span> = pad_sequences<span style="color: #fe8019;">(</span>secuencias, maxlen=50<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">y</span> = np.array<span style="color: #fe8019;">(</span>etiquetas<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Crear modelo
</span><span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>50,<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Embedding<span style="color: #b8bb26;">(</span>1000, 128<span style="color: #b8bb26;">)</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">Embedding de palabras
</span><span style="background-color: #3c3836;"> </span>   layers.LSTM<span style="color: #b8bb26;">(</span>64, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>32, activation=<span style="color: #b8bb26;">'relu'</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

modelo.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>optimizer=<span style="color: #b8bb26;">'adam'</span>, loss=<span style="color: #b8bb26;">'binary_crossentropy'</span>, metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'accuracy'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Entrenar
</span>modelo.fit<span style="color: #fe8019;">(</span>X, y, epochs=10, batch_size=32, validation_split=0.2<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org74a6e42" class="outline-4">
<h4 id="org74a6e42">Ejemplo 3: Generación de Secuencias</h4>
<div class="outline-text-4" id="text-org74a6e42">
<p>
Generar texto carácter por carácter.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> tensorflow <span style="color: #fb4934;">import</span> keras
<span style="color: #fb4934;">from</span> tensorflow.keras <span style="color: #fb4934;">import</span> layers
<span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np

<span style="color: #928374;"># </span><span style="color: #928374;">Texto de entrenamiento
</span><span style="color: #83a598;">texto</span> = <span style="color: #b8bb26;">"El gato est&#225; durmiendo en el sof&#225;. "</span> * 100

<span style="color: #928374;"># </span><span style="color: #928374;">Crear mapeo car&#225;cter &#8594; &#237;ndice
</span><span style="color: #83a598;">caracteres</span> = <span style="color: #fe8019;">sorted</span><span style="color: #fe8019;">(</span><span style="color: #fe8019;">list</span><span style="color: #b16286;">(</span><span style="color: #fe8019;">set</span><span style="color: #b8bb26;">(</span>texto<span style="color: #b8bb26;">)</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="color: #83a598;">char_to_idx</span> = <span style="color: #fe8019;">{</span>char: idx <span style="color: #fb4934;">for</span> idx, char <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">enumerate</span><span style="color: #b16286;">(</span>caracteres<span style="color: #b16286;">)</span><span style="color: #fe8019;">}</span>
<span style="color: #83a598;">idx_to_char</span> = <span style="color: #fe8019;">{</span>idx: char <span style="color: #fb4934;">for</span> char, idx <span style="color: #fb4934;">in</span> char_to_idx.items<span style="color: #b16286;">()</span><span style="color: #fe8019;">}</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Crear secuencias: usar 40 caracteres para predecir el siguiente
</span><span style="color: #83a598;">longitud_secuencia</span> = 40
<span style="color: #83a598;">X</span>, <span style="color: #83a598;">y</span> = <span style="color: #fe8019;">[]</span>, <span style="color: #fe8019;">[]</span>

<span style="color: #fb4934;">for</span> i <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">range</span><span style="color: #fe8019;">(</span><span style="color: #fe8019;">len</span><span style="color: #b16286;">(</span>texto<span style="color: #b16286;">)</span> - longitud_secuencia<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">secuencia</span> = texto<span style="color: #fe8019;">[</span>i:i+longitud_secuencia<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">siguiente</span> = texto<span style="color: #fe8019;">[</span>i+longitud_secuencia<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   X.append<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>char_to_idx<span style="color: #b8bb26;">[</span>char<span style="color: #b8bb26;">]</span> <span style="color: #fb4934;">for</span> char <span style="color: #fb4934;">in</span> secuencia<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   y.append<span style="color: #fe8019;">(</span>char_to_idx<span style="color: #b16286;">[</span>siguiente<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

<span style="color: #83a598;">X</span> = np.array<span style="color: #fe8019;">(</span>X<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">y</span> = keras.utils.to_categorical<span style="color: #fe8019;">(</span>y, num_classes=<span style="color: #fe8019;">len</span><span style="color: #b16286;">(</span>caracteres<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Crear modelo
</span><span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>longitud_secuencia,<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Embedding<span style="color: #b8bb26;">(</span><span style="color: #fe8019;">len</span><span style="color: #83a598;">(</span>caracteres<span style="color: #83a598;">)</span>, 50<span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.LSTM<span style="color: #b8bb26;">(</span>128, return_sequences=<span style="color: #d3869b;">True</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.LSTM<span style="color: #b8bb26;">(</span>128, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>128, activation=<span style="color: #b8bb26;">'relu'</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span><span style="color: #fe8019;">len</span><span style="color: #83a598;">(</span>caracteres<span style="color: #83a598;">)</span>, activation=<span style="color: #b8bb26;">'softmax'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

modelo.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>optimizer=<span style="color: #b8bb26;">'adam'</span>, loss=<span style="color: #b8bb26;">'categorical_crossentropy'</span>, metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'accuracy'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Entrenar
</span>modelo.fit<span style="color: #fe8019;">(</span>X, y, epochs=50, batch_size=128<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Generar texto
</span><span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">generar_texto</span><span style="color: #fe8019;">(</span>semilla, longitud=100<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">texto_generado</span> = semilla
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> _ <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">range</span><span style="color: #fe8019;">(</span>longitud<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">x</span> = np.array<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span><span style="color: #b8bb26;">[</span>char_to_idx<span style="color: #83a598;">[</span>char<span style="color: #83a598;">]</span> <span style="color: #fb4934;">for</span> char <span style="color: #fb4934;">in</span> texto_generado<span style="color: #83a598;">[</span>-longitud_secuencia:<span style="color: #83a598;">]</span><span style="color: #b8bb26;">]</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">pred</span> = modelo.predict<span style="color: #fe8019;">(</span>x, verbose=0<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">siguiente_idx</span> = np.argmax<span style="color: #fe8019;">(</span>pred<span style="color: #b16286;">[</span>0<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">siguiente_char</span> = idx_to_char<span style="color: #fe8019;">[</span>siguiente_idx<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">texto_generado</span> += siguiente_char
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> texto_generado

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>generar_texto<span style="color: #b16286;">(</span><span style="color: #b8bb26;">"El gato est&#225; "</span>, 50<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgaa07859" class="outline-3">
<h3 id="orgaa07859">Variantes y Extensiones</h3>
<div class="outline-text-3" id="text-orgaa07859">
</div>
<div id="outline-container-orgcdcafab" class="outline-4">
<h4 id="orgcdcafab">RNN Bidireccional</h4>
<div class="outline-text-4" id="text-orgcdcafab">
<p>
Una RNN bidireccional procesa la secuencia en ambas direcciones (hacia adelante y hacia atrás).
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> tensorflow.keras <span style="color: #fb4934;">import</span> layers

<span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>10, 5<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Bidirectional<span style="color: #b8bb26;">(</span>layers.LSTM<span style="color: #83a598;">(</span>32<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">Procesa en ambas direcciones
</span><span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
<b><b>Ventaja</b></b>: Puede usar información tanto del pasado como del "futuro" (en el contexto de la secuencia completa).
</p>

<p>
<b><b>Uso</b></b>: Cuando tienes acceso a toda la secuencia (no predicción en tiempo real).
</p>
</div>
</div>
<div id="outline-container-org6da1340" class="outline-4">
<h4 id="org6da1340">RNN Apiladas (Stacked)</h4>
<div class="outline-text-4" id="text-org6da1340">
<p>
Múltiples capas RNN apiladas para capturar patrones más complejos.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>10, 5<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.LSTM<span style="color: #b8bb26;">(</span>64, return_sequences=<span style="color: #d3869b;">True</span><span style="color: #b8bb26;">)</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">return_sequences=True para apilar
</span><span style="background-color: #3c3836;"> </span>   layers.LSTM<span style="color: #b8bb26;">(</span>32, return_sequences=<span style="color: #d3869b;">True</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.LSTM<span style="color: #b8bb26;">(</span>16, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
<b><b>Ventaja</b></b>: Cada capa puede aprender diferentes niveles de abstracción.
</p>

<p>
<b><b>Desventaja</b></b>: Más parámetros, más lento de entrenar.
</p>
</div>
</div>
<div id="outline-container-org08e1e72" class="outline-4">
<h4 id="org08e1e72">Attention Mechanism</h4>
<div class="outline-text-4" id="text-org08e1e72">
<p>
Los mecanismos de atención permiten que el modelo "preste atención" a partes específicas de la secuencia.
</p>

<p>
Más avanzado, pero muy poderoso. Se usa en arquitecturas como Transformers.
</p>
</div>
</div>
</div>
<div id="outline-container-org4135e1a" class="outline-3">
<h3 id="org4135e1a">Regularización y Mejoras</h3>
<div class="outline-text-3" id="text-org4135e1a">
</div>
<div id="outline-container-orgdf401ff" class="outline-4">
<h4 id="orgdf401ff">Dropout</h4>
<div class="outline-text-4" id="text-orgdf401ff">
<p>
Evita sobreajuste desactivando aleatoriamente algunas neuronas.
</p>

<div class="org-src-container">
<pre class="src src-python">layers.LSTM<span style="color: #fe8019;">(</span>64, dropout=0.2, recurrent_dropout=0.2<span style="color: #fe8019;">)</span>
</pre>
</div>

<ul class="org-ul">
<li><code>dropout</code>: Dropout en las entradas</li>
<li><code>recurrent_dropout</code>: Dropout en las conexiones recurrentes</li>
</ul>
</div>
</div>
<div id="outline-container-org40e3794" class="outline-4">
<h4 id="org40e3794">Early Stopping</h4>
<div class="outline-text-4" id="text-org40e3794">
<p>
Detener el entrenamiento cuando el error de validación deja de mejorar.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> tensorflow.keras.callbacks <span style="color: #fb4934;">import</span> EarlyStopping

<span style="color: #83a598;">callbacks</span> = <span style="color: #fe8019;">[</span>
<span style="background-color: #3c3836;"> </span>   EarlyStopping<span style="color: #b16286;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   monitor=<span style="color: #b8bb26;">'val_loss'</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   patience=10,  <span style="color: #928374;"># </span><span style="color: #928374;">Esperar 10 &#233;pocas sin mejora
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   restore_best_weights=<span style="color: #d3869b;">True</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #b16286;">)</span>
<span style="color: #fe8019;">]</span>

modelo.fit<span style="color: #fe8019;">(</span>X_train, y_train, validation_data=<span style="color: #b16286;">(</span>X_val, y_val<span style="color: #b16286;">)</span>, 
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>  callbacks=callbacks<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-orgd79965c" class="outline-4">
<h4 id="orgd79965c">Gradient Clipping</h4>
<div class="outline-text-4" id="text-orgd79965c">
<p>
Limitar el valor máximo del gradiente para evitar explosión.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> tensorflow.keras.optimizers <span style="color: #fb4934;">import</span> Adam

<span style="color: #83a598;">optimizer</span> = Adam<span style="color: #fe8019;">(</span>clipnorm=1.0<span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Limitar norma del gradiente a 1.0
</span>modelo.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>optimizer=optimizer, loss=<span style="color: #b8bb26;">'binary_crossentropy'</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgb98ceb8" class="outline-3">
<h3 id="orgb98ceb8">Conceptos Clave</h3>
<div class="outline-text-3" id="text-orgb98ceb8">
<ol class="org-ol">
<li><b><b>RNN procesan secuencias</b></b> manteniendo memoria del pasado</li>
<li><b><b>BPTT</b></b> propaga errores hacia atrás en el tiempo</li>
<li><b><b>LSTM y GRU</b></b> solucionan problemas de RNN vanilla</li>
<li><b><b>Parámetros compartidos</b></b> hacen que RNN sean eficientes</li>
</ol>
</div>
<div id="outline-container-org667e0a5" class="outline-4">
<h4 id="org667e0a5">Cuándo Usar RNN</h4>
<div class="outline-text-4" id="text-org667e0a5">
<ul class="org-ul">
<li>Datos secuenciales o temporales</li>
<li>El orden importa</li>
<li>El contexto temporal es relevante</li>
<li>Longitud variable de secuencias</li>
</ul>
</div>
</div>
<div id="outline-container-orga4c90b9" class="outline-4">
<h4 id="orga4c90b9">Cuándo NO Usar RNN</h4>
<div class="outline-text-4" id="text-orga4c90b9">
<ul class="org-ul">
<li>Datos independientes (sin secuencia)</li>
<li>El orden no importa</li>
<li>Problemas que se resuelven bien con feedforward</li>
<li>Secuencias muy largas (considerar Transformers)</li>
</ul>
</div>
</div>
<div id="outline-container-org45f99b5" class="outline-4">
<h4 id="org45f99b5">Próximos Pasos</h4>
<div class="outline-text-4" id="text-org45f99b5">
<ol class="org-ol">
<li>Experimentar con diferentes arquitecturas (LSTM, GRU)</li>
<li>Aprender sobre Transformers (sucesor de RNN)</li>
<li>Explorar aplicaciones específicas (NLP, series temporales)</li>
<li>Estudiar técnicas avanzadas (attention, encoder-decoder)</li>
</ol>
</div>
</div>
</div>
</div>
<div id="outline-container-org1c8a5a1" class="outline-2">
<h2 id="org1c8a5a1">Redes Recurrentes (RNN) con Aplicación al Juego</h2>
<div class="outline-text-2" id="text-org1c8a5a1">
</div>
<div id="outline-container-org9b9bb80" class="outline-3">
<h3 id="org9b9bb80">Introducción</h3>
<div class="outline-text-3" id="text-org9b9bb80">
</div>
<div id="outline-container-org2320d08" class="outline-4">
<h4 id="org2320d08">¿Qué son las Redes Recurrentes?</h4>
<div class="outline-text-4" id="text-org2320d08">
<p>
Las Redes Neuronales Recurrentes (RNN - Recurrent Neural Networks) son
un tipo especial de red neuronal diseñadas para trabajar con
<b><b>secuencias de datos</b></b>. A diferencia de las redes feedforward (como el
MLP), las RNN tienen "memoria" que les permite recordar información de
pasos anteriores.
</p>
</div>
</div>
<div id="outline-container-orgf055e60" class="outline-4">
<h4 id="orgf055e60">¿Por qué RNN para el juego?</h4>
<div class="outline-text-4" id="text-orgf055e60">
<p>
En el juego actual, el MLP solo considera:
</p>
<ul class="org-ul">
<li>Velocidad de la bala (en este momento)</li>
<li>Distancia (en este momento)</li>
</ul>

<p>
Pero una RNN podría considerar:
</p>
<ul class="org-ul">
<li>La <b><b>historia</b></b> de velocidades y distancias anteriores</li>
<li>El <b><b>patrón temporal</b></b> de cómo se mueve la bala</li>
<li>La <b><b>secuencia</b></b> de decisiones anteriores</li>
</ul>

<p>
Esto podría hacer que el modelo entienda mejor el contexto y tome decisiones más inteligentes.
</p>
</div>
</div>
<div id="outline-container-org1137961" class="outline-4">
<h4 id="org1137961">Objetivo de estas notas</h4>
<div class="outline-text-4" id="text-org1137961">
<p>
Aprender:
</p>
<ol class="org-ol">
<li>Conceptos fundamentales de RNN</li>
<li>Diferentes tipos de RNN (vanilla, LSTM, GRU)</li>
<li>Cómo adaptar el juego para usar RNN</li>
<li>Implementación práctica</li>
<li>Comparación RNN vs MLP</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org2fc62c7" class="outline-3">
<h3 id="org2fc62c7">Conceptos Fundamentales</h3>
<div class="outline-text-3" id="text-org2fc62c7">
</div>
<div id="outline-container-orge1d6668" class="outline-4">
<h4 id="orge1d6668">El Problema de las Secuencias</h4>
<div class="outline-text-4" id="text-orge1d6668">
<p>
<b><b>Ejemplo del juego</b></b>:
</p>
<ul class="org-ul">
<li>Frame 1: distancia=500, velocidad=-10 → ¿saltar?</li>
<li>Frame 2: distancia=450, velocidad=-10 → ¿saltar?</li>
<li>Frame 3: distancia=400, velocidad=-10 → ¿saltar?</li>
</ul>

<p>
Un MLP ve cada frame de forma independiente. Una RNN ve la <b><b>secuencia completa</b></b> y puede aprender que:
</p>
<ul class="org-ul">
<li>"Si la distancia está disminuyendo constantemente y la velocidad es negativa, probablemente deba saltar pronto"</li>
</ul>
</div>
</div>
<div id="outline-container-orgb38dc52" class="outline-4">
<h4 id="orgb38dc52">Arquitectura Básica de RNN</h4>
<div class="outline-text-4" id="text-orgb38dc52">
<p>
Una RNN tiene una estructura que permite que la salida de un paso anterior se use como entrada del siguiente:
</p>

<pre class="example" id="org8fd1d6a">
        h[t-1] ──┐
                 │
        x[t] ────┼──→ RNN Cell ──→ h[t] ──→ y[t]
                 │                    │
                 └────────────────────┘
                 (feedback loop)
</pre>

<p>
Donde:
</p>
<ul class="org-ul">
<li><code>x[t]</code> : Entrada en el tiempo t (ej: distancia, velocidad en frame t)</li>
<li><code>h[t]</code> : Estado oculto (memoria) en el tiempo t</li>
<li><code>y[t]</code> : Salida en el tiempo t (ej: decisión de salto)</li>
<li><code>h[t-1]</code> : Estado oculto del paso anterior (memoria)</li>
</ul>
</div>
</div>
<div id="outline-container-org89994e6" class="outline-4">
<h4 id="org89994e6">Ecuación Matemática Básica</h4>
<div class="outline-text-4" id="text-org89994e6">
<p>
Para una RNN simple (vanilla RNN):
</p>

<p>
\[
h_t = \tanh(W_{xh} \cdot x_t + W_{hh} \cdot h_{t-1} + b_h)
\]
</p>

<p>
\[
y_t = W_{hy} \cdot h_t + b_y
\]
</p>

<p>
Donde:
</p>
<ul class="org-ul">
<li><code>W_{xh}</code> : Pesos de entrada a oculto</li>
<li><code>W_{hh}</code> : Pesos de oculto a oculto (la "memoria")</li>
<li><code>W_{hy}</code> : Pesos de oculto a salida</li>
<li><code>b_h, b_y</code> : Sesgos (biases)</li>
</ul>
</div>
</div>
<div id="outline-container-org5c82640" class="outline-4">
<h4 id="org5c82640">Ventajas de RNN</h4>
<div class="outline-text-4" id="text-org5c82640">
<ol class="org-ol">
<li><b><b>Memoria temporal</b></b>: Recuerda información de pasos anteriores</li>
<li><b><b>Secuencias de longitud variable</b></b>: Puede procesar secuencias de diferentes tamaños</li>
<li><b><b>Contexto</b></b>: Entiende el contexto de la secuencia completa</li>
</ol>
</div>
</div>
<div id="outline-container-orgee38827" class="outline-4">
<h4 id="orgee38827">Desventajas de RNN Vanilla</h4>
<div class="outline-text-4" id="text-orgee38827">
<ol class="org-ol">
<li><b><b>Problema del gradiente que desaparece</b></b>: En secuencias largas, el gradiente se vuelve muy pequeño</li>
<li><b><b>Memoria limitada</b></b>: La memoria se desvanece rápidamente</li>
<li><b><b>Dificultad para capturar dependencias largas</b></b>: No puede recordar información de muchos pasos atrás</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-orga373c7d" class="outline-3">
<h3 id="orga373c7d">Matemáticas Detalladas de las Redes Recurrentes</h3>
<div class="outline-text-3" id="text-orga373c7d">
</div>
<div id="outline-container-orgcfcb00e" class="outline-4">
<h4 id="orgcfcb00e">Desglose Paso a Paso de las Ecuaciones</h4>
<div class="outline-text-4" id="text-orgcfcb00e">
<p>
Vamos a descomponer las ecuaciones matemáticas de una RNN paso a paso para entender exactamente qué está pasando.
</p>
</div>
</div>
<div id="outline-container-orgd126d0e" class="outline-4">
<h4 id="orgd126d0e">Ecuación del Estado Oculto (Hidden State)</h4>
<div class="outline-text-4" id="text-orgd126d0e">
<p>
La ecuación fundamental de una RNN es:
</p>

<p>
\[
h_t = \tanh(W_{xh} \cdot x_t + W_{hh} \cdot h_{t-1} + b_h)
\]
</p>

<p>
<b><b>Desglose de cada componente</b></b>:
</p>

<ol class="org-ol">
<li><b><b><code>W_{xh} \cdot x_t</code></b></b>: Transformación lineal de la entrada actual
<ul class="org-ul">
<li><code>W_{xh}</code> es una matriz de pesos de tamaño (dimensión<sub>oculta</sub> × dimensión<sub>entrada</sub>)</li>
<li><code>x_t</code> es el vector de entrada en el tiempo t</li>
<li>Resultado: Vector de tamaño (dimensión<sub>oculta</sub>,)</li>
</ul></li>

<li><b><b><code>W_{hh} \cdot h_{t-1}</code></b></b>: Transformación de la memoria anterior
<ul class="org-ul">
<li><code>W_{hh}</code> es una matriz de pesos de tamaño (dimensión<sub>oculta</sub> × dimensión<sub>oculta</sub>)</li>
<li><code>h_{t-1}</code> es el estado oculto del paso anterior</li>
<li>Resultado: Vector de tamaño (dimensión<sub>oculta</sub>,)</li>
<li><b><b>Esta es la clave de la "memoria"</b></b>: La información del pasado se combina con el presente</li>
</ul></li>

<li><b><b><code>b_h</code></b></b>: Sesgo (bias) del estado oculto
<ul class="org-ul">
<li>Vector de tamaño (dimensión<sub>oculta</sub>,)</li>
<li>Permite ajustar el punto de activación</li>
</ul></li>

<li><b><b>Suma</b></b>: Se suman los tres componentes
<ul class="org-ul">
<li><code>W_{xh} \cdot x_t + W_{hh} \cdot h_{t-1} + b_h</code></li>
<li>Resultado: Vector de tamaño (dimensión<sub>oculta</sub>,)</li>
</ul></li>

<li><b><b><code>tanh()</code></b></b>: Función de activación
<ul class="org-ul">
<li>Comprime el resultado al rango (-1, 1)</li>
<li>Introduce no-linealidad</li>
<li>Ayuda a estabilizar los valores</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-org4cf6278" class="outline-4">
<h4 id="org4cf6278">Ecuación de la Salida</h4>
<div class="outline-text-4" id="text-org4cf6278">
<p>
\[
y_t = W_{hy} \cdot h_t + b_y
\]
</p>

<p>
Esta es más simple:
</p>
<ul class="org-ul">
<li><code>W_{hy}</code>: Matriz de pesos (dimensión<sub>salida</sub> × dimensión<sub>oculta</sub>)</li>
<li><code>h_t</code>: Estado oculto calculado anteriormente</li>
<li><code>b_y</code>: Sesgo de la salida</li>
<li>Resultado: <code>y_t</code>, la predicción en el tiempo t</li>
</ul>
</div>
</div>
<div id="outline-container-orgc474a38" class="outline-4">
<h4 id="orgc474a38">Ejemplo Numérico Concreto</h4>
<div class="outline-text-4" id="text-orgc474a38">
<p>
Vamos a ver un ejemplo paso a paso con números reales.
</p>

<p>
<b><b>Configuración</b></b>:
</p>
<ul class="org-ul">
<li>Dimensión de entrada: 2 (velocidad, distancia)</li>
<li>Dimensión oculta: 3 (3 neuronas en la capa oculta)</li>
<li>Dimensión de salida: 1 (probabilidad de salto)</li>
</ul>

<p>
<b><b>Paso 1: Inicialización (t=0)</b></b>
</p>

<p>
Al inicio, no hay memoria previa, así que <code>h_0 = 0</code> (vector de ceros).
</p>

<p>
<b><b>Paso 2: Primer Frame (t=1)</b></b>
</p>

<p>
<b><b>Entrada</b></b>: <code>x_1 = \begin{bmatrix} -10 \\ 500 \end{bmatrix}</code> (velocidad=-10, distancia=500)
</p>

<p>
<b><b>Pesos</b></b> (ejemplo):
\[
W_{xh} = \begin{bmatrix}
0.1 & 0.2 \\
-0.3 & 0.4 \\
0.2 & -0.1
\end{bmatrix}, \quad
W_{hh} = \begin{bmatrix}
0.5 & 0.1 & 0.2 \\
0.1 & 0.6 & 0.3 \\
0.2 & 0.3 & 0.7
\end{bmatrix}, \quad
b_h = \begin{bmatrix}
0.1 \\
-0.2 \\
0.3
\end{bmatrix}
\]
</p>

<p>
<b><b>Cálculo</b></b>:
</p>

<ol class="org-ol">
<li><code>W_{xh} \cdot x_1</code>:</li>
</ol>
<p>
\[
</p>
\begin{bmatrix}
0.1 & 0.2 \\
-0.3 & 0.4 \\
0.2 & -0.1
\end{bmatrix}
\begin{bmatrix}
-10 \\
500
\end{bmatrix}
<p>
=
</p>
\begin{bmatrix}
0.1(-10) + 0.2(500) \\
-0.3(-10) + 0.4(500) \\
0.2(-10) + -0.1(500)
\end{bmatrix}
<p>
=
</p>
\begin{bmatrix}
-1 + 100 \\
3 + 200 \\
-2 - 50
\end{bmatrix}
<p>
=
</p>
\begin{bmatrix}
99 \\
203 \\
-52
\end{bmatrix}
<p>
\]
</p>

<ol class="org-ol">
<li><code>W_{hh} \cdot h_0</code>:</li>
</ol>
<p>
\[
</p>
\begin{bmatrix}
0.5 & 0.1 & 0.2 \\
0.1 & 0.6 & 0.3 \\
0.2 & 0.3 & 0.7
\end{bmatrix}
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}
<p>
=
</p>
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}
<p>
\]
</p>

<ol class="org-ol">
<li>Suma con bias:</li>
</ol>
<p>
\[
</p>
\begin{bmatrix}
99 \\
203 \\
-52
\end{bmatrix}
<ul class="org-ul">
<li></li>
</ul>
\begin{bmatrix}
0 \\
0 \\
0
\end{bmatrix}
<ul class="org-ul">
<li></li>
</ul>
\begin{bmatrix}
0.1 \\
-0.2 \\
0.3
\end{bmatrix}
<p>
=
</p>
\begin{bmatrix}
99.1 \\
202.8 \\
-51.7
\end{bmatrix}
<p>
\]
</p>

<ol class="org-ol">
<li>Aplicar tanh:</li>
</ol>
<p>
\[
h<sub>1</sub> = tanh\left(\begin{bmatrix}
99.1 <br />
202.8 <br />
-51.7
\end{bmatrix}\right)
&asymp;
</p>
\begin{bmatrix}
1.0 \\
1.0 \\
-1.0
\end{bmatrix}
<p>
\]
</p>

<p>
(Nota: tanh de valores grandes se acerca a ±1)
</p>

<p>
<b><b>Paso 3: Segundo Frame (t=2)</b></b>
</p>

<p>
<b><b>Entrada</b></b>: <code>x_2 = \begin{bmatrix} -10 \\ 450 \end{bmatrix}</code> (distancia disminuyó)
</p>

<p>
<b><b>Cálculo</b></b>:
</p>

<ol class="org-ol">
<li><code>W_{xh} \cdot x_2</code>:</li>
</ol>
<p>
\[
</p>
\begin{bmatrix}
0.1 & 0.2 \\
-0.3 & 0.4 \\
0.2 & -0.1
\end{bmatrix}
\begin{bmatrix}
-10 \\
450
\end{bmatrix}
<p>
=
</p>
\begin{bmatrix}
89 \\
177 \\
-47
\end{bmatrix}
<p>
\]
</p>

<ol class="org-ol">
<li><code>W_{hh} \cdot h_1</code> (¡Ahora usamos la memoria!):</li>
</ol>
<p>
\[
</p>
\begin{bmatrix}
0.5 & 0.1 & 0.2 \\
0.1 & 0.6 & 0.3 \\
0.2 & 0.3 & 0.7
\end{bmatrix}
\begin{bmatrix}
1.0 \\
1.0 \\
-1.0
\end{bmatrix}
<p>
=
</p>
\begin{bmatrix}
0.5 + 0.1 - 0.2 \\
0.1 + 0.6 - 0.3 \\
0.2 + 0.3 - 0.7
\end{bmatrix}
<p>
=
</p>
\begin{bmatrix}
0.4 \\
0.4 \\
-0.2
\end{bmatrix}
<p>
\]
</p>

<ol class="org-ol">
<li>Suma:</li>
</ol>
<p>
\[
</p>
\begin{bmatrix}
89 \\
177 \\
-47
\end{bmatrix}
<ul class="org-ul">
<li></li>
</ul>
\begin{bmatrix}
0.4 \\
0.4 \\
-0.2
\end{bmatrix}
<ul class="org-ul">
<li></li>
</ul>
\begin{bmatrix}
0.1 \\
-0.2 \\
0.3
\end{bmatrix}
<p>
=
</p>
\begin{bmatrix}
89.5 \\
177.2 \\
-46.9
\end{bmatrix}
<p>
\]
</p>

<ol class="org-ol">
<li>Aplicar tanh:</li>
</ol>
<p>
\[
h<sub>2</sub> = tanh\left(\begin{bmatrix}
89.5 <br />
177.2 <br />
-46.9
\end{bmatrix}\right)
&asymp;
</p>
\begin{bmatrix}
1.0 \\
1.0 \\
-1.0
\end{bmatrix}
<p>
\]
</p>

<p>
<b><b>Observación clave</b></b>: Aunque la entrada cambió ligeramente (distancia 500→450), el estado oculto <code>h_2</code> es similar a <code>h_1</code> porque la <b><b>memoria</b></b> (<code>h_1</code>) se combina con la nueva entrada.
</p>
</div>
</div>
<div id="outline-container-orgad06936" class="outline-4">
<h4 id="orgad06936">Cálculo de la Salida</h4>
<div class="outline-text-4" id="text-orgad06936">
<p>
Continuando con el ejemplo, calculemos <code>y_2</code>:
</p>

<p>
<b><b>Pesos de salida</b></b>:
\[
W_{hy} = \begin{bmatrix} 0.3 & -0.5 & 0.8 \end{bmatrix}, \quad
b_y = 0.2
\]
</p>

<p>
<b><b>Cálculo</b></b>:
\[
y<sub>2</sub> = W<sub>hy</sub> &sdot; h<sub>2</sub> + b<sub>y</sub>
= \begin{bmatrix} 0.3 &amp; -0.5 &amp; 0.8 \end{bmatrix}
</p>
\begin{bmatrix}
1.0 \\
1.0 \\
-1.0
\end{bmatrix}
<ul class="org-ul">
<li>0.2</li>
</ul>
<p>
\]
</p>

<p>
\[
= 0.3(1.0) + (-0.5)(1.0) + 0.8(-1.0) + 0.2
= 0.3 - 0.5 - 0.8 + 0.2
= -0.8
\]
</p>

<p>
Si aplicamos sigmoid para obtener probabilidad:
\[
P(\text{salto}) = \sigma(y_2) = \sigma(-0.8) = \frac{1}{1 + e^{0.8}} \approx 0.31
\]
</p>

<p>
Probabilidad de salto ≈ 31% (baja, lo cual tiene sentido si la distancia aún es grande).
</p>
</div>
</div>
<div id="outline-container-orga607972" class="outline-4">
<h4 id="orga607972">Propagación hacia Atrás en el Tiempo (BPTT)</h4>
<div class="outline-text-4" id="text-orga607972">
<p>
El entrenamiento de una RNN usa Backpropagation Through Time (BPTT), que es una extensión del backpropagation estándar.
</p>
</div>
</div>
<div id="outline-container-org7938dfa" class="outline-4">
<h4 id="org7938dfa">Idea General</h4>
<div class="outline-text-4" id="text-org7938dfa">
<p>
En una red feedforward, el error se propaga hacia atrás capa por capa. En una RNN, el error se propaga hacia atrás <b><b>en el tiempo</b></b> también.
</p>
</div>
</div>
<div id="outline-container-org898b7ad" class="outline-4">
<h4 id="org898b7ad">Derivadas Necesarias</h4>
<div class="outline-text-4" id="text-org898b7ad">
<p>
Para entrenar, necesitamos calcular:
</p>

<ol class="org-ol">
<li><b><b><code>∂L/∂W_{hy}</code></b></b>: Gradiente respecto a los pesos de salida</li>
<li><b><b><code>∂L/∂W_{xh}</code></b></b>: Gradiente respecto a los pesos de entrada</li>
<li><b><b><code>∂L/∂W_{hh}</code></b></b>: Gradiente respecto a los pesos recurrentes</li>
<li><b><b><code>∂L/∂b_h</code></b></b> y <b><b><code>∂L/∂b_y</code></b></b>: Gradientes de los sesgos</li>
</ol>
</div>
</div>
<div id="outline-container-orgd5fdb55" class="outline-4">
<h4 id="orgd5fdb55">Cálculo del Gradiente en el Tiempo T</h4>
<div class="outline-text-4" id="text-orgd5fdb55">
<p>
Supongamos que tenemos una secuencia de longitud T y queremos calcular el gradiente en el tiempo final <code>T</code>.
</p>

<p>
<b><b>Pérdida total</b></b>:
\[
L = \sum_{t=1}^{T} L_t(y_t, \hat{y}_t)
\]
</p>

<p>
Donde <code>L_t</code> es la pérdida en el tiempo t (ej: binary cross-entropy).
</p>

<p>
<b><b>Gradiente respecto a <code>W_{hh}</code></b></b>:
</p>

<p>
\[
\frac{\partial L}{\partial W_{hh}} = \sum_{t=1}^{T} \frac{\partial L_t}{\partial W_{hh}}
\]
</p>

<p>
Para calcular <code>∂L_t/∂W_{hh}</code>, necesitamos la regla de la cadena:
</p>

<p>
\[
\frac{\partial L_t}{\partial W_{hh}} = \frac{\partial L_t}{\partial y_t} \cdot \frac{\partial y_t}{\partial h_t} \cdot \frac{\partial h_t}{\partial W_{hh}}
\]
</p>

<p>
El problema es que <code>h_t</code> depende de <code>h_{t-1}</code>, que depende de <code>h_{t-2}</code>, etc.:
</p>

<p>
\[
\frac{\partial h_t}{\partial W_{hh}} = \frac{\partial h_t}{\partial W_{hh}} + \frac{\partial h_t}{\partial h_{t-1}} \cdot \frac{\partial h_{t-1}}{\partial W_{hh}} + \frac{\partial h_t}{\partial h_{t-1}} \cdot \frac{\partial h_{t-1}}{\partial h_{t-2}} \cdot \frac{\partial h_{t-2}}{\partial W_{hh}} + \cdots
\]
</p>

<p>
Esto crea una cadena de multiplicaciones que puede hacer que el gradiente:
</p>
<ul class="org-ul">
<li><b><b>Desaparezca</b></b> (vanishing gradient): Si los valores son &lt; 1, multiplicarlos muchas veces → 0</li>
<li><b><b>Explote</b></b> (exploding gradient): Si los valores son &gt; 1, multiplicarlos muchas veces → ∞</li>
</ul>
</div>
</div>
<div id="outline-container-orgfd4d1ba" class="outline-4">
<h4 id="orgfd4d1ba">Ejemplo del Problema del Gradiente que Desaparece</h4>
<div class="outline-text-4" id="text-orgfd4d1ba">
<p>
Supongamos que <code>∂h_t/∂h_{t-1} = 0.5</code> (valor típico).
</p>

<p>
Para una secuencia de longitud 10:
\[
\frac{\partial h_{10}}{\partial h_1} = 0.5^9 \approx 0.002
\]
</p>

<p>
Para una secuencia de longitud 50:
\[
\frac{\partial h_{50}}{\partial h_1} = 0.5^{49} \approx 1.8 \times 10^{-15}
\]
</p>

<p>
¡El gradiente es prácticamente cero! El modelo no puede aprender dependencias largas.
</p>
</div>
</div>
<div id="outline-container-org607f929" class="outline-4">
<h4 id="org607f929">Visualización del Flujo de Información</h4>
<div class="outline-text-4" id="text-org607f929">
<pre class="example" id="orgd632715">
Tiempo:     t=1        t=2        t=3        t=4
          ┌─────┐    ┌─────┐    ┌─────┐    ┌─────┐
Entrada:  │ x₁  │    │ x₂  │    │ x₃  │    │ x₄  │
          └──┬──┘    └──┬──┘    └──┬──┘    └──┬──┘
             │          │          │          │
          ┌──▼──┐    ┌──▼──┐    ┌──▼──┐    ┌──▼──┐
Memoria:  │ h₀  │───▶│ h₁  │───▶│ h₂  │───▶│ h₃  │───▶...
          └──┬──┘    └──┬──┘    └──┬──┘    └──┬──┘
             │          │          │          │
          ┌──▼──┐    ┌──▼──┐    ┌──▼──┐    ┌──▼──┐
Salida:   │ y₁  │    │ y₂  │    │ y₃  │    │ y₄  │
          └─────┘    └─────┘    └─────┘    └─────┘

Flujo de información:
- Hacia adelante: x_t → h_t → y_t (con h_{t-1} → h_t)
- Hacia atrás: ∂L/∂y_t → ∂L/∂h_t → ∂L/∂h_{t-1} → ... → ∂L/∂h_1
</pre>
</div>
</div>
<div id="outline-container-org04eb302" class="outline-4">
<h4 id="org04eb302">Descomposición de la Ecuación RNN</h4>
<div class="outline-text-4" id="text-org04eb302">
<p>
Vamos a ver qué representa cada término matemáticamente:
</p>

<p>
\[
h_t = \tanh(W_{xh} \cdot x_t + W_{hh} \cdot h_{t-1} + b_h)
\]
</p>

<p>
<b><b>Término 1: <code>W_{xh} \cdot x_t</code></b></b>
</p>
<ul class="org-ul">
<li><b><b>Significado</b></b>: "¿Qué información nueva aporta la entrada actual?"</li>
<li><b><b>En el juego</b></b>: "¿Qué me dice este frame sobre la situación actual?"</li>
<li><b><b>Ejemplo</b></b>: Si distancia=300 y velocidad=-10, esto sugiere peligro</li>
</ul>

<p>
<b><b>Término 2: <code>W_{hh} \cdot h_{t-1}</code></b></b>
</p>
<ul class="org-ul">
<li><b><b>Significado</b></b>: "¿Qué información del pasado es relevante ahora?"</li>
<li><b><b>En el juego</b></b>: "¿Qué aprendí de los frames anteriores?"</li>
<li><b><b>Ejemplo</b></b>: Si en los últimos frames la distancia ha estado disminuyendo, esto es una tendencia importante</li>
</ul>

<p>
<b><b>Suma de ambos términos</b></b>:
</p>
<ul class="org-ul">
<li><b><b>Significado</b></b>: Combinar información nueva con memoria del pasado</li>
<li><b><b>En el juego</b></b>: "Considerando tanto la situación actual como la tendencia, ¿qué debo hacer?"</li>
</ul>
</div>
</div>
<div id="outline-container-org349ed9c" class="outline-4">
<h4 id="org349ed9c">Función de Activación tanh</h4>
<div class="outline-text-4" id="text-org349ed9c">
<p>
¿Por qué tanh y no otra función?
</p>

<p>
<b><b>Propiedades de tanh</b></b>:
</p>
<ul class="org-ul">
<li>Rango: (-1, 1)</li>
<li>Derivada: <code>tanh'(x) = 1 - tanh²(x)</code></li>
<li>Derivada máxima: 1 (en x=0)</li>
<li>Derivada mínima: 0 (cuando |x| es grande)</li>
</ul>

<p>
<b><b>Ventajas</b></b>:
</p>
<ul class="org-ul">
<li>Mantiene los valores acotados (evita explosión)</li>
<li>Es diferenciable en todas partes</li>
<li>Tiene gradiente razonable en el rango útil</li>
</ul>

<p>
<b><b>Desventajas</b></b>:
</p>
<ul class="org-ul">
<li>Para valores grandes, la derivada es muy pequeña → contribuye al problema del gradiente que desaparece</li>
</ul>
</div>
</div>
<div id="outline-container-org68a3482" class="outline-4">
<h4 id="org68a3482">Ejemplo Completo: Secuencia de 3 Frames</h4>
<div class="outline-text-4" id="text-org68a3482">
<p>
Vamos a calcular manualmente una secuencia completa para el juego.
</p>

<p>
<b><b>Configuración simplificada</b></b>:
</p>
<ul class="org-ul">
<li>Dimensión oculta: 2 (para simplificar)</li>
<li>Pesos inicializados aleatoriamente</li>
</ul>

<p>
<b><b>Frame 1</b></b> (t=1):
</p>
<ul class="org-ul">
<li>Entrada: <code>x_1 = [-10, 500]</code> (velocidad, distancia)</li>
<li>Memoria previa: <code>h_0 = [0, 0]</code></li>
</ul>

<p>
\[
h_1 = \tanh\left(W_{xh} \begin{bmatrix} -10 \\ 500 \end{bmatrix} + W_{hh} \begin{bmatrix} 0 \\ 0 \end{bmatrix} + b_h\right)
\]
</p>

<p>
Supongamos que <code>h_1 = [0.3, -0.7]</code>
</p>

<p>
<b><b>Frame 2</b></b> (t=2):
</p>
<ul class="org-ul">
<li>Entrada: <code>x_2 = [-10, 450]</code> (distancia disminuyó)</li>
<li>Memoria previa: <code>h_1 = [0.3, -0.7]</code></li>
</ul>

<p>
\[
h_2 = \tanh\left(W_{xh} \begin{bmatrix} -10 \\ 450 \end{bmatrix} + W_{hh} \begin{bmatrix} 0.3 \\ -0.7 \end{bmatrix} + b_h\right)
\]
</p>

<p>
La memoria <code>h_1</code> ahora influye en <code>h_2</code>. Si <code>W_{hh}</code> tiene valores positivos en la diagonal, <code>h_2</code> recordará parte de <code>h_1</code>.
</p>

<p>
Supongamos que <code>h_2 = [0.5, -0.6]</code>
</p>

<p>
<b><b>Frame 3</b></b> (t=3):
</p>
<ul class="org-ul">
<li>Entrada: <code>x_3 = [-10, 400]</code> (distancia sigue disminuyendo)</li>
<li>Memoria previa: <code>h_2 = [0.5, -0.6]</code></li>
</ul>

<p>
\[
h_3 = \tanh\left(W_{xh} \begin{bmatrix} -10 \\ 400 \end{bmatrix} + W_{hh} \begin{bmatrix} 0.5 \\ -0.6 \end{bmatrix} + b_h\right)
\]
</p>

<p>
Ahora <code>h_3</code> tiene información de <code>h_2</code> (que a su vez tenía información de <code>h_1</code>). La RNN puede "ver" la tendencia: distancia está disminuyendo constantemente.
</p>

<p>
Supongamos que <code>h_3 = [0.8, -0.4]</code>
</p>

<p>
<b><b>Salida final</b></b>:
\[
y_3 = W_{hy} \cdot h_3 + b_y
\]
</p>

<p>
Si <code>y_3 = 0.7</code>, entonces <code>P(salto) = σ(0.7) ≈ 0.67</code> (67% de probabilidad de saltar).
</p>

<p>
<b><b>Interpretación</b></b>: La RNN vio la secuencia [500, 450, 400] y aprendió que la distancia está disminuyendo rápidamente, por lo que aumenta la probabilidad de salto.
</p>
</div>
</div>
<div id="outline-container-org5f96cbc" class="outline-4">
<h4 id="org5f96cbc">Representación Matricial Completa</h4>
<div class="outline-text-4" id="text-org5f96cbc">
<p>
Para una secuencia completa, podemos escribir todo en forma matricial:
</p>

<p>
<b><b>Entradas</b></b>: <code>X = [x_1, x_2, ..., x_T]</code> (matriz T × dimensión<sub>entrada</sub>)
</p>

<p>
<b><b>Estados ocultos</b></b>: <code>H = [h_1, h_2, ..., h_T]</code> (matriz T × dimensión<sub>oculta</sub>)
</p>

<p>
<b><b>Ecuación vectorizada</b></b> (para todos los tiempos a la vez):
\[
H = \tanh(X \cdot W_{xh}^T + H_{shifted} \cdot W_{hh}^T + \mathbf{1} \cdot b_h^T)
\]
</p>

<p>
Donde <code>H_{shifted}</code> es H desplazado un paso (h<sub>0</sub>, h<sub>1</sub>, &#x2026;, h<sub>T-1</sub>).
</p>
</div>
</div>
<div id="outline-container-org2bc82e7" class="outline-4">
<h4 id="org2bc82e7">Cálculo de la Pérdida y Optimización</h4>
<div class="outline-text-4" id="text-org2bc82e7">
<p>
<b><b>Pérdida total</b></b>:
\[
L = -\frac{1}{T}\sum_{t=1}^{T} \left[ y_t^* \log(\sigma(y_t)) + (1-y_t^*) \log(1-\sigma(y_t)) \right]
\]
</p>

<p>
Donde <code>y_t^*</code> es el valor real (0 o 1) y <code>y_t</code> es la predicción.
</p>

<p>
<b><b>Gradiente respecto a <code>W_{hy}</code></b></b>:
\[
\frac{\partial L}{\partial W_{hy}} = \frac{1}{T}\sum_{t=1}^{T} (\sigma(y_t) - y_t^*) \cdot h_t
\]
</p>

<p>
<b><b>Gradiente respecto a <code>W_{xh}</code></b></b> (más complejo debido a la recurrencia):
\[
\frac{\partial L}{\partial W_{xh}} = \sum_{t=1}^{T} \frac{\partial L_t}{\partial W_{xh}}
\]
</p>

<p>
Donde cada término requiere calcular la cadena completa desde t hasta 1.
</p>
</div>
</div>
<div id="outline-container-org99d24e6" class="outline-4">
<h4 id="org99d24e6">Implementación Numérica</h4>
<div class="outline-text-4" id="text-org99d24e6">
<p>
Aquí está cómo se calcula realmente en código:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np

<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">rnn_forward</span><span style="color: #fe8019;">(</span>x_sequence, W_xh, W_hh, W_hy, b_h, b_y<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Forward pass de una RNN.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Args:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   x_sequence: Lista de entradas [x_1, x_2, ..., x_T]
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   W_xh: Pesos entrada&#8594;oculto
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   W_hh: Pesos oculto&#8594;oculto
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   W_hy: Pesos oculto&#8594;salida
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   b_h: Sesgo oculto
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   b_y: Sesgo salida
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Returns:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   h_states: Lista de estados ocultos
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   y_outputs: Lista de salidas
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">h_states</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">y_outputs</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">h_prev</span> = np.zeros<span style="color: #fe8019;">(</span>W_hh.shape<span style="color: #b16286;">[</span>0<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Inicializar h_0 = 0
</span><span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> x_t <span style="color: #fb4934;">in</span> x_sequence:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Calcular estado oculto
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">h_t</span> = np.tanh<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   np.dot<span style="color: #b16286;">(</span>W_xh, x_t<span style="color: #b16286;">)</span> +      <span style="color: #928374;"># </span><span style="color: #928374;">Entrada actual
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   np.dot<span style="color: #b16286;">(</span>W_hh, h_prev<span style="color: #b16286;">)</span> +   <span style="color: #928374;"># </span><span style="color: #928374;">Memoria anterior
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   b_h                      <span style="color: #928374;"># </span><span style="color: #928374;">Sesgo
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Calcular salida
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">y_t</span> = np.dot<span style="color: #fe8019;">(</span>W_hy, h_t<span style="color: #fe8019;">)</span> + b_y
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   h_states.append<span style="color: #fe8019;">(</span>h_t<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   y_outputs.append<span style="color: #fe8019;">(</span>y_t<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">h_prev</span> = h_t  <span style="color: #928374;"># </span><span style="color: #928374;">Actualizar para el siguiente paso
</span><span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> h_states, y_outputs

<span style="color: #928374;"># </span><span style="color: #928374;">Ejemplo de uso
</span><span style="color: #83a598;">x_seq</span> = <span style="color: #fe8019;">[</span>
<span style="background-color: #3c3836;"> </span>   np.array<span style="color: #b16286;">(</span><span style="color: #b8bb26;">[</span>-10, 500<span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   np.array<span style="color: #b16286;">(</span><span style="color: #b8bb26;">[</span>-10, 450<span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   np.array<span style="color: #b16286;">(</span><span style="color: #b8bb26;">[</span>-10, 400<span style="color: #b8bb26;">]</span><span style="color: #b16286;">)</span>
<span style="color: #fe8019;">]</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Pesos (ejemplo, normalmente se inicializan aleatoriamente)
</span><span style="color: #83a598;">W_xh</span> = np.random.randn<span style="color: #fe8019;">(</span>3, 2<span style="color: #fe8019;">)</span> * 0.1
<span style="color: #83a598;">W_hh</span> = np.random.randn<span style="color: #fe8019;">(</span>3, 3<span style="color: #fe8019;">)</span> * 0.1
<span style="color: #83a598;">W_hy</span> = np.random.randn<span style="color: #fe8019;">(</span>1, 3<span style="color: #fe8019;">)</span> * 0.1
<span style="color: #83a598;">b_h</span> = np.zeros<span style="color: #fe8019;">(</span>3<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">b_y</span> = np.array<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>0.0<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

<span style="color: #83a598;">h_states</span>, <span style="color: #83a598;">y_outputs</span> = rnn_forward<span style="color: #fe8019;">(</span>x_seq, W_xh, W_hh, W_hy, b_h, b_y<span style="color: #fe8019;">)</span>

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Estados ocultos:"</span><span style="color: #fe8019;">)</span>
<span style="color: #fb4934;">for</span> i, h <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">enumerate</span><span style="color: #fe8019;">(</span>h_states<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"h_</span>{i+1}<span style="color: #b8bb26;"> = </span>{h}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">Salidas:"</span><span style="color: #fe8019;">)</span>
<span style="color: #fb4934;">for</span> i, y <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">enumerate</span><span style="color: #fe8019;">(</span>y_outputs<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">prob</span> = 1 / <span style="color: #fe8019;">(</span>1 + np.exp<span style="color: #b16286;">(</span>-y<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">sigmoid
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">"y_</span>{i+1}<span style="color: #b8bb26;"> = </span>{y[0]:.3f}<span style="color: #b8bb26;">, P(salto) = </span>{prob[0]:.3f}<span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org0c48849" class="outline-4">
<h4 id="org0c48849">Resumen Matemático</h4>
<div class="outline-text-4" id="text-org0c48849">
<p>
<b><b>Ecuaciones clave</b></b>:
</p>

<ol class="org-ol">
<li><b><b>Estado oculto</b></b>: <code>h_t = tanh(W_{xh}x_t + W_{hh}h_{t-1} + b_h)</code></li>
<li><b><b>Salida</b></b>: <code>y_t = W_{hy}h_t + b_y</code></li>
<li><b><b>Probabilidad</b></b>: <code>P_t = σ(y_t)</code></li>
</ol>

<p>
<b><b>Propiedades importantes</b></b>:
</p>

<ul class="org-ul">
<li><b><b>Memoria</b></b>: <code>h_t</code> contiene información de todos los pasos anteriores (a través de <code>h_{t-1}</code>)</li>
<li><b><b>No-linealidad</b></b>: tanh permite aprender patrones complejos</li>
<li><b><b>Gradientes</b></b>: Se propagan hacia atrás en el tiempo (BPTT)</li>
<li><b><b>Problema</b></b>: Gradientes pueden desaparecer o explotar en secuencias largas</li>
</ul>

<p>
<b><b>Interpretación para el juego</b></b>:
</p>
<ul class="org-ul">
<li>La RNN "recuerda" cómo ha cambiado la distancia y velocidad en los frames anteriores</li>
<li>Combina esta memoria con la información actual</li>
<li>Toma una decisión basada en el contexto completo, no solo el frame actual</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgb7d9d8b" class="outline-3">
<h3 id="orgb7d9d8b">Tipos de Redes Recurrentes</h3>
<div class="outline-text-3" id="text-orgb7d9d8b">
</div>
<div id="outline-container-org71784cb" class="outline-4">
<h4 id="org71784cb">RNN Vanilla (Simple)</h4>
<div class="outline-text-4" id="text-org71784cb">
<p>
La RNN más básica, con la estructura que vimos antes.
</p>

<p>
<b><b>Ventajas</b></b>:
</p>
<ul class="org-ul">
<li>Simple de entender</li>
<li>Rápida de entrenar</li>
<li>Buena para secuencias cortas</li>
</ul>

<p>
<b><b>Desventajas</b></b>:
</p>
<ul class="org-ul">
<li>Problema del gradiente que desaparece</li>
<li>Memoria limitada</li>
</ul>

<p>
<b><b>Uso en el juego</b></b>: Podría funcionar para secuencias de 5-10 frames.
</p>
</div>
</div>
<div id="outline-container-org8835713" class="outline-4">
<h4 id="org8835713">LSTM (Long Short-Term Memory)</h4>
<div class="outline-text-4" id="text-org8835713">
<p>
LSTM fue diseñada para solucionar el problema del gradiente que desaparece.
</p>

<p>
<b><b>Estructura clave</b></b>: La LSTM tiene "puertas" (gates) que controlan el flujo de información:
</p>

<ol class="org-ol">
<li><b><b>Forget Gate</b></b> (Puerta de olvido): Decide qué información olvidar</li>
<li><b><b>Input Gate</b></b> (Puerta de entrada): Decide qué nueva información guardar</li>
<li><b><b>Output Gate</b></b> (Puerta de salida): Decide qué información usar para la salida</li>
</ol>

<pre class="example" id="org8b74946">
        ┌─────────────────┐
        │  Forget Gate    │ ──→ ¿Qué olvidar?
        ├─────────────────┤
        │  Input Gate     │ ──→ ¿Qué recordar?
        ├─────────────────┤
        │  Output Gate    │ ──→ ¿Qué usar?
        └─────────────────┘
</pre>

<p>
<b><b>Ecuaciones principales</b></b>:
</p>

<p>
\[
f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f) \quad \text{(Forget Gate)}
\]
</p>

<p>
\[
i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i) \quad \text{(Input Gate)}
\]
</p>

<p>
\[
\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C) \quad \text{(Candidato a memoria)}
\]
</p>

<p>
\[
C_t = f_t * C_{t-1} + i_t * \tilde{C}_t \quad \text{(Estado de celda)}
\]
</p>

<p>
\[
o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o) \quad \text{(Output Gate)}
\]
</p>

<p>
\[
h_t = o_t * \tanh(C_t) \quad \text{(Estado oculto)}
\]
</p>

<p>
<b><b>Ventajas</b></b>:
</p>
<ul class="org-ul">
<li>Puede recordar información por mucho tiempo</li>
<li>Soluciona el problema del gradiente que desaparece</li>
<li>Muy efectiva para secuencias largas</li>
</ul>

<p>
<b><b>Desventajas</b></b>:
</p>
<ul class="org-ul">
<li>Más compleja computacionalmente</li>
<li>Más parámetros que entrenar</li>
</ul>

<p>
<b><b>Uso en el juego</b></b>: Ideal para secuencias largas (20+ frames) donde necesitas recordar el patrón completo.
</p>
</div>
</div>
<div id="outline-container-orgacc372a" class="outline-4">
<h4 id="orgacc372a">GRU (Gated Recurrent Unit)</h4>
<div class="outline-text-4" id="text-orgacc372a">
<p>
GRU es una versión simplificada de LSTM con solo 2 puertas en lugar de 3.
</p>

<p>
<b><b>Estructura</b></b>:
</p>
<ol class="org-ol">
<li><b><b>Reset Gate</b></b>: Decide qué información del pasado ignorar</li>
<li><b><b>Update Gate</b></b>: Decide qué información actualizar</li>
</ol>

<p>
<b><b>Ecuaciones</b></b>:
</p>

<p>
\[
r_t = \sigma(W_r \cdot [h_{t-1}, x_t] + b_r) \quad \text{(Reset Gate)}
\]
</p>

<p>
\[
z_t = \sigma(W_z \cdot [h_{t-1}, x_t] + b_z) \quad \text{(Update Gate)}
\]
</p>

<p>
\[
\tilde{h}_t = \tanh(W \cdot [r_t * h_{t-1}, x_t] + b) \quad \text{(Candidato)}
\]
</p>

<p>
\[
h_t = (1 - z_t) * h_{t-1} + z_t * \tilde{h}_t \quad \text{(Estado oculto)}
\]
</p>

<p>
<b><b>Ventajas</b></b>:
</p>
<ul class="org-ul">
<li>Más simple que LSTM</li>
<li>Menos parámetros</li>
<li>A menudo funciona tan bien como LSTM</li>
<li>Más rápida de entrenar</li>
</ul>

<p>
<b><b>Desventajas</b></b>:
</p>
<ul class="org-ul">
<li>Menos flexible que LSTM para casos muy complejos</li>
</ul>

<p>
<b><b>Uso en el juego</b></b>: Excelente balance entre simplicidad y poder. Recomendado para la mayoría de casos.
</p>
</div>
</div>
</div>
<div id="outline-container-orgf0ce3a4" class="outline-3">
<h3 id="orgf0ce3a4">Adaptando el Juego para RNN</h3>
<div class="outline-text-3" id="text-orgf0ce3a4">
</div>
<div id="outline-container-org0c489a2" class="outline-4">
<h4 id="org0c489a2">Cambios Necesarios en los Datos</h4>
<div class="outline-text-4" id="text-org0c489a2">
<p>
<b><b>Formato actual (MLP)</b></b>:
Cada muestra es independiente:
</p>
<ul class="org-ul">
<li>Muestra 1: [velocidad, distancia] → salto</li>
<li>Muestra 2: [velocidad, distancia] → salto</li>
<li>Muestra 3: [velocidad, distancia] → salto</li>
</ul>

<p>
<b><b>Formato para RNN (Secuencias)</b></b>:
Necesitamos secuencias de frames:
</p>
<ul class="org-ul">
<li>Secuencia 1: [[v1,d1], [v2,d2], [v3,d3], &#x2026;] → [s1, s2, s3, &#x2026;]</li>
<li>Secuencia 2: [[v1,d1], [v2,d2], [v3,d3], &#x2026;] → [s1, s2, s3, &#x2026;]</li>
</ul>
</div>
</div>
<div id="outline-container-org570e72b" class="outline-4">
<h4 id="org570e72b">Estructura de Datos para RNN</h4>
<div class="outline-text-4" id="text-org570e72b">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #928374;"># </span><span style="color: #928374;">Para MLP (actual)
</span><span style="color: #83a598;">sample</span> = <span style="color: #fe8019;">{</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'velocidad_bala'</span>: -10.0,
<span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'distancia'</span>: 250.0,
<span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'salto'</span>: 1
<span style="color: #fe8019;">}</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Para RNN (nuevo)
</span><span style="color: #83a598;">sequence</span> = <span style="color: #fe8019;">{</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'frames'</span>: <span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">{</span><span style="color: #b8bb26;">'velocidad'</span>: -10.0, <span style="color: #b8bb26;">'distancia'</span>: 500.0<span style="color: #b8bb26;">}</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">{</span><span style="color: #b8bb26;">'velocidad'</span>: -10.0, <span style="color: #b8bb26;">'distancia'</span>: 450.0<span style="color: #b8bb26;">}</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">{</span><span style="color: #b8bb26;">'velocidad'</span>: -10.0, <span style="color: #b8bb26;">'distancia'</span>: 400.0<span style="color: #b8bb26;">}</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">{</span><span style="color: #b8bb26;">'velocidad'</span>: -10.0, <span style="color: #b8bb26;">'distancia'</span>: 350.0<span style="color: #b8bb26;">}</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">{</span><span style="color: #b8bb26;">'velocidad'</span>: -10.0, <span style="color: #b8bb26;">'distancia'</span>: 300.0<span style="color: #b8bb26;">}</span>,
<span style="background-color: #3c3836;"> </span>   <span style="color: #b16286;">]</span>,
<span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'decisiones'</span>: <span style="color: #b16286;">[</span>0, 0, 0, 1, 1<span style="color: #b16286;">]</span>  <span style="color: #928374;"># </span><span style="color: #928374;">&#191;Salt&#243; en cada frame?
</span><span style="color: #fe8019;">}</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org9060f4e" class="outline-4">
<h4 id="org9060f4e">Longitud de Secuencia</h4>
<div class="outline-text-4" id="text-org9060f4e">
<p>
<b><b>Opciones</b></b>:
</p>
<ul class="org-ul">
<li><b><b>Secuencias cortas (5-10 frames)</b></b>: RNN vanilla o GRU, más rápido</li>
<li><b><b>Secuencias medianas (10-20 frames)</b></b>: GRU o LSTM</li>
<li><b><b>Secuencias largas (20+ frames)</b></b>: LSTM</li>
</ul>

<p>
<b><b>Para el juego</b></b>: Recomendamos 10-15 frames, suficiente para capturar el patrón de una bala acercándose.
</p>
</div>
</div>
<div id="outline-container-orgcb74237" class="outline-4">
<h4 id="orgcb74237">Ventana Deslizante (Sliding Window)</h4>
<div class="outline-text-4" id="text-orgcb74237">
<p>
Para crear secuencias a partir de datos continuos:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">crear_secuencias</span><span style="color: #fe8019;">(</span>datos, longitud_secuencia=10<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Convierte datos continuos en secuencias de longitud fija.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Ejemplo:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   datos = [d1, d2, d3, d4, d5, d6, d7, d8, d9, d10, d11, ...]
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Con longitud_secuencia=5:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   secuencia1 = [d1, d2, d3, d4, d5] &#8594; decisi&#243;n en d5
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   secuencia2 = [d2, d3, d4, d5, d6] &#8594; decisi&#243;n en d6
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   secuencia3 = [d3, d4, d5, d6, d7] &#8594; decisi&#243;n en d7
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">secuencias</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">decisiones</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> i <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">range</span><span style="color: #fe8019;">(</span><span style="color: #fe8019;">len</span><span style="color: #b16286;">(</span>datos<span style="color: #b16286;">)</span> - longitud_secuencia + 1<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">secuencia</span> = datos<span style="color: #fe8019;">[</span>i:i+longitud_secuencia<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">La decisi&#243;n es la del &#250;ltimo frame de la secuencia
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">decision</span> = secuencia<span style="color: #fe8019;">[</span>-1<span style="color: #fe8019;">][</span><span style="color: #b8bb26;">'salto'</span><span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   secuencias.append<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span><span style="color: #b8bb26;">(</span>s<span style="color: #83a598;">[</span><span style="color: #b8bb26;">'velocidad'</span><span style="color: #83a598;">]</span>, s<span style="color: #83a598;">[</span><span style="color: #b8bb26;">'distancia'</span><span style="color: #83a598;">]</span><span style="color: #b8bb26;">)</span> <span style="color: #fb4934;">for</span> s <span style="color: #fb4934;">in</span> secuencia<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   decisiones.append<span style="color: #fe8019;">(</span>decision<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> secuencias, decisiones
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgd6eacb8" class="outline-3">
<h3 id="orgd6eacb8">Implementación Práctica</h3>
<div class="outline-text-3" id="text-orgd6eacb8">
</div>
<div id="outline-container-org3381c73" class="outline-4">
<h4 id="org3381c73">Instalación de Dependencias</h4>
<div class="outline-text-4" id="text-org3381c73">
<p>
Para usar RNN en Python necesitamos:
</p>

<div class="org-src-container">
<pre class="src src-bash">pip install tensorflow keras numpy
</pre>
</div>

<p>
O si prefieres PyTorch:
</p>

<div class="org-src-container">
<pre class="src src-bash">pip install torch numpy
</pre>
</div>

<p>
En este tutorial usaremos <b><b>Keras/TensorFlow</b></b> por su simplicidad.
</p>
</div>
</div>
<div id="outline-container-org0d1fd23" class="outline-4">
<h4 id="org0d1fd23">Modificando el Juego: Recolectar Secuencias</h4>
<div class="outline-text-4" id="text-org0d1fd23">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">class</span> <span style="color: #fabd2f;">JuegoRNN</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">__init__</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span><span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">... c&#243;digo existente ...
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">longitud_secuencia</span> = 10  <span style="color: #928374;"># </span><span style="color: #928374;">Frames en cada secuencia
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">buffer_secuencia</span> = <span style="color: #fe8019;">[]</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Buffer para construir secuencias
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">registrar_frame_secuencia</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span><span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""Registra un frame para construir secuencias."""</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> <span style="color: #fb4934;">not</span> <span style="color: #fb4934;">self</span>.bala_disparada:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">distancia</span> = <span style="color: #fe8019;">abs</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>.jugador.x - <span style="color: #fb4934;">self</span>.bala.x<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">frame</span> = <span style="color: #fe8019;">{</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'velocidad_bala'</span>: <span style="color: #fe8019;">float</span><span style="color: #b16286;">(</span><span style="color: #fb4934;">self</span>.velocidad_bala<span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'distancia'</span>: <span style="color: #fe8019;">float</span><span style="color: #b16286;">(</span>distancia<span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'salto'</span>: 0 <span style="color: #fb4934;">if</span> <span style="color: #fb4934;">self</span>.en_suelo <span style="color: #fb4934;">else</span> 1
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">}</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.buffer_secuencia.append<span style="color: #fe8019;">(</span>frame<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Si el buffer est&#225; lleno, guardamos una secuencia
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> <span style="color: #fe8019;">len</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>.buffer_secuencia<span style="color: #fe8019;">)</span> &gt;= <span style="color: #fb4934;">self</span>.longitud_secuencia:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Guardar secuencia completa
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.secuencias_modelo.append<span style="color: #fe8019;">(</span><span style="color: #b16286;">{</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'frames'</span>: <span style="color: #fb4934;">self</span>.buffer_secuencia.copy<span style="color: #b8bb26;">()</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'decision_final'</span>: <span style="color: #fb4934;">self</span>.buffer_secuencia<span style="color: #b8bb26;">[</span>-1<span style="color: #b8bb26;">][</span><span style="color: #b8bb26;">'salto'</span><span style="color: #b8bb26;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b16286;">}</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Deslizar ventana: quitar el primer elemento
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.buffer_secuencia.pop<span style="color: #fe8019;">(</span>0<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org2ebc7d1" class="outline-4">
<h4 id="org2ebc7d1">Preparación de Datos para RNN</h4>
<div class="outline-text-4" id="text-org2ebc7d1">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np
<span style="color: #fb4934;">from</span> sklearn.preprocessing <span style="color: #fb4934;">import</span> StandardScaler

<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">preparar_datos_rnn</span><span style="color: #fe8019;">(</span>secuencias<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Prepara datos para entrenar una RNN.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Args:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   secuencias: Lista de secuencias, cada una con 'frames' y 'decision_final'
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Returns:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   X: Array 3D (num_secuencias, longitud_secuencia, num_caracteristicas)
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   y: Array 1D (num_secuencias,)
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   scaler: Scaler para normalizar
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Extraer caracter&#237;sticas y decisiones
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_list</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">y_list</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> seq <span style="color: #fb4934;">in</span> secuencias:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Extraer caracter&#237;sticas de cada frame
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">features</span> = <span style="color: #fe8019;">[</span><span style="color: #b16286;">[</span>f<span style="color: #b8bb26;">[</span><span style="color: #b8bb26;">'velocidad_bala'</span><span style="color: #b8bb26;">]</span>, f<span style="color: #b8bb26;">[</span><span style="color: #b8bb26;">'distancia'</span><span style="color: #b8bb26;">]</span><span style="color: #b16286;">]</span> <span style="color: #fb4934;">for</span> f <span style="color: #fb4934;">in</span> seq<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'frames'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   X_list.append<span style="color: #fe8019;">(</span>features<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   y_list.append<span style="color: #fe8019;">(</span>seq<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'decision_final'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Convertir a numpy arrays
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X</span> = np.array<span style="color: #fe8019;">(</span>X_list<span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Shape: (num_secuencias, longitud_secuencia, 2)
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">y</span> = np.array<span style="color: #fe8019;">(</span>y_list<span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Shape: (num_secuencias,)
</span><span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Normalizar caracter&#237;sticas
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Reshape para normalizar: (num_secuencias * longitud_secuencia, 2)
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_reshaped</span> = X.reshape<span style="color: #fe8019;">(</span>-1, 2<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">scaler</span> = StandardScaler<span style="color: #fe8019;">()</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_normalized</span> = scaler.fit_transform<span style="color: #fe8019;">(</span>X_reshaped<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Volver a la forma original
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_normalized</span> = X_normalized.reshape<span style="color: #fe8019;">(</span>X.shape<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> X_normalized, y, scaler
</pre>
</div>
</div>
</div>
<div id="outline-container-org0fe380a" class="outline-4">
<h4 id="org0fe380a">Creando una RNN con Keras</h4>
<div class="outline-text-4" id="text-org0fe380a">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> tensorflow <span style="color: #fb4934;">import</span> keras
<span style="color: #fb4934;">from</span> tensorflow.keras <span style="color: #fb4934;">import</span> layers

<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">crear_modelo_rnn</span><span style="color: #fe8019;">(</span>longitud_secuencia=10, num_caracteristicas=2, tipo=<span style="color: #b8bb26;">'GRU'</span><span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Crea un modelo RNN para el juego.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Args:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   longitud_secuencia: N&#250;mero de frames en cada secuencia
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   num_caracteristicas: N&#250;mero de caracter&#237;sticas por frame (2: velocidad, distancia)
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   tipo: 'RNN', 'LSTM', o 'GRU'
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">()</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Capa de entrada
</span><span style="background-color: #3c3836;"> </span>   modelo.add<span style="color: #fe8019;">(</span>layers.Input<span style="color: #b16286;">(</span>shape=<span style="color: #b8bb26;">(</span>longitud_secuencia, num_caracteristicas<span style="color: #b8bb26;">)</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Capa recurrente
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> tipo == <span style="color: #b8bb26;">'LSTM'</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   modelo.add<span style="color: #fe8019;">(</span>layers.LSTM<span style="color: #b16286;">(</span>32, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">elif</span> tipo == <span style="color: #b8bb26;">'GRU'</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   modelo.add<span style="color: #fe8019;">(</span>layers.GRU<span style="color: #b16286;">(</span>32, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">else</span>:  <span style="color: #928374;"># </span><span style="color: #928374;">RNN vanilla
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   modelo.add<span style="color: #fe8019;">(</span>layers.SimpleRNN<span style="color: #b16286;">(</span>32, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Capa densa para la salida
</span><span style="background-color: #3c3836;"> </span>   modelo.add<span style="color: #fe8019;">(</span>layers.Dense<span style="color: #b16286;">(</span>16, activation=<span style="color: #b8bb26;">'relu'</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   modelo.add<span style="color: #fe8019;">(</span>layers.Dropout<span style="color: #b16286;">(</span>0.2<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Regularizaci&#243;n
</span><span style="background-color: #3c3836;"> </span>   modelo.add<span style="color: #fe8019;">(</span>layers.Dense<span style="color: #b16286;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Salida binaria
</span><span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   modelo.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   optimizer=<span style="color: #b8bb26;">'adam'</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   loss=<span style="color: #b8bb26;">'binary_crossentropy'</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'accuracy'</span>, <span style="color: #b8bb26;">'precision'</span>, <span style="color: #b8bb26;">'recall'</span><span style="color: #b16286;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> modelo
</pre>
</div>
</div>
</div>
<div id="outline-container-org1d02aeb" class="outline-4">
<h4 id="org1d02aeb">Entrenamiento de la RNN</h4>
<div class="outline-text-4" id="text-org1d02aeb">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">entrenar_rnn</span><span style="color: #fe8019;">(</span>modelo, X_train, y_train, X_test, y_test, epochs=50<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Entrena el modelo RNN.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Callbacks para mejorar el entrenamiento
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">callbacks</span> = <span style="color: #fe8019;">[</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   keras.callbacks.EarlyStopping<span style="color: #b16286;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   monitor=<span style="color: #b8bb26;">'val_loss'</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   patience=10,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   restore_best_weights=<span style="color: #d3869b;">True</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   keras.callbacks.ReduceLROnPlateau<span style="color: #b16286;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   monitor=<span style="color: #b8bb26;">'val_loss'</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   factor=0.5,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   patience=5
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b16286;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Entrenar
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">historia</span> = modelo.fit<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   X_train, y_train,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   validation_data=<span style="color: #b16286;">(</span>X_test, y_test<span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   epochs=epochs,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   batch_size=32,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   callbacks=callbacks,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   verbose=1
<span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> historia, modelo
</pre>
</div>
</div>
</div>
<div id="outline-container-org35ca976" class="outline-4">
<h4 id="org35ca976">Predicción con RNN</h4>
<div class="outline-text-4" id="text-org35ca976">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">predecir_rnn</span><span style="color: #fe8019;">(</span>modelo, secuencia_actual, scaler<span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Predice si debe saltar bas&#225;ndose en la secuencia actual.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Args:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   modelo: Modelo RNN entrenado
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   secuencia_actual: Lista de frames recientes (longitud_secuencia frames)
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   scaler: Scaler usado para normalizar
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Returns:
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   </span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   probabilidad: Probabilidad de que deba saltar (0-1)
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Preparar secuencia
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">features</span> = <span style="color: #fe8019;">[</span><span style="color: #b16286;">[</span>f<span style="color: #b8bb26;">[</span><span style="color: #b8bb26;">'velocidad_bala'</span><span style="color: #b8bb26;">]</span>, f<span style="color: #b8bb26;">[</span><span style="color: #b8bb26;">'distancia'</span><span style="color: #b8bb26;">]</span><span style="color: #b16286;">]</span> <span style="color: #fb4934;">for</span> f <span style="color: #fb4934;">in</span> secuencia_actual<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X</span> = np.array<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>features<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">Shape: (1, longitud_secuencia, 2)
</span><span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Normalizar
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_reshaped</span> = X.reshape<span style="color: #fe8019;">(</span>-1, 2<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_normalized</span> = scaler.transform<span style="color: #fe8019;">(</span>X_reshaped<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_normalized</span> = X_normalized.reshape<span style="color: #fe8019;">(</span>X.shape<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Predecir
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">probabilidad</span> = modelo.predict<span style="color: #fe8019;">(</span>X_normalized, verbose=0<span style="color: #fe8019;">)[</span>0<span style="color: #fe8019;">][</span>0<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> probabilidad
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org4ff89dd" class="outline-3">
<h3 id="org4ff89dd">Comparación: MLP vs RNN</h3>
<div class="outline-text-3" id="text-org4ff89dd">
</div>
<div id="outline-container-org109a23a" class="outline-4">
<h4 id="org109a23a">Tabla Comparativa</h4>
<div class="outline-text-4" id="text-org109a23a">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Aspecto</th>
<th scope="col" class="org-left">MLP</th>
<th scope="col" class="org-left">RNN</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><b><b>Entrada</b></b></td>
<td class="org-left">Frame individual</td>
<td class="org-left">Secuencia de frames</td>
</tr>

<tr>
<td class="org-left"><b><b>Memoria</b></b></td>
<td class="org-left">No tiene</td>
<td class="org-left">Tiene memoria temporal</td>
</tr>

<tr>
<td class="org-left"><b><b>Contexto</b></b></td>
<td class="org-left">Solo el momento actual</td>
<td class="org-left">Historia completa</td>
</tr>

<tr>
<td class="org-left"><b><b>Complejidad</b></b></td>
<td class="org-left">Simple</td>
<td class="org-left">Más compleja</td>
</tr>

<tr>
<td class="org-left"><b><b>Tiempo entrenamiento</b></b></td>
<td class="org-left">Rápido</td>
<td class="org-left">Más lento</td>
</tr>

<tr>
<td class="org-left"><b><b>Datos necesarios</b></b></td>
<td class="org-left">Menos</td>
<td class="org-left">Más (secuencias)</td>
</tr>

<tr>
<td class="org-left"><b><b>Mejor para</b></b></td>
<td class="org-left">Decisiones instantáneas</td>
<td class="org-left">Patrones temporales</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-orgf76bda9" class="outline-4">
<h4 id="orgf76bda9">Ejemplo Práctico: Misma Situación</h4>
<div class="outline-text-4" id="text-orgf76bda9">
<p>
<b><b>Situación</b></b>: Bala acercándose con velocidad constante.
</p>

<p>
<b><b>MLP</b></b>:
</p>
<ul class="org-ul">
<li>Frame 1: distancia=500 → No salto (correcto)</li>
<li>Frame 2: distancia=450 → No salto (correcto)</li>
<li>Frame 3: distancia=400 → No salto (correcto)</li>
<li>Frame 4: distancia=350 → ¿Salto? (depende del umbral)</li>
</ul>

<p>
<b><b>RNN</b></b>:
</p>
<ul class="org-ul">
<li>Ve la secuencia completa: [500, 450, 400, 350, 300, &#x2026;]</li>
<li>Aprende el patrón: "distancia disminuyendo constantemente"</li>
<li>Puede predecir mejor: "En los próximos frames probablemente deba saltar"</li>
<li>Toma decisiones más informadas basadas en la tendencia</li>
</ul>
</div>
</div>
<div id="outline-container-org6f6facc" class="outline-4">
<h4 id="org6f6facc">Cuándo Usar Cada Una</h4>
<div class="outline-text-4" id="text-org6f6facc">
<p>
<b><b>Usa MLP cuando</b></b>:
</p>
<ul class="org-ul">
<li>Las decisiones son independientes del contexto temporal</li>
<li>Tienes pocos datos</li>
<li>Necesitas un modelo simple y rápido</li>
<li>Cada frame contiene toda la información necesaria</li>
</ul>

<p>
<b><b>Usa RNN cuando</b></b>:
</p>
<ul class="org-ul">
<li>El contexto temporal es importante</li>
<li>Los patrones se desarrollan en el tiempo</li>
<li>Tienes suficientes datos para crear secuencias</li>
<li>Quieres capturar tendencias y patrones</li>
</ul>

<p>
<b><b>Para el juego</b></b>: RNN podría ser mejor porque:
</p>
<ul class="org-ul">
<li>El movimiento de la bala es una secuencia temporal</li>
<li>La decisión de saltar depende de cómo se ha movido la bala</li>
<li>Podemos predecir mejor cuándo saltar viendo la tendencia</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgeaff0de" class="outline-3">
<h3 id="orgeaff0de">Implementación Completa: Juego con RNN</h3>
<div class="outline-text-3" id="text-orgeaff0de">
</div>
<div id="outline-container-org9d47443" class="outline-4">
<h4 id="org9d47443">Estructura del Código</h4>
<div class="outline-text-4" id="text-org9d47443">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> os
<span style="color: #fb4934;">import</span> random
<span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np
<span style="color: #fb4934;">from</span> dataclasses <span style="color: #fb4934;">import</span> dataclass
<span style="color: #fb4934;">from</span> typing <span style="color: #fb4934;">import</span> List, Optional, Tuple
<span style="color: #fb4934;">from</span> collections <span style="color: #fb4934;">import</span> deque

<span style="color: #fb4934;">import</span> pygame
<span style="color: #fb4934;">from</span> sklearn.model_selection <span style="color: #fb4934;">import</span> train_test_split
<span style="color: #fb4934;">from</span> sklearn.preprocessing <span style="color: #fb4934;">import</span> StandardScaler
<span style="color: #fb4934;">from</span> tensorflow <span style="color: #fb4934;">import</span> keras
<span style="color: #fb4934;">from</span> tensorflow.keras <span style="color: #fb4934;">import</span> layers

<span style="color: #fabd2f;">@dataclass</span>
<span style="color: #fb4934;">class</span> <span style="color: #fabd2f;">FrameSecuencia</span>:
<span style="background-color: #3c3836;"> </span>   velocidad_bala: <span style="color: #fe8019;">float</span>
<span style="background-color: #3c3836;"> </span>   distancia: <span style="color: #fe8019;">float</span>
<span style="background-color: #3c3836;"> </span>   salto: <span style="color: #fe8019;">int</span>

<span style="color: #fb4934;">class</span> <span style="color: #fabd2f;">JuegoRNN</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">__init__</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span><span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   pygame.init<span style="color: #fe8019;">()</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">... inicializaci&#243;n de pygame ...
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Par&#225;metros RNN
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">longitud_secuencia</span> = 10
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">buffer_secuencia</span> = deque<span style="color: #fe8019;">(</span>maxlen=<span style="color: #fb4934;">self</span>.longitud_secuencia<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">secuencias_modelo</span>: <span style="color: #fabd2f;">List</span><span style="color: #fe8019;">[</span><span style="color: #fe8019;">dict</span><span style="color: #fe8019;">]</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Modelo
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">modelo_rnn</span> = <span style="color: #d3869b;">None</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">scaler_rnn</span> = <span style="color: #d3869b;">None</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">modelo_entrenado</span> = <span style="color: #d3869b;">False</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">registrar_frame_secuencia</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span><span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""Registra un frame para construir secuencias."""</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> <span style="color: #fb4934;">not</span> <span style="color: #fb4934;">self</span>.bala_disparada:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">distancia</span> = <span style="color: #fe8019;">abs</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>.jugador.x - <span style="color: #fb4934;">self</span>.bala.x<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">frame</span> = FrameSecuencia<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   velocidad_bala=<span style="color: #fe8019;">float</span><span style="color: #b16286;">(</span><span style="color: #fb4934;">self</span>.velocidad_bala<span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   distancia=<span style="color: #fe8019;">float</span><span style="color: #b16286;">(</span>distancia<span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   salto=0 <span style="color: #fb4934;">if</span> <span style="color: #fb4934;">self</span>.en_suelo <span style="color: #fb4934;">else</span> 1
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.buffer_secuencia.append<span style="color: #fe8019;">(</span>frame<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Cuando el buffer est&#225; lleno, guardamos secuencia
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> <span style="color: #fe8019;">len</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>.buffer_secuencia<span style="color: #fe8019;">)</span> == <span style="color: #fb4934;">self</span>.longitud_secuencia:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.secuencias_modelo.append<span style="color: #fe8019;">(</span><span style="color: #b16286;">{</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'frames'</span>: <span style="color: #fe8019;">list</span><span style="color: #b8bb26;">(</span><span style="color: #fb4934;">self</span>.buffer_secuencia<span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">'decision'</span>: <span style="color: #fb4934;">self</span>.buffer_secuencia<span style="color: #b8bb26;">[</span>-1<span style="color: #b8bb26;">]</span>.salto
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b16286;">}</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">preparar_datos_rnn</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span><span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""Prepara datos para entrenar RNN."""</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> <span style="color: #fe8019;">len</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>.secuencias_modelo<span style="color: #fe8019;">)</span> &lt; 50:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> <span style="color: #d3869b;">None</span>, <span style="color: #d3869b;">None</span>, <span style="color: #d3869b;">None</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_list</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">y_list</span> = <span style="color: #fe8019;">[]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">for</span> seq <span style="color: #fb4934;">in</span> <span style="color: #fb4934;">self</span>.secuencias_modelo:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">features</span> = <span style="color: #fe8019;">[</span><span style="color: #b16286;">[</span>f.velocidad_bala, f.distancia<span style="color: #b16286;">]</span> <span style="color: #fb4934;">for</span> f <span style="color: #fb4934;">in</span> seq<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'frames'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   X_list.append<span style="color: #fe8019;">(</span>features<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   y_list.append<span style="color: #fe8019;">(</span>seq<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'decision'</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X</span> = np.array<span style="color: #fe8019;">(</span>X_list<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">y</span> = np.array<span style="color: #fe8019;">(</span>y_list<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Normalizar
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_reshaped</span> = X.reshape<span style="color: #fe8019;">(</span>-1, 2<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">scaler</span> = StandardScaler<span style="color: #fe8019;">()</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_normalized</span> = scaler.fit_transform<span style="color: #fe8019;">(</span>X_reshaped<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_normalized</span> = X_normalized.reshape<span style="color: #fe8019;">(</span>X.shape<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> X_normalized, y, scaler
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">crear_modelo_rnn</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>, tipo=<span style="color: #b8bb26;">'GRU'</span><span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""Crea modelo RNN."""</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span><span style="color: #fb4934;">self</span>.longitud_secuencia, 2<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   layers.GRU<span style="color: #b8bb26;">(</span>32, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span> <span style="color: #fb4934;">if</span> tipo == <span style="color: #b8bb26;">'GRU'</span> <span style="color: #fb4934;">else</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   layers.LSTM<span style="color: #b8bb26;">(</span>32, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span> <span style="color: #fb4934;">if</span> tipo == <span style="color: #b8bb26;">'LSTM'</span> <span style="color: #fb4934;">else</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   layers.SimpleRNN<span style="color: #b8bb26;">(</span>32, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>16, activation=<span style="color: #b8bb26;">'relu'</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   layers.Dropout<span style="color: #b8bb26;">(</span>0.2<span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b8bb26;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   modelo.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   optimizer=<span style="color: #b8bb26;">'adam'</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   loss=<span style="color: #b8bb26;">'binary_crossentropy'</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'accuracy'</span><span style="color: #b16286;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> modelo
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">entrenar_rnn</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>, tipo=<span style="color: #b8bb26;">'GRU'</span><span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""Entrena el modelo RNN."""</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X</span>, <span style="color: #83a598;">y</span>, <span style="color: #83a598;">scaler</span> = <span style="color: #fb4934;">self</span>.preparar_datos_rnn<span style="color: #fe8019;">()</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> X <span style="color: #fb4934;">is</span> <span style="color: #d3869b;">None</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> <span style="color: #d3869b;">False</span>, <span style="color: #b8bb26;">"Necesitas m&#225;s secuencias (&gt;= 50)."</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Dividir datos
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_train</span>, <span style="color: #83a598;">X_test</span>, <span style="color: #83a598;">y_train</span>, <span style="color: #83a598;">y_test</span> = train_test_split<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   X, y, test_size=0.2, random_state=42
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Crear y entrenar modelo
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">modelo</span> = <span style="color: #fb4934;">self</span>.crear_modelo_rnn<span style="color: #fe8019;">(</span>tipo<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">historia</span> = modelo.fit<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   X_train, y_train,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   validation_data=<span style="color: #b16286;">(</span>X_test, y_test<span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   epochs=50,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   batch_size=32,
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   verbose=0
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Evaluar
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">acc</span> = modelo.evaluate<span style="color: #fe8019;">(</span>X_test, y_test, verbose=0<span style="color: #fe8019;">)[</span>1<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">modelo_rnn</span> = modelo
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">scaler_rnn</span> = scaler
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">modelo_entrenado</span> = <span style="color: #d3869b;">True</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> <span style="color: #d3869b;">True</span>, f<span style="color: #b8bb26;">"RNN (</span>{tipo}<span style="color: #b8bb26;">) entrenada. Accuracy test &#8776; </span>{acc:.3f}<span style="color: #b8bb26;">"</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">decision_auto_rnn</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span><span style="color: #fe8019;">)</span> -&gt; <span style="color: #fe8019;">bool</span>:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""Decide si saltar usando RNN."""</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> <span style="color: #fb4934;">not</span> <span style="color: #fb4934;">self</span>.modelo_entrenado <span style="color: #fb4934;">or</span> <span style="color: #fe8019;">len</span><span style="color: #fe8019;">(</span><span style="color: #fb4934;">self</span>.buffer_secuencia<span style="color: #fe8019;">)</span> &lt; <span style="color: #fb4934;">self</span>.longitud_secuencia:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> <span style="color: #d3869b;">False</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> <span style="color: #fb4934;">not</span> <span style="color: #fb4934;">self</span>.bala_disparada <span style="color: #fb4934;">or</span> <span style="color: #fb4934;">not</span> <span style="color: #fb4934;">self</span>.en_suelo:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> <span style="color: #d3869b;">False</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Preparar secuencia actual
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">features</span> = <span style="color: #fe8019;">[</span><span style="color: #b16286;">[</span>f.velocidad_bala, f.distancia<span style="color: #b16286;">]</span> <span style="color: #fb4934;">for</span> f <span style="color: #fb4934;">in</span> <span style="color: #fb4934;">self</span>.buffer_secuencia<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X</span> = np.array<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>features<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Normalizar
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_reshaped</span> = X.reshape<span style="color: #fe8019;">(</span>-1, 2<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_normalized</span> = <span style="color: #fb4934;">self</span>.scaler_rnn.transform<span style="color: #fe8019;">(</span>X_reshaped<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">X_normalized</span> = X_normalized.reshape<span style="color: #fe8019;">(</span>X.shape<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Predecir
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">proba</span> = <span style="color: #fb4934;">self</span>.modelo_rnn.predict<span style="color: #fe8019;">(</span>X_normalized, verbose=0<span style="color: #fe8019;">)[</span>0<span style="color: #fe8019;">][</span>0<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">self</span>.<span style="color: #83a598;">ultima_proba_salto</span> = proba
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">return</span> proba &gt;= 0.5
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org04afa66" class="outline-3">
<h3 id="org04afa66">Visualización de Secuencias</h3>
<div class="outline-text-3" id="text-org04afa66">
</div>
<div id="outline-container-org33286be" class="outline-4">
<h4 id="org33286be">Graficar Secuencias Temporales</h4>
<div class="outline-text-4" id="text-org33286be">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> matplotlib.pyplot <span style="color: #fb4934;">as</span> plt

<span style="color: #fb4934;">def</span> <span style="color: #b8bb26;">graficar_secuencia</span><span style="color: #fe8019;">(</span>secuencia, titulo=<span style="color: #b8bb26;">"Secuencia de Juego"</span><span style="color: #fe8019;">)</span>:
<span style="background-color: #3c3836;"> </span>   <span style="color: #dfd2b8;">"""
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   Grafica una secuencia mostrando c&#243;mo cambian distancia y velocidad en el tiempo.
</span><span style="color: #dfd2b8; background-color: #3c3836;"> </span><span style="color: #dfd2b8;">   """</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">frames</span> = secuencia<span style="color: #fe8019;">[</span><span style="color: #b8bb26;">'frames'</span><span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">tiempos</span> = <span style="color: #fe8019;">list</span><span style="color: #fe8019;">(</span><span style="color: #fe8019;">range</span><span style="color: #b16286;">(</span><span style="color: #fe8019;">len</span><span style="color: #b8bb26;">(</span>frames<span style="color: #b8bb26;">)</span><span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">distancias</span> = <span style="color: #fe8019;">[</span>f.distancia <span style="color: #fb4934;">for</span> f <span style="color: #fb4934;">in</span> frames<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">velocidades</span> = <span style="color: #fe8019;">[</span><span style="color: #fe8019;">abs</span><span style="color: #b16286;">(</span>f.velocidad_bala<span style="color: #b16286;">)</span> <span style="color: #fb4934;">for</span> f <span style="color: #fb4934;">in</span> frames<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">decisiones</span> = <span style="color: #fe8019;">[</span>f.salto <span style="color: #fb4934;">for</span> f <span style="color: #fb4934;">in</span> frames<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   fig, <span style="color: #fe8019;">(</span><span style="color: #83a598;">ax1</span>, <span style="color: #83a598;">ax2</span><span style="color: #fe8019;">)</span> = plt.subplots<span style="color: #fe8019;">(</span>2, 1, figsize=<span style="color: #b16286;">(</span>10, 6<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Gr&#225;fica de distancia
</span><span style="background-color: #3c3836;"> </span>   ax1.plot<span style="color: #fe8019;">(</span>tiempos, distancias, <span style="color: #b8bb26;">'b-o'</span>, label=<span style="color: #b8bb26;">'Distancia'</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   ax1.set_ylabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'Distancia'</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   ax1.set_title<span style="color: #fe8019;">(</span>f<span style="color: #b8bb26;">'</span>{titulo}<span style="color: #b8bb26;"> - Distancia vs Tiempo'</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   ax1.grid<span style="color: #fe8019;">(</span><span style="color: #d3869b;">True</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   ax1.legend<span style="color: #fe8019;">()</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Gr&#225;fica de velocidad y decisiones
</span><span style="background-color: #3c3836;"> </span>   ax2.plot<span style="color: #fe8019;">(</span>tiempos, velocidades, <span style="color: #b8bb26;">'r-s'</span>, label=<span style="color: #b8bb26;">'Velocidad (abs)'</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #928374;"># </span><span style="color: #928374;">Marcar frames donde se salt&#243;
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #83a598;">saltos</span> = <span style="color: #fe8019;">[</span>i <span style="color: #fb4934;">for</span> i, d <span style="color: #fb4934;">in</span> <span style="color: #fe8019;">enumerate</span><span style="color: #b16286;">(</span>decisiones<span style="color: #b16286;">)</span> <span style="color: #fb4934;">if</span> d == 1<span style="color: #fe8019;">]</span>
<span style="background-color: #3c3836;"> </span>   <span style="color: #fb4934;">if</span> saltos:
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   ax2.scatter<span style="color: #fe8019;">(</span>saltos, <span style="color: #b16286;">[</span>velocidades<span style="color: #b8bb26;">[</span>i<span style="color: #b8bb26;">]</span> <span style="color: #fb4934;">for</span> i <span style="color: #fb4934;">in</span> saltos<span style="color: #b16286;">]</span>, 
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>  c=<span style="color: #b8bb26;">'green'</span>, s=100, marker=<span style="color: #b8bb26;">'*'</span>, label=<span style="color: #b8bb26;">'Salto'</span>, zorder=5<span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   ax2.set_xlabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'Frame'</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   ax2.set_ylabel<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'Velocidad'</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   ax2.set_title<span style="color: #fe8019;">(</span><span style="color: #b8bb26;">'Velocidad y Decisiones'</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   ax2.grid<span style="color: #fe8019;">(</span><span style="color: #d3869b;">True</span><span style="color: #fe8019;">)</span>
<span style="background-color: #3c3836;"> </span>   ax2.legend<span style="color: #fe8019;">()</span>
<span style="background-color: #3c3836;"> </span>   
<span style="background-color: #3c3836;"> </span>   plt.tight_layout<span style="color: #fe8019;">()</span>
<span style="background-color: #3c3836;"> </span>   plt.show<span style="color: #fe8019;">()</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org176c179" class="outline-3">
<h3 id="org176c179">Actividades Prácticas</h3>
<div class="outline-text-3" id="text-org176c179">
</div>
<div id="outline-container-orgaa3a1ee" class="outline-4">
<h4 id="orgaa3a1ee">Actividad 1: Comparar MLP vs RNN</h4>
<div class="outline-text-4" id="text-orgaa3a1ee">
<ol class="org-ol">
<li>Entrena un modelo MLP con el juego</li>
<li>Entrena un modelo RNN (GRU) con el mismo juego</li>
<li>Compara:
<ul class="org-ul">
<li>Accuracy en test</li>
<li>Precision y Recall</li>
<li>Comportamiento en modo auto</li>
<li>¿Cuál juega mejor?</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-orgbd8821b" class="outline-4">
<h4 id="orgbd8821b">Actividad 2: Experimentar con Longitud de Secuencia</h4>
<div class="outline-text-4" id="text-orgbd8821b">
<ol class="org-ol">
<li>Entrena RNN con secuencias de 5 frames</li>
<li>Entrena RNN con secuencias de 10 frames</li>
<li>Entrena RNN con secuencias de 20 frames</li>
<li>Compara resultados:
<ul class="org-ul">
<li>¿Cuál tiene mejor accuracy?</li>
<li>¿Cuál se entrena más rápido?</li>
<li>¿Cuál juega mejor en modo auto?</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-orgfbcebb9" class="outline-4">
<h4 id="orgfbcebb9">Actividad 3: Comparar Tipos de RNN</h4>
<div class="outline-text-4" id="text-orgfbcebb9">
<ol class="org-ol">
<li>Entrena una RNN vanilla (SimpleRNN)</li>
<li>Entrena una GRU</li>
<li>Entrena una LSTM</li>
<li>Compara:
<ul class="org-ul">
<li>Tiempo de entrenamiento</li>
<li>Accuracy</li>
<li>Comportamiento en el juego</li>
</ul></li>
</ol>
</div>
</div>
<div id="outline-container-orga32e15e" class="outline-4">
<h4 id="orga32e15e">Actividad 4: Análisis de Secuencias</h4>
<div class="outline-text-4" id="text-orga32e15e">
<ol class="org-ol">
<li>Exporta secuencias a CSV</li>
<li>Visualiza varias secuencias con gráficas</li>
<li>Identifica patrones:
<ul class="org-ul">
<li>¿Qué patrones llevan a saltar?</li>
<li>¿Qué patrones llevan a no saltar?</li>
<li>¿Hay tendencias claras?</li>
</ul></li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org0b6cbde" class="outline-3">
<h3 id="org0b6cbde">Conceptos Avanzados</h3>
<div class="outline-text-3" id="text-org0b6cbde">
</div>
<div id="outline-container-orgeda4ef9" class="outline-4">
<h4 id="orgeda4ef9">Bidireccionalidad (Bidirectional RNN)</h4>
<div class="outline-text-4" id="text-orgeda4ef9">
<p>
Una RNN bidireccional procesa la secuencia en ambas direcciones:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">from</span> tensorflow.keras <span style="color: #fb4934;">import</span> layers

<span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>longitud_secuencia, 2<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Bidirectional<span style="color: #b8bb26;">(</span>layers.GRU<span style="color: #83a598;">(</span>32<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
<b><b>Ventaja</b></b>: Puede usar información tanto del pasado como del "futuro" (en el contexto de la secuencia).
</p>

<p>
<b><b>Para el juego</b></b>: Probablemente no necesario, ya que solo tenemos información del pasado.
</p>
</div>
</div>
<div id="outline-container-orgb2a61b8" class="outline-4">
<h4 id="orgb2a61b8">Stacked RNN (RNN Apiladas)</h4>
<div class="outline-text-4" id="text-orgb2a61b8">
<p>
Múltiples capas RNN apiladas para capturar patrones más complejos:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">modelo</span> = keras.Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   layers.Input<span style="color: #b8bb26;">(</span>shape=<span style="color: #83a598;">(</span>longitud_secuencia, 2<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.GRU<span style="color: #b8bb26;">(</span>32, return_sequences=<span style="color: #d3869b;">True</span><span style="color: #b8bb26;">)</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">return_sequences=True para apilar
</span><span style="background-color: #3c3836;"> </span>   layers.GRU<span style="color: #b8bb26;">(</span>16, return_sequences=<span style="color: #d3869b;">False</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   layers.Dense<span style="color: #b8bb26;">(</span>1, activation=<span style="color: #b8bb26;">'sigmoid'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org67f236f" class="outline-4">
<h4 id="org67f236f">Attention Mechanism</h4>
<div class="outline-text-4" id="text-org67f236f">
<p>
Los mecanismos de atención permiten que el modelo "preste atención" a partes específicas de la secuencia. Más avanzado, pero muy poderoso.
</p>
</div>
</div>
<div id="outline-container-org25ca826" class="outline-4">
<h4 id="org25ca826">Regularización para RNN</h4>
<div class="outline-text-4" id="text-org25ca826">
<ul class="org-ul">
<li><b><b>Dropout</b></b>: Ya lo usamos en el ejemplo</li>
<li><b><b>Recurrent Dropout</b></b>: Dropout específico para conexiones recurrentes</li>
<li><b><b>L2 Regularization</b></b>: Penalizar pesos grandes</li>
</ul>

<div class="org-src-container">
<pre class="src src-python">layers.GRU<span style="color: #fe8019;">(</span>32, 
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>  dropout=0.2,           <span style="color: #928374;"># </span><span style="color: #928374;">Dropout en inputs
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>  recurrent_dropout=0.2, <span style="color: #928374;"># </span><span style="color: #928374;">Dropout en conexiones recurrentes
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>  kernel_regularizer=keras.regularizers.l2<span style="color: #b16286;">(</span>0.01<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-org60178a7" class="outline-3">
<h3 id="org60178a7">Troubleshooting Común</h3>
<div class="outline-text-3" id="text-org60178a7">
</div>
<div id="outline-container-orgc99cc70" class="outline-4">
<h4 id="orgc99cc70">Problema: "No hay suficientes datos"</h4>
<div class="outline-text-4" id="text-orgc99cc70">
<p>
<b><b>Solución</b></b>:
</p>
<ul class="org-ul">
<li>Reduce la longitud de secuencia</li>
<li>Recolecta más datos jugando más tiempo</li>
<li>Usa ventana deslizante con solapamiento</li>
</ul>
</div>
</div>
<div id="outline-container-org9f9b50c" class="outline-4">
<h4 id="org9f9b50c">Problema: "El modelo no aprende (loss no baja)"</h4>
<div class="outline-text-4" id="text-org9f9b50c">
<p>
<b><b>Soluciones</b></b>:
</p>
<ul class="org-ul">
<li>Verifica que los datos estén normalizados</li>
<li>Reduce el learning rate</li>
<li>Aumenta el número de neuronas</li>
<li>Prueba diferentes optimizadores</li>
</ul>
</div>
</div>
<div id="outline-container-orgc55e954" class="outline-4">
<h4 id="orgc55e954">Problema: "Overfitting (accuracy train &gt;&gt; accuracy test)"</h4>
<div class="outline-text-4" id="text-orgc55e954">
<p>
<b><b>Soluciones</b></b>:
</p>
<ul class="org-ul">
<li>Aumenta dropout</li>
<li>Reduce el número de neuronas</li>
<li>Añade más datos</li>
<li>Usa early stopping (ya incluido en el código)</li>
</ul>
</div>
</div>
<div id="outline-container-org0133f95" class="outline-4">
<h4 id="org0133f95">Problema: "Entrenamiento muy lento"</h4>
<div class="outline-text-4" id="text-org0133f95">
<p>
<b><b>Soluciones</b></b>:
</p>
<ul class="org-ul">
<li>Reduce la longitud de secuencia</li>
<li>Reduce el número de neuronas</li>
<li>Usa GRU en lugar de LSTM</li>
<li>Reduce batch size (pero puede afectar estabilidad)</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org1045288" class="outline-2">
<h2 id="org1045288">Redes Neuronales LSTM (Long Short-Term Memory)</h2>
<div class="outline-text-2" id="text-org1045288">
<p>
Las redes neuronales LSTM (<b>Long Short-Term Memory</b>) son un tipo especial
de <b><b>Red Neuronal Recurrente (RNN)</b></b> diseñada para trabajar con datos
<b><b>secuenciales</b></b> y, en particular, para <b><b>recordar dependencias a largo
plazo</b></b>.
</p>

<p>
Se utilizan cuando el <b>orden</b> de los datos importa:
</p>

<ul class="org-ul">
<li>Texto (oraciones, párrafos, documentos).</li>
<li>Series temporales (precios, temperatura, señales).</li>
<li>Audio y voz.</li>
<li>Secuencias de eventos (logs, clics, acciones de usuario, etc.).</li>
</ul>

<p>
Su principal aporte es resolver (o al menos mitigar fuertemente) el
problema del <b><b>desvanecimiento del gradiente (vanishing gradient)</b></b> que
afecta a las RNN simples cuando manejan secuencias largas.
</p>
</div>
<div id="outline-container-orgbb76339" class="outline-3">
<h3 id="orgbb76339">Estructura general de una RNN</h3>
<div class="outline-text-3" id="text-orgbb76339">
<p>
En una RNN “simple”, en cada paso temporal \(t\):
</p>

<ul class="org-ul">
<li>Se recibe una entrada \(x_t\).</li>
<li>Se tiene un estado oculto anterior \(h_{t-1}\).</li>
<li>Se actualiza el estado oculto actual \(h_t\) con:</li>
</ul>

<div class="latex" id="org23f0f90">
<p>
h<sub>t</sub> = &phi;(W<sub>xh</sub> x<sub>t</sub> + W<sub>hh</sub> h<sub>t-1</sub> + b<sub>h</sub>)
</p>

</div>

<p>
donde:
</p>

<ul class="org-ul">
<li>\(W_{xh}\) y \(W_{hh}\) son matrices de pesos,</li>
<li>\(b_h\) es el sesgo,</li>
<li>\(\phi\) es una función de activación (típicamente <code>tanh</code> o <code>ReLU</code>).</li>
</ul>

<p>
El estado final (o todos los estados) se usan para hacer predicciones.
</p>
</div>
<div id="outline-container-org9f5e7a6" class="outline-4">
<h4 id="org9f5e7a6">Problema: vanishing y exploding gradients</h4>
<div class="outline-text-4" id="text-org9f5e7a6">
<p>
Durante el entrenamiento, se aplica <b>Backpropagation Through Time (BPTT)</b>,
es decir, se retropropagan los gradientes a través de todos los pasos
temporales.
</p>

<p>
En secuencias largas:
</p>

<ul class="org-ul">
<li>Los gradientes pueden volverse <b><b>muy pequeños</b></b> → la red “olvida” las
dependencias lejanas (problema de <b>vanishing gradient</b>).</li>
<li>O volverse <b><b>muy grandes</b></b> → inestabilidad numérica (problema de
<b>exploding gradient</b>).</li>
</ul>

<p>
Consecuencia: las RNN simples tienen dificultades para <b><b>aprender
relaciones de largo plazo</b></b>, por ejemplo, la dependencia entre una
palabra al principio de una oración y otra al final.
</p>
</div>
</div>
</div>
<div id="outline-container-org735c313" class="outline-3">
<h3 id="org735c313">Motivación de las LSTM</h3>
<div class="outline-text-3" id="text-org735c313">
<p>
Las LSTM fueron propuestas para permitir que la red:
</p>

<ul class="org-ul">
<li><b><b>Mantenga información relevante durante muchos pasos temporales</b></b>.</li>
<li><b><b>Controle qué recordar y qué olvidar</b></b>.</li>
<li>Facilite el flujo de gradiente a través del tiempo, reduciendo el
problema del desvanecimiento.</li>
</ul>

<p>
La idea principal es introducir una <b><b>celda de memoria</b></b> y un sistema de
<b><b>puertas (gates)</b></b> que regulan el flujo de información.
</p>
</div>
</div>
<div id="outline-container-org4bbd0a8" class="outline-3">
<h3 id="org4bbd0a8">Arquitectura interna de una celda LSTM</h3>
<div class="outline-text-3" id="text-org4bbd0a8">
<p>
En lugar de solo tener el estado oculto \(h_t\), la LSTM mantiene:
</p>

<ul class="org-ul">
<li>un <b><b>estado de memoria</b></b> \(c_t\) (a veces llamado <b>cell state</b>),</li>
<li>un <b><b>estado oculto</b></b> \(h_t\) (la “salida” en ese paso).</li>
</ul>

<p>
En cada paso temporal \(t\), la LSTM procesa:
</p>

<ul class="org-ul">
<li>la entrada actual \(x_t\),</li>
<li>el estado oculto anterior \(h_{t-1}\),</li>
<li>el estado de memoria anterior \(c_{t-1}\).</li>
</ul>

<p>
Y calcula:
</p>

<ul class="org-ul">
<li>una <b>puerta de olvido</b> \(f_t\),</li>
<li>una <b>puerta de entrada</b> \(i_t\),</li>
<li>una <b>candidata de memoria</b> \(\tilde{c}_t\),</li>
<li>una <b>puerta de salida</b> \(o_t\),</li>
<li>el nuevo estado de memoria \(c_t\),</li>
<li>el nuevo estado oculto \(h_t\).</li>
</ul>
</div>
<div id="outline-container-orgb64c9cc" class="outline-4">
<h4 id="orgb64c9cc">Ecuaciones de la LSTM</h4>
<div class="outline-text-4" id="text-orgb64c9cc">
<p>
Típicamente, las ecuaciones de una LSTM (versión “estándar”) son:
</p>

<div class="latex" id="org5091186">
\begin{aligned}
f_t &= \sigma(W_f [h_{t-1}, x_t] + b_f) \\
i_t &= \sigma(W_i [h_{t-1}, x_t] + b_i) \\
\tilde{c}_t &= \tanh(W_c [h_{t-1}, x_t] + b_c) \\
c_t &= f_t \odot c_{t-1} + i_t \odot \tilde{c}_t \\
o_t &= \sigma(W_o [h_{t-1}, x_t] + b_o) \\
h_t &= o_t \odot \tanh(c_t)
\end{aligned}

</div>

<p>
donde:
</p>

<ul class="org-ul">
<li>\(\sigma\) es la función sigmoide,</li>
<li>\(\tanh\) es la tangente hiperbólica,</li>
<li>\(\odot\) es el producto elemento a elemento,</li>
<li>\([h_{t-1}, x_t]\) indica la concatenación de vectores.</li>
</ul>
</div>
</div>
<div id="outline-container-org6357ddc" class="outline-4">
<h4 id="org6357ddc">Interpretación de las puertas</h4>
<div class="outline-text-4" id="text-org6357ddc">
<ul class="org-ul">
<li>\(f_t\) (<b>forget gate</b> o puerta de olvido):  
<ul class="org-ul">
<li>Toma valores en \([0,1]\) (por la sigmoide).</li>
<li>Decide cuánto de la memoria anterior \(c_{t-1}\) se conserva.</li>
<li>Si \(f_t \approx 1\) → se mantiene casi toda la memoria anterior.</li>
<li>Si \(f_t \approx 0\) → se olvida casi todo.</li>
</ul></li>

<li>\(i_t\) (<b>input gate</b> o puerta de entrada):  
<ul class="org-ul">
<li>Controla cuánta de la nueva información candidata \(\tilde{c}_t\) se
incorpora a la memoria.</li>
<li>Valores cercanos a 1 permiten “escribir” nueva información; valores
cercanos a 0 bloquean escritura.</li>
</ul></li>

<li>\(\tilde{c}_t\) (candidata de memoria):  
<ul class="org-ul">
<li>Es el nuevo contenido potencial para la memoria.</li>
<li>Se combina con \(i_t\) para actualizar \(c_t\).</li>
</ul></li>

<li>\(c_t\) (<b>cell state</b>):  
<ul class="org-ul">
<li>Es la memoria principal de la LSTM.</li>
<li>Se actualiza como:
\[
      c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c}_t
    \]</li>
<li>Puede transportar información durante muchos pasos, ya que el
gradiente puede fluir a lo largo de \(c_t\) con menos atenuación.</li>
</ul></li>

<li>\(o_t\) (<b>output gate</b> o puerta de salida):  
<ul class="org-ul">
<li>Controla qué parte de la memoria \(c_t\) se expone como salida \(h_t\).</li>
</ul></li>

<li>\(h_t\) (estado oculto / salida):  
<ul class="org-ul">
<li>Es la “representación” que se usa para producir salidas en cada
paso, o para alimentar capas posteriores.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd57c3b7" class="outline-3">
<h3 id="orgd57c3b7">Intuición conceptual</h3>
<div class="outline-text-3" id="text-orgd57c3b7">
<p>
Una forma intuitiva de entender una LSTM es verla como una <b><b>celda de
memoria con una “llave de escritura”, una “llave de borrado” y una
“llave de lectura”</b></b>:
</p>

<ul class="org-ul">
<li><b>Olvido</b>: la red decide qué partes de la memoria vieja ya no son
relevantes y las borra parcialmente (puerta \(f_t\)).</li>
<li><b>Escritura</b>: la red decide qué nueva información vale la pena guardar
(puerta \(i_t\) y candidata \(\tilde{c}_t\)).</li>
<li><b>Lectura</b>: la red decide qué parte de la memoria compartir como salida
(puerta \(o_t\)).</li>
</ul>

<p>
Esto permite que la red conserve información importante durante muchos
pasos temporales, por ejemplo:
</p>

<ul class="org-ul">
<li>el tema general de una oración,</li>
<li>la tendencia de una serie temporal,</li>
<li>el contexto de una conversación, etc.</li>
</ul>
</div>
</div>
<div id="outline-container-org4338421" class="outline-3">
<h3 id="org4338421">Entrenamiento de una LSTM</h3>
<div class="outline-text-3" id="text-org4338421">
<p>
El entrenamiento de una LSTM sigue el mismo esquema general que otras
redes neuronales:
</p>

<ol class="org-ol">
<li><b><b>Forward pass</b></b>:
<ul class="org-ul">
<li>La secuencia completa \((x_1, x_2, \dots, x_T)\) se ingresa paso a
paso.</li>
<li>En cada paso se actualizan \(c_t\) y \(h_t\).</li>
<li>Se produce una salida (por ejemplo, en cada paso o solo al final).</li>
</ul></li>

<li><b><b>Cálculo de la pérdida</b></b>:
<ul class="org-ul">
<li>Se compara la salida de la red con la etiqueta real.</li>
<li>Se usa una función de pérdida acorde al problema:
<ul class="org-ul">
<li>Clasificación: entropía cruzada (multiclase o binaria).</li>
<li>Regresión: error cuadrático medio (MSE), etc.</li>
</ul></li>
</ul></li>

<li><b><b>Backpropagation Through Time (BPTT)</b></b>:
<ul class="org-ul">
<li>Se retropropaga el gradiente desde el último paso hacia los
primeros.</li>
<li>Se actualizan los pesos de todas las puertas y conexiones.</li>
</ul></li>

<li><b><b>Actualización de parámetros</b></b>:
<ul class="org-ul">
<li>Se utilizan optimizadores como SGD, Adam, RMSprop.</li>
<li>En la práctica, Adam y RMSprop son muy populares en LSTM.</li>
</ul></li>
</ol>

<p>
Gracias a la estructura de memoria, los gradientes a través de \(c_t\)
tienden a <b><b>no desaparecer tan rápido</b></b> como en una RNN simple.
</p>
</div>
</div>
<div id="outline-container-org91a1f9a" class="outline-3">
<h3 id="org91a1f9a">Tipos de tareas típicas con LSTM</h3>
<div class="outline-text-3" id="text-org91a1f9a">
<p>
Las LSTM se aplican a muchas tareas de secuencia:
</p>

<ul class="org-ul">
<li><b>Modelado de lenguaje</b>:
<ul class="org-ul">
<li>Predecir la siguiente palabra de una oración.</li>
<li>Asignar probabilidad a una secuencia de palabras.</li>
</ul></li>

<li><b>Traducción automática</b>:
<ul class="org-ul">
<li>Modelos encoder–decoder (LSTM para codificar una oración, otra LSTM
para decodificar en otro idioma).</li>
</ul></li>

<li><b>Etiquetado secuencial</b>:
<ul class="org-ul">
<li>Etiquetado de partes del habla (POS tagging).</li>
<li>Reconocimiento de entidades nombradas (NER).</li>
</ul></li>

<li><b>Series temporales</b>:
<ul class="org-ul">
<li>Predicción de valores futuros (ej. precios de acciones).</li>
<li>Detección de anomalías en señales.</li>
</ul></li>

<li><b>Procesamiento de audio / voz</b>:
<ul class="org-ul">
<li>Reconocimiento de voz.</li>
<li>Síntesis de voz (en combinación con otras arquitecturas).</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org10b4b28" class="outline-3">
<h3 id="org10b4b28">Variantes y extensiones de LSTM</h3>
<div class="outline-text-3" id="text-org10b4b28">
<p>
A partir de la LSTM estándar, han surgido múltiples variantes:
</p>

<ul class="org-ul">
<li><b>LSTM bidireccional (Bidirectional LSTM)</b>:
<ul class="org-ul">
<li>Procesa la secuencia en dos direcciones:
<ul class="org-ul">
<li>de izquierda a derecha (forward),</li>
<li>de derecha a izquierda (backward).</li>
</ul></li>
<li>Se concatena la información de ambos sentidos.</li>
<li>Útil cuando se tiene acceso a la secuencia completa (texto, frases).</li>
</ul></li>

<li><b>Pilado de LSTMs (Stacked LSTM)</b>:
<ul class="org-ul">
<li>Varias capas LSTM apiladas una sobre otra.</li>
<li>Las salidas de una capa sirven de entradas a la siguiente.</li>
<li>Permite aprender representaciones más complejas.</li>
</ul></li>

<li><b>LSTM con atención (Attention)</b>:
<ul class="org-ul">
<li>Combinación de LSTM con mecanismos de atención.</li>
<li>El modelo decide a qué partes de la secuencia “prestar más atención”
al hacer una predicción.</li>
</ul></li>

<li><b>GRU (Gated Recurrent Unit)</b>:
<ul class="org-ul">
<li>Variante simplificada de LSTM (menos puertas, menos parámetros).</li>
<li>Suele tener rendimiento comparable en muchos problemas.</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgde6d266" class="outline-3">
<h3 id="orgde6d266">Implementación básica en Python (Keras)</h3>
<div class="outline-text-3" id="text-orgde6d266">
<p>
A modo de ejemplo muy simple (no ligado a un dataset específico):
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np
<span style="color: #fb4934;">import</span> tensorflow <span style="color: #fb4934;">as</span> tf
<span style="color: #fb4934;">from</span> tensorflow.keras.models <span style="color: #fb4934;">import</span> Sequential
<span style="color: #fb4934;">from</span> tensorflow.keras.layers <span style="color: #fb4934;">import</span> LSTM, Dense

<span style="color: #928374;"># </span><span style="color: #928374;">Supongamos una secuencia de longitud 10 con 5 features por timestep
</span><span style="color: #83a598;">timesteps</span> = 10
<span style="color: #83a598;">features</span> = 5
<span style="color: #83a598;">num_samples</span> = 100
<span style="color: #83a598;">num_classes</span> = 3

<span style="color: #928374;"># </span><span style="color: #928374;">Datos aleatorios de ejemplo (solo para ilustrar la forma)
</span><span style="color: #83a598;">X</span> = np.random.randn<span style="color: #fe8019;">(</span>num_samples, timesteps, features<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">y</span> = np.random.randint<span style="color: #fe8019;">(</span>0, num_classes, size=<span style="color: #b16286;">(</span>num_samples,<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">One-hot encoding
</span><span style="color: #83a598;">y_onehot</span> = tf.keras.utils.to_categorical<span style="color: #fe8019;">(</span>y, num_classes=num_classes<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Definir modelo LSTM
</span><span style="color: #83a598;">model</span> = Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   LSTM<span style="color: #b8bb26;">(</span>32, input_shape=<span style="color: #83a598;">(</span>timesteps, features<span style="color: #83a598;">)</span><span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   Dense<span style="color: #b8bb26;">(</span>num_classes, activation=<span style="color: #b8bb26;">'softmax'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

model.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   loss=<span style="color: #b8bb26;">'categorical_crossentropy'</span>,
<span style="background-color: #3c3836;"> </span>   optimizer=<span style="color: #b8bb26;">'adam'</span>,
<span style="background-color: #3c3836;"> </span>   metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'accuracy'</span><span style="color: #b16286;">]</span>
<span style="color: #fe8019;">)</span>

model.summary<span style="color: #fe8019;">()</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Entrenamiento de ejemplo
</span>model.fit<span style="color: #fe8019;">(</span>X, y_onehot, epochs=10, batch_size=16<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
En este ejemplo:
</p>

<ul class="org-ul">
<li>La entrada tiene forma <code>(num_samples, timesteps, features)</code>.</li>
<li>La LSTM devuelve un vector (el último estado oculto).</li>
<li>La capa <code>Dense</code> con softmax produce una distribución de probabilidad
sobre las clases.</li>
</ul>
</div>
</div>
<div id="outline-container-orgcf7ef7b" class="outline-3">
<h3 id="orgcf7ef7b">Ventajas y limitaciones de LSTM</h3>
<div class="outline-text-3" id="text-orgcf7ef7b">
</div>
<div id="outline-container-org022b700" class="outline-4">
<h4 id="org022b700">Ventajas</h4>
<div class="outline-text-4" id="text-org022b700">
<ul class="org-ul">
<li>Manejan mejor dependencias de largo plazo que las RNN simples.</li>
<li>Funcionan bien en problemas donde el orden y el contexto importan.</li>
<li>Son muy flexibles y pueden combinarse con otras arquitecturas
(convolucionales, atención, etc.).</li>
</ul>
</div>
</div>
<div id="outline-container-org8c2821d" class="outline-4">
<h4 id="org8c2821d">Limitaciones</h4>
<div class="outline-text-4" id="text-org8c2821d">
<ul class="org-ul">
<li>Entrenamiento relativamente costoso (más parámetros que RNN simple).</li>
<li>Difíciles de paralelizar completamente debido a su naturaleza
secuencial.</li>
<li>En tareas muy complejas y con grandes volúmenes de datos, han sido en
muchos casos superadas por arquitecturas basadas en <b>transformers</b>.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgf3c31f7" class="outline-3">
<h3 id="orgf3c31f7">Conclusión</h3>
<div class="outline-text-3" id="text-orgf3c31f7">
<p>
Las LSTM representan un paso fundamental en la historia de las redes
neuronales para secuencias:
</p>

<ul class="org-ul">
<li>resolvieron en gran medida el problema del desvanecimiento del
gradiente en RNN,</li>
<li>permitieron avances significativos en NLP, series temporales y voz,</li>
<li>siguen siendo una herramienta muy útil y educativa para entender cómo
las redes pueden “recordar” información a lo largo del tiempo.</li>
</ul>

<p>
Aun cuando hoy en día los <b>transformers</b> dominen muchas aplicaciones de
NLP, las LSTM siguen siendo:
</p>

<ul class="org-ul">
<li>una excelente base conceptual,</li>
<li>útiles en problemas con secuencias pequeñas o recursos limitados,</li>
<li>y una parte importante de la “caja de herramientas” de cualquier
persona que trabaja con aprendizaje profundo y datos secuenciales.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgda04a0a" class="outline-2">
<h2 id="orgda04a0a">Ejemplo Clasificación del dataset Iris con una red LSTM</h2>
<div class="outline-text-2" id="text-orgda04a0a">
<p>
Este apartado muestra un ejemplo completo en Python usando el dataset
clásico Iris y una red neuronal recurrente del tipo <b>LSTM</b> (Long Short-Term Memory)
usando la librería <b>Keras</b> (TensorFlow).
</p>

<p>
El objetivo es clasificar flores Iris en tres clases:
</p>

<ul class="org-ul">
<li>Setosa</li>
<li>Versicolor</li>
<li>Virginica</li>
</ul>

<p>
A diferencia del MLP (Perceptrón Multicapa), la LSTM está diseñada
para procesar datos <b>secuenciales</b>. En este ejemplo, forzamos la
estructura secuencial tratando las 4 características de Iris como una
secuencia de 4 pasos temporales.
</p>
</div>
<div id="outline-container-org89e758c" class="outline-3">
<h3 id="org89e758c">Importar librerías</h3>
<div class="outline-text-3" id="text-org89e758c">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #fb4934;">import</span> numpy <span style="color: #fb4934;">as</span> np

<span style="color: #fb4934;">from</span> sklearn.datasets <span style="color: #fb4934;">import</span> load_iris
<span style="color: #fb4934;">from</span> sklearn.model_selection <span style="color: #fb4934;">import</span> train_test_split
<span style="color: #fb4934;">from</span> sklearn.preprocessing <span style="color: #fb4934;">import</span> StandardScaler
<span style="color: #fb4934;">from</span> sklearn.metrics <span style="color: #fb4934;">import</span> accuracy_score, classification_report

<span style="color: #fb4934;">import</span> tensorflow <span style="color: #fb4934;">as</span> tf
<span style="color: #fb4934;">from</span> tensorflow.keras.models <span style="color: #fb4934;">import</span> Sequential
<span style="color: #fb4934;">from</span> tensorflow.keras.layers <span style="color: #fb4934;">import</span> LSTM, Dense
<span style="color: #fb4934;">from</span> tensorflow.keras.utils <span style="color: #fb4934;">import</span> to_categorical
</pre>
</div>
</div>
</div>
<div id="outline-container-org3f6c220" class="outline-3">
<h3 id="org3f6c220">Cargar el dataset Iris</h3>
<div class="outline-text-3" id="text-org3f6c220">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">iris</span> = load_iris<span style="color: #fe8019;">()</span>
<span style="color: #83a598;">X</span> = iris.data      <span style="color: #928374;"># </span><span style="color: #928374;">Caracter&#237;sticas (150 x 4)
</span><span style="color: #83a598;">y</span> = iris.target    <span style="color: #928374;"># </span><span style="color: #928374;">Clases (150,)
</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>X.shape<span style="color: #fe8019;">)</span>     <span style="color: #928374;"># </span><span style="color: #928374;">(150, 4)
</span><span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>y.shape<span style="color: #fe8019;">)</span>     <span style="color: #928374;"># </span><span style="color: #928374;">(150,)</span>
</pre>
</div>

<p>
Las 4 características son:
</p>

<ul class="org-ul">
<li>Largo del sépalo</li>
<li>Ancho del sépalo</li>
<li>Largo del pétalo</li>
<li>Ancho del pétalo</li>
</ul>

<p>
Las clases están codificadas como:
</p>

<ul class="org-ul">
<li>0 → Setosa</li>
<li>1 → Versicolor</li>
<li>2 → Virginica</li>
</ul>
</div>
</div>
<div id="outline-container-org836caf5" class="outline-3">
<h3 id="org836caf5">Partición entrenamiento / prueba</h3>
<div class="outline-text-3" id="text-org836caf5">
<p>
El siguiente fragmento de código realiza la partición del conjunto de
datos original en dos subconjuntos disjuntos: uno destinado al
entrenamiento del modelo y otro a su evaluación.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">X_train</span>, <span style="color: #83a598;">X_test</span>, <span style="color: #83a598;">y_train</span>, <span style="color: #83a598;">y_test</span> = train_test_split<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   X,
<span style="background-color: #3c3836;"> </span>   y,
<span style="background-color: #3c3836;"> </span>   test_size=0.2,
<span style="background-color: #3c3836;"> </span>   random_state=42,
<span style="background-color: #3c3836;"> </span>   stratify=y
<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
<div id="outline-container-org1065ce6" class="outline-4">
<h4 id="org1065ce6">Propósito de la partición</h4>
<div class="outline-text-4" id="text-org1065ce6">
<p>
En aprendizaje automático supervisado, es fundamental evaluar la
capacidad de generalización de un modelo. Para ello, los datos
disponibles se dividen en:
</p>

<ul class="org-ul">
<li><b>Conjunto de entrenamiento</b>: utilizado para ajustar los parámetros del modelo (pesos y sesgos).</li>
<li><b>Conjunto de prueba</b>: utilizado exclusivamente para medir el desempeño del modelo sobre datos no vistos durante el entrenamiento.</li>
</ul>

<p>
Esta separación permite detectar fenómenos como overfitting y
underfitting, y proporciona una estimación más realista del
rendimiento esperado en producción.
</p>
</div>
</div>
<div id="outline-container-org51f6f57" class="outline-4">
<h4 id="org51f6f57">Parámetro test<sub>size</sub></h4>
<div class="outline-text-4" id="text-org51f6f57">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">test_size</span> = 0.2
</pre>
</div>

<p>
indica que el 20 % del conjunto total de datos se reserva para el
conjunto de prueba, mientras que el 80 % restante se utiliza para
entrenamiento.
</p>
</div>
</div>
<div id="outline-container-orgda8f574" class="outline-4">
<h4 id="orgda8f574">Reproducibilidad del experimento</h4>
<div class="outline-text-4" id="text-orgda8f574">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">random_state</span> = 42
</pre>
</div>

<p>
fija la semilla del generador de números aleatorios utilizado durante
la partición. Esto garantiza que la división de los datos sea
reproducible.
</p>
</div>
</div>
<div id="outline-container-org2b5088a" class="outline-4">
<h4 id="org2b5088a">Estratificación de clases</h4>
<div class="outline-text-4" id="text-org2b5088a">
<p>
El parámetro:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">stratify</span> = y
</pre>
</div>

<p>
indica que la división debe realizarse de forma estratificada,
conservando la proporción original de cada clase en ambos
subconjuntos.
</p>
</div>
</div>
</div>
<div id="outline-container-orgc8f85a3" class="outline-3">
<h3 id="orgc8f85a3">Normalización de los datos</h3>
<div class="outline-text-3" id="text-orgc8f85a3">
<p>
La normalización de los datos de entrada es un paso crítico en el
entrenamiento de redes neuronales (incluyendo LSTM), ya que influye
directamente en la estabilidad numérica, la velocidad de convergencia
y la eficacia del aprendizaje.
</p>

<p>
Usaremos estandarización con <code>StandardScaler</code>:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">scaler</span> = StandardScaler<span style="color: #fe8019;">()</span>
<span style="color: #83a598;">X_train</span> = scaler.fit_transform<span style="color: #fe8019;">(</span>X_train<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">X_test</span> = scaler.transform<span style="color: #fe8019;">(</span>X_test<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Cada característica \(x\) se transforma según:
</p>

<div class="latex" id="org8f4060b">
<p>
x' = \frac{x - \mu}{\sigma}
</p>

</div>

<p>
donde:
</p>

<ul class="org-ul">
<li>\( \mu \) es la media de la característica,</li>
<li>\( \sigma \) es la desviación estándar.</li>
</ul>

<p>
El resultado es:
</p>

<ul class="org-ul">
<li>media aproximadamente 0,</li>
<li>desviación estándar aproximadamente 1.</li>
</ul>
</div>
</div>
<div id="outline-container-org70b6344" class="outline-3">
<h3 id="org70b6344">Preparar los datos para LSTM</h3>
<div class="outline-text-3" id="text-org70b6344">
<p>
Las LSTM en Keras esperan entradas con forma:
</p>

<ul class="org-ul">
<li>\((n\_muestras, n\_timesteps, n\_features)\)</li>
</ul>

<p>
En Iris, tenemos 4 características. Una forma simple de usar LSTM es:
</p>

<ul class="org-ul">
<li>considerar una secuencia de longitud 4 (<code>timesteps=4</code>),</li>
<li>con 1 característica por paso (<code>features=1</code>).</li>
</ul>

<p>
Esto implica reestructurar cada muestra de forma (4,) a (4, 1):
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #928374;"># </span><span style="color: #928374;">Reshape para LSTM: (n_muestras, timesteps=4, features=1)
</span><span style="color: #83a598;">X_train_lstm</span> = X_train.reshape<span style="color: #fe8019;">(</span><span style="color: #b16286;">(</span>X_train.shape<span style="color: #b8bb26;">[</span>0<span style="color: #b8bb26;">]</span>, 4, 1<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="color: #83a598;">X_test_lstm</span> = X_test.reshape<span style="color: #fe8019;">(</span><span style="color: #b16286;">(</span>X_test.shape<span style="color: #b8bb26;">[</span>0<span style="color: #b8bb26;">]</span>, 4, 1<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>X_train_lstm.shape<span style="color: #fe8019;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">(120, 4, 1)
</span><span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>X_test_lstm.shape<span style="color: #fe8019;">)</span>   <span style="color: #928374;"># </span><span style="color: #928374;">(30, 4, 1)</span>
</pre>
</div>

<p>
Además, para clasificación multiclase con Keras, se suele usar
one-hot encoding de las etiquetas:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">num_classes</span> = <span style="color: #fe8019;">len</span><span style="color: #fe8019;">(</span>np.unique<span style="color: #b16286;">(</span>y<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="color: #83a598;">y_train_cat</span> = to_categorical<span style="color: #fe8019;">(</span>y_train, num_classes=num_classes<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">y_test_cat</span> = to_categorical<span style="color: #fe8019;">(</span>y_test, num_classes=num_classes<span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
</div>
<div id="outline-container-org0bffa15" class="outline-3">
<h3 id="org0bffa15">Definir la red LSTM</h3>
<div class="outline-text-3" id="text-org0bffa15">
<p>
Definimos un modelo secuencial con una capa LSTM y una capa densa de
salida con softmax:
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">model</span> = Sequential<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span>
<span style="background-color: #3c3836;"> </span>   LSTM<span style="color: #b8bb26;">(</span>
<span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   units=16,           <span style="color: #928374;"># </span><span style="color: #928374;">n&#250;mero de unidades LSTM
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   activation=<span style="color: #b8bb26;">'tanh'</span>,  <span style="color: #928374;"># </span><span style="color: #928374;">activaci&#243;n interna
</span><span style="background-color: #3c3836;"> </span>   <span style="background-color: #3c3836;"> </span>   input_shape=<span style="color: #83a598;">(</span>4, 1<span style="color: #83a598;">)</span>  <span style="color: #928374;"># </span><span style="color: #928374;">(timesteps=4, features=1)
</span><span style="background-color: #3c3836;"> </span>   <span style="color: #b8bb26;">)</span>,
<span style="background-color: #3c3836;"> </span>   Dense<span style="color: #b8bb26;">(</span>num_classes, activation=<span style="color: #b8bb26;">'softmax'</span><span style="color: #b8bb26;">)</span>
<span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
<div id="outline-container-org871cecb" class="outline-4">
<h4 id="org871cecb">Arquitectura de la red</h4>
<div class="outline-text-4" id="text-org871cecb">
<ul class="org-ul">
<li><b>Capa de entrada</b>:
<ul class="org-ul">
<li>Forma: (4, 1)</li>
<li>4 pasos "temporales" (cada uno con 1 valor), derivados de las 4 características.</li>
</ul></li>

<li><b>Capa LSTM</b>:
<ul class="org-ul">
<li><code>units=16</code>: 16 unidades de memoria.</li>
<li>Procesa la secuencia \((x_1, x_2, x_3, x_4)\) y genera una representación que captura
dependencias entre pasos.</li>
</ul></li>

<li><b>Capa de salida (Dense + softmax)</b>:
<ul class="org-ul">
<li>3 neuronas (una por clase).</li>
<li>Activación softmax para obtener probabilidades.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org594fc8a" class="outline-3">
<h3 id="org594fc8a">Compilación del modelo</h3>
<div class="outline-text-3" id="text-org594fc8a">
<p>
Escogemos una función de pérdida apropiada para clasificación
multiclase y un optimizador:
</p>

<div class="org-src-container">
<pre class="src src-python">model.<span style="color: #fe8019;">compile</span><span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   loss=<span style="color: #b8bb26;">'categorical_crossentropy'</span>,
<span style="background-color: #3c3836;"> </span>   optimizer=tf.keras.optimizers.Adam<span style="color: #b16286;">(</span>learning_rate=0.001<span style="color: #b16286;">)</span>,
<span style="background-color: #3c3836;"> </span>   metrics=<span style="color: #b16286;">[</span><span style="color: #b8bb26;">'accuracy'</span><span style="color: #b16286;">]</span>
<span style="color: #fe8019;">)</span>
</pre>
</div>

<ul class="org-ul">
<li><code>categorical_crossentropy</code>: log-loss multiclase.</li>
<li><b>Adam</b>: optimizador basado en descenso de gradiente con momento y tasas
de aprendizaje adaptativas.</li>
<li>Tasa de aprendizaje inicial \(\eta = 0.001\).</li>
</ul>
</div>
</div>
<div id="outline-container-org844c4fb" class="outline-3">
<h3 id="org844c4fb">Entrenamiento del modelo LSTM</h3>
<div class="outline-text-3" id="text-org844c4fb">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #83a598;">history</span> = model.fit<span style="color: #fe8019;">(</span>
<span style="background-color: #3c3836;"> </span>   X_train_lstm,
<span style="background-color: #3c3836;"> </span>   y_train_cat,
<span style="background-color: #3c3836;"> </span>   epochs=200,         <span style="color: #928374;"># </span><span style="color: #928374;">n&#250;mero de &#233;pocas
</span><span style="background-color: #3c3836;"> </span>   batch_size=16,
<span style="background-color: #3c3836;"> </span>   validation_split=0.1,
<span style="background-color: #3c3836;"> </span>   verbose=1
<span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Durante el entrenamiento:
</p>
</div>
<div id="outline-container-org3f59729" class="outline-4">
<h4 id="org3f59729">Propagación hacia adelante (forward pass)</h4>
<div class="outline-text-4" id="text-org3f59729">
<ul class="org-ul">
<li>Cada muestra de entrada se considera como una secuencia de 4 pasos.</li>
<li>En cada paso, la LSTM actualiza su:
<ul class="org-ul">
<li>estado oculto \(h_t\),</li>
<li>estado de memoria \(c_t\).</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9a73e56" class="outline-4">
<h4 id="org9a73e56">Cálculo del error</h4>
<div class="outline-text-4" id="text-org9a73e56">
<ul class="org-ul">
<li>La salida softmax se compara con la etiqueta real codificada en one-hot.</li>
<li>Se calcula la pérdida mediante entropía cruzada categórica.</li>
</ul>
</div>
</div>
<div id="outline-container-org0bd1ce6" class="outline-4">
<h4 id="org0bd1ce6">Backpropagation Through Time (BPTT)</h4>
<div class="outline-text-4" id="text-org0bd1ce6">
<ul class="org-ul">
<li>El error se propaga hacia atrás a lo largo del tiempo (sobre los 4 pasos).</li>
<li>Se calculan los gradientes de los pesos de la LSTM y de la capa de salida.</li>
</ul>
</div>
</div>
<div id="outline-container-org4496298" class="outline-4">
<h4 id="org4496298">Descenso de gradiente con Adam</h4>
<div class="outline-text-4" id="text-org4496298">
<ul class="org-ul">
<li>Adam combina Momentum y RMSProp.</li>
<li>Ajusta automáticamente la tasa de aprendizaje para cada parámetro.</li>
<li>Proporciona convergencia rápida y estable.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orga182cf4" class="outline-3">
<h3 id="orga182cf4">Evaluación del modelo</h3>
<div class="outline-text-3" id="text-orga182cf4">
<p>
Una vez entrenado el modelo, se evalúa su desempeño usando datos no
vistos (conjunto de prueba).
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #928374;"># </span><span style="color: #928374;">Probabilidades por clase
</span><span style="color: #83a598;">y_pred_proba</span> = model.predict<span style="color: #fe8019;">(</span>X_test_lstm<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">Clase predicha = &#237;ndice de la probabilidad m&#225;xima
</span><span style="color: #83a598;">y_pred</span> = np.argmax<span style="color: #fe8019;">(</span>y_pred_proba, axis=1<span style="color: #fe8019;">)</span>

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Accuracy:"</span>, accuracy_score<span style="color: #b16286;">(</span>y_test, y_pred<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">Reporte de clasificaci&#243;n:</span><span style="color: #d3869b;">\n</span><span style="color: #b8bb26;">"</span><span style="color: #fe8019;">)</span>
<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span>classification_report<span style="color: #b16286;">(</span>y_test, y_pred, target_names=iris.target_names<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>
</pre>
</div>
</div>
<div id="outline-container-org97da62f" class="outline-4">
<h4 id="org97da62f">Métricas utilizadas</h4>
<div class="outline-text-4" id="text-org97da62f">
<ul class="org-ul">
<li><b>Accuracy</b>: proporción total de predicciones correctas.</li>
<li><b>Precision</b>: qué tan confiables son las predicciones positivas.</li>
<li><b>Recall</b>: capacidad del modelo para encontrar todos los ejemplos de una clase.</li>
<li><b>F1-score</b>: balance entre precisión y recall.</li>
</ul>

<p>
En el dataset Iris, el accuracy también suele estar en el rango del
95 % al 100 %.
</p>
</div>
</div>
</div>
<div id="outline-container-org552cdf9" class="outline-3">
<h3 id="org552cdf9">Predicción con una nueva flor</h3>
<div class="outline-text-3" id="text-org552cdf9">
<p>
El modelo entrenado puede utilizarse para predecir nuevas muestras.
Es importante repetir el mismo preprocesamiento: normalización y
reshape para LSTM.
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #928374;"># </span><span style="color: #928374;">[largo_sepalo, ancho_sepalo, largo_petalo, ancho_petalo]
</span><span style="color: #83a598;">flor_nueva</span> = np.array<span style="color: #fe8019;">(</span><span style="color: #b16286;">[</span><span style="color: #b8bb26;">[</span>5.1, 3.5, 1.4, 0.2<span style="color: #b8bb26;">]</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">1) Normalizaci&#243;n con el mismo scaler del entrenamiento
</span><span style="color: #83a598;">flor_nueva_scaled</span> = scaler.transform<span style="color: #fe8019;">(</span>flor_nueva<span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">2) Reshape para LSTM: (1, timesteps=4, features=1)
</span><span style="color: #83a598;">flor_nueva_lstm</span> = flor_nueva_scaled.reshape<span style="color: #fe8019;">(</span><span style="color: #b16286;">(</span>1, 4, 1<span style="color: #b16286;">)</span><span style="color: #fe8019;">)</span>

<span style="color: #928374;"># </span><span style="color: #928374;">3) Predicci&#243;n
</span><span style="color: #83a598;">proba</span> = model.predict<span style="color: #fe8019;">(</span>flor_nueva_lstm<span style="color: #fe8019;">)</span>
<span style="color: #83a598;">prediccion</span> = np.argmax<span style="color: #fe8019;">(</span>proba, axis=1<span style="color: #fe8019;">)</span>

<span style="color: #fe8019;">print</span><span style="color: #fe8019;">(</span><span style="color: #b8bb26;">"Clase predicha:"</span>, iris.target_names<span style="color: #b16286;">[</span>prediccion<span style="color: #b8bb26;">[</span>0<span style="color: #b8bb26;">]</span><span style="color: #b16286;">]</span><span style="color: #fe8019;">)</span>
</pre>
</div>

<p>
Es fundamental aplicar la misma normalización y la misma estructura de
entrada (forma (1, 4, 1)) que se usaron en el entrenamiento.
</p>
</div>
</div>
<div id="outline-container-orge649d6b" class="outline-3">
<h3 id="orge649d6b">Interpretación matemática básica de la LSTM</h3>
<div class="outline-text-3" id="text-orge649d6b">
<p>
En una LSTM, en cada paso temporal \(t\) se procesan:
</p>

<ul class="org-ul">
<li>la entrada \(x_t\),</li>
<li>el estado oculto anterior \(h_{t-1}\),</li>
<li>el estado de memoria anterior \(c_{t-1}\).</li>
</ul>

<p>
La LSTM utiliza <b>puertas</b> que controlan el flujo de información:
</p>

<div class="latex" id="orgd4deb36">
\begin{aligned}
f_t &= \sigma(W_f [h_{t-1}, x_t] + b_f) \\
i_t &= \sigma(W_i [h_{t-1}, x_t] + b_i) \\
\tilde{c}_t &= \tanh(W_c [h_{t-1}, x_t] + b_c) \\
c_t &= f_t \odot c_{t-1} + i_t \odot \tilde{c}_t \\
o_t &= \sigma(W_o [h_{t-1}, x_t] + b_o) \\
h_t &= o_t \odot \tanh(c_t)
\end{aligned}

</div>

<p>
donde:
</p>

<ul class="org-ul">
<li>\(\sigma\) es la función sigmoide,</li>
<li>\(\odot\) denota el producto elemento a elemento.</li>
</ul>

<p>
Al final de la secuencia (tras los 4 pasos), el último estado oculto
\(h_T\) se pasa a la capa densa con función softmax:
</p>

<div class="latex" id="orgee86c00">
<p>
\text{softmax}(z<sub>i</sub>) = \frac{e<sup>z<sub>i</sub></sup>}{&sum;<sub>j</sub> e<sup>z<sub>j</sub></sup>}
</p>

</div>

<p>
lo que permite interpretar las salidas como probabilidades para cada
clase (Setosa, Versicolor, Virginica).
</p>
</div>
</div>
</div>
<div id="outline-container-org2b976a8" class="outline-2">
<h2 id="org2b976a8">Bibliografía  Deep Learning</h2>
<div class="outline-text-2" id="text-org2b976a8">
</div>
<div id="outline-container-org40ff0e0" class="outline-3">
<h3 id="org40ff0e0">Teórica y Académica&#xa0;&#xa0;&#xa0;<span class="tag"><span class="MATEMATICAS">MATEMATICAS</span>&#xa0;<span class="FUNDAMENTOS">FUNDAMENTOS</span></span></h3>
<div class="outline-text-3" id="text-org40ff0e0">
<p>
Libros diseñados para entender el "porqué" de los algoritmos.
</p>
</div>
<div id="outline-container-orge063114" class="outline-4">
<h4 id="orge063114">Deep Learning</h4>
<div class="outline-text-4" id="text-orge063114">
<ul class="org-ul">
<li><b>Autores:</b> Ian Goodfellow, Yoshua Bengio y Aaron Courville.</li>
<li><b>Editorial:</b> MIT Press (2016).</li>
<li><b>Nota:</b> Considerada la "Biblia" de la IA. Cubre álgebra lineal, probabilidad y arquitecturas complejas.</li>
<li><b>Web:</b> <a href="https://www.deeplearningbook.org/">Acceso gratuito a la versión web (HTML)</a></li>
</ul>
</div>
</div>
<div id="outline-container-org3c33460" class="outline-4">
<h4 id="org3c33460">Neural Networks and Deep Learning: A Textbook</h4>
<div class="outline-text-4" id="text-org3c33460">
<ul class="org-ul">
<li><b>Autor:</b> Charu C. Aggarwal.</li>
<li><b>Editorial:</b> Springer (2018).</li>
<li><b>Enfoque:</b> Muy estructurado para estudiantes de ingeniería y computación.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd417486" class="outline-3">
<h3 id="orgd417486">Práctica y Programación&#xa0;&#xa0;&#xa0;<span class="tag"><span class="PYTHON">PYTHON</span>&#xa0;<span class="PYTORCH">PYTORCH</span>&#xa0;<span class="KERAS">KERAS</span></span></h3>
<div class="outline-text-3" id="text-orgd417486">
<p>
Libros enfocados en la implementación inmediata usando librerías de Python.
</p>
</div>
<div id="outline-container-orgcd85552" class="outline-4">
<h4 id="orgcd85552">Deep Learning with Python (3rd Edition)</h4>
<div class="outline-text-4" id="text-orgcd85552">
<ul class="org-ul">
<li><b>Autor:</b> François Chollet (Creador de Keras).</li>
<li><b>Editorial:</b> Manning Publications (2025).</li>
<li><b>Por qué leerlo:</b> Explicaciones excepcionales sobre la intuición detrás de las redes neuronales.</li>
<li><b>Enlace:</b> <a href="https://www.manning.com/books/deep-learning-with-python-third-edition">Página del libro</a></li>
</ul>
</div>
</div>
<div id="outline-container-org97e6bd7" class="outline-4">
<h4 id="org97e6bd7">Hands-On Machine Learning with Scikit-Learn and PyTorch</h4>
<div class="outline-text-4" id="text-org97e6bd7">
<ul class="org-ul">
<li><b>Autor:</b> Aurélien Géron.</li>
<li><b>Editorial:</b> O'Reilly Media (Edición 2025).</li>
<li><b>Enfoque:</b> Es el manual más completo para pasar de la teoría a la práctica industrial. Cubre desde regresiones simples hasta Transformers.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org30571c1" class="outline-3">
<h3 id="org30571c1">Aprendizaje "Desde Cero"&#xa0;&#xa0;&#xa0;<span class="tag"><span class="NUMPY">NUMPY</span>&#xa0;<span class="LOGICA">LOGICA</span></span></h3>
<div class="outline-text-3" id="text-org30571c1">
<p>
Ideales para entender cómo funciona el "motor" de una red neuronal sin usar herramientas automáticas.
</p>
</div>
<div id="outline-container-orgeacc3f3" class="outline-4">
<h4 id="orgeacc3f3">Grokking Deep Learning</h4>
<div class="outline-text-4" id="text-orgeacc3f3">
<ul class="org-ul">
<li><b>Autor:</b> Andrew Trask.</li>
<li><b>Editorial:</b> Manning Publications.</li>
<li><b>Descripción:</b> Aprenderás a programar redes neuronales usando solo <code>NumPy</code>. Ideal si quieres entender la "caja negra".</li>
</ul>
</div>
</div>
<div id="outline-container-orgb93e5b6" class="outline-4">
<h4 id="orgb93e5b6">Neural Networks from Scratch (NNFS)</h4>
<div class="outline-text-4" id="text-orgb93e5b6">
<ul class="org-ul">
<li><b>Autores:</b> Harrison Kinsley (Sentdex) y Daniel Kukieła.</li>
<li><b>Descripción:</b> Basado en código puro de Python. Muy popular entre autodidactas.</li>
<li><b>Web:</b> <a href="https://nnfs.io/">Sitio Oficial de NNFS</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc2e1102" class="outline-3">
<h3 id="orgc2e1102">Tabla Comparativa para Elección Rápida</h3>
<div class="outline-text-3" id="text-orgc2e1102">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Libro</th>
<th scope="col" class="org-left">Nivel</th>
<th scope="col" class="org-left">Enfoque Principal</th>
<th scope="col" class="org-left">Tecnología</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Goodfellow</td>
<td class="org-left">Avanzado</td>
<td class="org-left">Teoría/Matemáticas</td>
<td class="org-left">Genérico</td>
</tr>

<tr>
<td class="org-left">Chollet</td>
<td class="org-left">Intermedio</td>
<td class="org-left">Intuición</td>
<td class="org-left">Keras/TensorFlow</td>
</tr>

<tr>
<td class="org-left">Géron</td>
<td class="org-left">Todos</td>
<td class="org-left">Práctica/Industria</td>
<td class="org-left">PyTorch/Scikit-Learn</td>
</tr>

<tr>
<td class="org-left">Trask</td>
<td class="org-left">Principiante</td>
<td class="org-left">Lógica Interna</td>
<td class="org-left">NumPy</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Autor: Eduardo Alcaraz</p>
<p class="date">Created: 2026-01-22 jue 09:15</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
