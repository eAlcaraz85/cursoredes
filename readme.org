#+TITLE: Redes Neuronales Artificiales
#+AUTHOR: Eduardo Alcaraz
#+LANGUAGE: es
#+LaTeX_HEADER: \usepackage[spanish]{inputenc}
#+SETUPFILE: /home/likcos/Dropbox/org/cursos/redesneuronales/theme-readtheorg-local.setup
#+EXPORT_FILE_NAME: index.html
#+OPTIONS: num:nil
#+OPTIONS: tex:mathjax
#+HTML_HEAD: <style> #content{max-width:1800px;}</style>
#+HTML_HEAD: <style>pre.src {background-color: #303030; color: #e5e5e5;}</style>




* Presentaci√≥n del Curso
** Objetivo general
  Este curso tiene como objetivo proporcionar una
  comprensi√≥n *profunda y progresiva* de las redes neuronales
  artificiales, desde sus fundamentos te√≥ricos hasta las principales
  arquitecturas modernas utilizadas en la industria y la
  investigaci√≥n.


- Fundamentos matem√°ticos y conceptuales
- Funcionamiento interno de una red neuronal
- Entrenamiento y optimizaci√≥n
- Arquitecturas principales
- Intuici√≥n pr√°ctica y casos de uso



* Instalaci√≥n de requerimientos

** Verificaci√≥n de Python
Antes de instalar las dependencias, verifique que el sistema cuente con Python
versi√≥n 3.9 o superior.

#+BEGIN_SRC bash
python --version
#+END_SRC

En caso de que el comando anterior no est√© disponible, intente:

#+BEGIN_SRC bash
python3 --version
#+END_SRC

** Creaci√≥n del entorno virtual
Se recomienda crear un entorno virtual para aislar las dependencias del proyecto
y evitar conflictos entre versiones de librer√≠as.

#+BEGIN_SRC bash
python -m venv mlp_env
#+END_SRC

** Activaci√≥n del entorno virtual

La activaci√≥n del entorno virtual depende del sistema operativo y del int√©rprete
de comandos utilizado.

*** GNU/Linux y macOS
#+BEGIN_SRC bash
source mlp_env/bin/activate
#+END_SRC

*** Windows ‚Äì S√≠mbolo del sistema (CMD)
Si se utiliza el *S√≠mbolo del sistema* (cmd.exe), ejecute:

#+BEGIN_SRC bat
mlp_env\Scripts\activate.bat
#+END_SRC

*** Windows ‚Äì PowerShell
Si se utiliza *Windows PowerShell*, ejecute:

#+BEGIN_SRC powershell
mlp_env\Scripts\Activate.ps1
#+END_SRC

En caso de que la ejecuci√≥n de scripts est√© deshabilitada, habil√≠tela
temporalmente con:

#+BEGIN_SRC powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process
#+END_SRC

Posteriormente, vuelva a ejecutar el comando de activaci√≥n.

*** Windows ‚Äì Git Bash
Si se utiliza *Git Bash*, ejecute:

#+BEGIN_SRC bash
source mlp_env/Scripts/activate
#+END_SRC

Una vez activado el entorno virtual, el nombre del entorno aparecer√° entre
par√©ntesis al inicio de la l√≠nea de comandos.

** Actualizaci√≥n del gestor de paquetes
Antes de instalar las librer√≠as, se recomienda actualizar el gestor de paquetes
=pip=.

#+BEGIN_SRC bash
pip install --upgrade pip
#+END_SRC

** Instalaci√≥n de dependencias
Ejecute el siguiente comando para instalar los requerimientos del m√≥dulo
Perceptr√≥n Multicapa *feedforward*.

#+BEGIN_SRC bash
pip install numpy matplotlib scikit-learn pygame
#+END_SRC

** Verificaci√≥n de la instalaci√≥n
Para verificar que las dependencias se instalaron correctamente, ejecute Python
en modo interactivo:

#+BEGIN_SRC bash
python
#+END_SRC

Posteriormente, importe las librer√≠as:

#+BEGIN_SRC python
import numpy
import matplotlib
import sklearn
import pygame
print("Instalaci√≥n de requerimientos completada correctamente")
#+END_SRC

** Desactivaci√≥n del entorno virtual
Una vez finalizado el trabajo, el entorno virtual puede desactivarse con el
siguiente comando:

#+BEGIN_SRC bash
deactivate
#+END_SRC

* Manual de Entornos Virtuales en Python

** Introducci√≥n
El uso de entornos virtuales es esencial para mantener las
dependencias de tus proyectos aisladas. En este manual aprender√°s a
gestionarlos usando el m√≥dulo est√°ndar =venv=.

** Flujo de Trabajo B√°sico

*** 1. Creaci√≥n del entorno
Para crear un entorno virtual, navega a la ra√≠z de tu proyecto en la terminal (o dentro de un buffer de Emacs con =M-x shell=) y ejecuta:

#+begin_src bash
python -m venv .venv
#+end_src

*Nota:* El nombre =.venv= es una convenci√≥n que hace que el directorio sea oculto en sistemas Unix.

*** 2. Activaci√≥n
La activaci√≥n depende de tu sistema operativo:

**** En Windows (PowerShell)
#+begin_src powershell
.\.venv\Scripts\Activate.ps1
#+end_src

**** En macOS / Linux
#+begin_src bash
source .venv/bin/activate
#+end_src

** Gesti√≥n de paquetes
Una vez activado (ver√°s el prefijo =(.venv)= en tu prompt), puedes instalar librer√≠as:

#+begin_src bash
pip install requests pandas
#+end_src


** El archivo de Requerimientos
Es fundamental para la reproducibilidad del proyecto.

** Exportar dependencias
#+begin_src bash
pip freeze > requirements.txt
#+end_src

** Instalar desde el archivo
#+begin_src bash
pip install -r requirements.txt
#+end_src

** Tips de Limpieza
Para salir del entorno virtual:
#+begin_src bash
deactivate
#+end_src

Para borrar el entorno, simplemente elimina la carpeta:
#+begin_src bash
rm -rf .venv  # En Linux/macOS
rmdir /s /q .venv  # En Windows
#+end_src

---
#+BEGIN_QUOTE
"Keep your global Python clean, keep your projects isolated."
#+END_QUOTE




** Entornos Virtuales Python (Edici√≥n Windows)

** Requisitos Previos
1. Tener instalado Python (descargado de [[https://www.python.org/][python.org]] o la Microsoft Store).
2. Durante la instalaci√≥n, aseg√∫rate de marcar la casilla: **"Add Python to PATH"**.

** Flujo de Trabajo en Windows

*** 1. Crear el Entorno Virtual
Abre tu terminal (PowerShell o CMD) en la carpeta de tu proyecto. El comando es el mismo para ambos:

#+begin_src powershell
python -m venv venv
#+end_src

*** 2. El Paso Cr√≠tico: La Activaci√≥n
En Windows, la activaci√≥n depende de qu√© terminal est√©s usando.

**** Opci√≥n A: PowerShell (Recomendado)
Si es la primera vez que usas scripts en Windows, podr√≠as recibir un error de seguridad. Primero, ejecuta esto como administrador (solo una vez):
#+begin_src powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
#+end_src

Luego, para activar el entorno:
#+begin_src powershell
.\venv\Scripts\Activate.ps1
#+end_src

**** Opci√≥n B: S√≠mbolo del Sistema (CMD)
#+begin_src cmd
.\venv\Scripts\activate.bat
#+end_src

*** 3. Confirmaci√≥n
Sabr√°s que el entorno est√° activo porque el nombre =(venv)= aparecer√° a la izquierda de la ruta en tu terminal:
#+example
(venv) C:\Proyectos\MiProyecto>
#+example

** Gesti√≥n de Librer√≠as con PIP

*** Instalaci√≥n de paquetes
Una vez activo el entorno, instala lo que necesites:
#+begin_src powershell
pip install pandas requests openpyxl
#+end_src

*** Congelar dependencias (Compartir proyecto)
Para que otros participantes tengan exactamente lo mismo que t√∫:
#+begin_src powershell
pip freeze > requirements.txt
#+end_src

*** Instalar desde un archivo recibido
Si un compa√±ero te pasa su =requirements.txt=:
#+begin_src powershell
pip install -r requirements.txt
#+end_src

** Uso de Entornos en Emacs (Windows)

Para que Emacs en Windows gestione bien el entorno, a√±ade esto a tu archivo de configuraci√≥n (=init.el= o =.emacs=):

*** Instalaci√≥n del paquete pyvenv
#+begin_src elisp
(use-package pyvenv
  :ensure t
  :config
  (pyvenv-mode 1))
#+end_src

*** C√≥mo activarlo dentro de Emacs
1. Presiona =M-x pyvenv-activate=.
2. Emacs te pedir√° la ruta. Navega hasta la carpeta =venv= de tu proyecto.
3. Al seleccionarla, Emacs usar√° ese int√©rprete de Python para todos los scripts que ejecutes.

** Soluci√≥n de Problemas Comunes en Windows

| Error / Problema | Soluci√≥n |
| :--- | :--- |
| "python" no se reconoce | Reinstala Python y marca "Add to PATH" o usa el comando `py`. |
| Error de "Execution Policy" | Ejecuta `Set-ExecutionPolicy RemoteSigned -Scope CurrentUser`. |
| No aparece el (venv) | Aseg√∫rate de usar el comando de activaci√≥n correcto para tu terminal (.ps1 vs .bat). |

** Desactivaci√≥n y Limpieza
Para salir del entorno:
#+begin_src powershell
deactivate
#+end_src

Si quieres borrar el entorno por completo (para empezar de cero):
#+begin_src powershell
rmdir /s /q venv
#+end_src

---
#+BEGIN_IMPORTANT
*Recordatorio:* Nunca incluyas la carpeta =venv= en tus archivos compartidos o en tu repositorio de Git. Solo comparte el c√≥digo y el archivo =requirements.txt=.
#+END_IMPORTANT








** Agregar a jupyter notebook

#+BEGIN_SRC shell
pip install ipykernel
python -m ipykernel install --user --name=redes --display-name="redes"
#+END_SRC

* Introducci√≥n a la Inteligencia Artificial (IA)
** Definici√≥n formal

La *Inteligencia Artificial* es el √°rea de la computaci√≥n que estudia
  c√≥mo construir sistemas capaces de realizar tareas que, si fueran
  realizadas por humanos, requerir√≠an inteligencia.

Esto incluye capacidades como:

- Aprender de la experiencia
- Razonar
- Reconocer patrones
- Tomar decisiones bajo incertidumbre

La IA no implica necesariamente consciencia; se centra en *comportamiento inteligente observable*.

** IA d√©bil vs IA fuerte

- *IA d√©bil*: sistemas especializados en una tarea concreta (la IA actual)
- *IA fuerte*: inteligencia general comparable a la humana (te√≥rica)

Las redes neuronales pertenecen claramente a la IA d√©bil.


* Machine Learning (Aprendizaje Autom√°tico)
  ** Relaci√≥n entre IA y ML
  El *Machine Learning (ML)* es una subdisciplina de la IA. Mientras la IA es el objetivo general, el ML es una de las herramientas principales para alcanzarlo.

Idea clave:
#+begin_quote
En lugar de programar reglas, el sistema aprende las reglas a partir de datos.
#+end_quote

** Tipos de aprendizaje

- *Supervisado*: datos con etiqueta (clasificaci√≥n, regresi√≥n)
- *No supervisado*: datos sin etiqueta (clustering, reducci√≥n de dimensi√≥n)
- *Por refuerzo*: aprendizaje mediante recompensa y castigo

Las redes neuronales pueden adaptarse a los tres esquemas.


* Historia de las Redes Neuronales
** Contexto hist√≥rico
Desde mediados del siglo XX, cient√≠ficos han intentado entender si la inteligencia pod√≠a ser replicada mediante modelos matem√°ticos.

** McCulloch y Pitts (1943)
Propusieron la primera neurona artificial basada en l√≥gica
booleana. Demostraron que redes de estas neuronas pod√≠an computar
cualquier funci√≥n l√≥gica.

Este trabajo sent√≥ las bases te√≥ricas de las redes neuronales.

** Perceptr√≥n y optimismo inicial
En los a√±os 50 y 60, el perceptr√≥n gener√≥ grandes expectativas al ser uno de los primeros sistemas que *aprend√≠a* autom√°ticamente.

** Cr√≠ticas y estancamiento
El libro *Perceptrons* (Minsky & Papert, 1969) demostr√≥ limitaciones severas del perceptr√≥n, provocando una fuerte ca√≠da en el inter√©s por las redes neuronales.

** Renacimiento moderno

Con mayor poder computacional, grandes bases de datos y mejores algoritmos, las redes neuronales resurgen como *Deep Learning*.





* La Neurona Artificial
** Motivaci√≥n
  Una red neuronal artificial es un modelo matem√°tico inspirado en la
  organizaci√≥n y conectividad de las neuronas biol√≥gicas, que abstrae
  su funcionamiento esencial para construir sistemas capaces de
  aprender representaciones a partir de datos mediante el ajuste de
  par√°metros.

** Componentes

- Entradas: variables num√©ricas
- Pesos: importancia relativa de cada entrada
- Bias: ajuste del umbral
- Activaci√≥n: decisi√≥n final

** Modelo matem√°tico
#+begin_src text
z = w¬∑x + b
a = f(z)
#+end_src

Este modelo es la unidad b√°sica de todas las redes neuronales modernas.


* El Perceptr√≥n
** Definici√≥n
  El perceptr√≥n es una neurona artificial entrenable utilizada para clasificaci√≥n binaria.

** Interpretaci√≥n geom√©trica
El perceptr√≥n aprende una *frontera de decisi√≥n lineal* que separa los datos en dos clases.

** Aprendizaje

Cuando el perceptr√≥n se equivoca, ajusta sus pesos para reducir el error.

** Limitaciones
No puede aprender relaciones no lineales, como XOR.


* ¬øQu√© es un problema linealmente separable?

**  Intuici√≥n b√°sica 

Un problema es linealmente separable si puedes separar las clases usando una l√≠nea recta (en 2D),
un plano (en 3D), o en general un hiperplano.
Si existe una sola frontera recta que divide perfectamente las clases, el problema es linealmente separable.



* Estructura de un Perceptr√≥n Simple


** Entradas (Inputs)
- Representadas como $x_1, x_2, ..., x_n$.
- Son los datos brutos o caracter√≠sticas que recibe el modelo.

** Pesos Sin√°pticos (Weights)
- Representados como $w_1, w_2, ..., w_n$.
- Determinan la importancia o influencia de cada entrada en el resultado final.

** Suma Ponderada (Weighted Sum)
- Es la combinaci√≥n lineal de las entradas y los pesos.
- La f√≥rmula matem√°tica es:
  $$z = \sum_{i=1}^{n} w_i x_i + b$$

  
** Sesgo (Bias)
- Representado generalmente como $b$ (o $w_0$).
- Permite desplazar la funci√≥n de activaci√≥n hacia la izquierda o derecha para ajustar mejor los datos.

** Funci√≥n de Activaci√≥n
- Decide si la neurona debe "dispararse" (activarse) o no.
- En el perceptr√≥n original de Rosenblatt, se utiliza la *Funci√≥n Escal√≥n* (Heaviside):
  - $f(z) = 1$ si $z > 0$
  - $f(z) = 0$ en caso contrario.

** Salida (Output)
- Es el resultado final del procesamiento ($\hat{y}$).
- En un perceptr√≥n simple, suele ser un valor binario (0 o 1).


* Ejemplo Tacos

** 1. El Escenario: La Decisi√≥n de la Cena
Para entender c√≥mo aprende una IA, vamos a usar un ejemplo de la vida real. Queremos que nuestra neurona artificial aprenda cu√°ndo estamos "Satisfechos" (1) o "Inconformes" (0).

*** Nuestras Entradas (Inputs)
- $x_0$: ¬øHay Tacos? (1 = S√≠, 0 = No)
- $x_1$: ¬øHay Refresco? (1 = S√≠, 0 = No)

*** El Peso (Weight): La Importancia
No todo nos hace igual de felices. Los **Pesos** ($w_0, w_1$) representan qu√© tanto nos importa cada ingrediente. 
- Si el peso del taco es alto, el taco es fundamental para nuestra felicidad.

** 2. ¬øC√≥mo toma la decisi√≥n? (La Suma y el Sesgo)
La neurona hace un c√°lculo matem√°tico simple:
$$net = (x_0 \cdot w_0) + (x_1 \cdot w_1) - \text{bias}$$

*** El Sesgo (Bias)
El **Bias** es nuestro "nivel de exigencia". Si el Bias es muy alto, necesitaremos mucha comida (pesos altos) para poder llegar a estar satisfechos.

** 3. El Descenso del Gradiente: ¬øC√≥mo "Aprende" la Neurona?
Cuando la neurona se equivoca, necesita ajustar sus pesos. Este proceso se llama **Descenso del Gradiente**.

*** El Error: La Br√∫jula
Si esper√°bamos estar felices (~target = 1~) pero la neurona dice que estamos tristes (~net = 0~), tenemos un **Error de 1**.
$$Error = Target - Net$$

*** El Ajuste (La Regla Delta)
Para corregir el error, cambiamos los pesos usando esta l√≥gica:
1. Miramos el **Error**.
2. Miramos la **Entrada** (¬øQui√©n tuvo la culpa? Si no hab√≠a tacos, el taco no pudo causar el error).
3. Aplicamos el **Learning Rate (K)**: Que es qu√© tan r√°pido queremos aprender.

$$Nuevo\_Peso = Peso\_Actual + (K \cdot Error \cdot Entrada)$$


Imagina que $K = 0.1$ y el Peso inicial del taco es $0.5$.
1. **Situaci√≥n:** Hay tacos ($x_0=1$), pero la red dice "Triste" ($net=0$). Nosotros quer√≠amos "Feliz" ($target=1$).
2. **C√°lculo del Error:** $1 - 0 = 1$.
3. **Ajuste del Peso:**
   - $Delta = 0.1 \cdot 1 \cdot 1 = 0.1$
   - $Nuevo\_Peso\_Taco = 0.5 + 0.1 = 0.6$

**Resultado:** La pr√≥xima vez que haya tacos, la neurona estar√° un poco m√°s cerca de hacernos felices. ¬°Eso es el aprendizaje!

Puntos importantes

- El **Gradiente** nos dice en qu√© direcci√≥n mover los pesos para que el error sea cero.
- El **Learning Rate** controla qu√© tan grandes son los pasos que damos hacia esa soluci√≥n.
- Si repetimos este proceso miles de veces (√âpocas), la neurona encontrar√° los pesos perfectos para nuestra felicidad.


** Perceptr√≥n ejemplo (Python)

1. Recibe entradas ($x_1, x_2, \dots$).
2. Las multiplica por pesos ($w_1, w_2, \dots$).
3. Suma un sesgo ($b$).
4. Aplica una funci√≥n de activaci√≥n (ej. Escal√≥n).

*** Perceptr√≥n para una compuerta "AND"
Este c√≥digo simula una neurona que solo se activa si ambas entradas son 1.

#+begin_src python :results output
def perceptron_and(x1, x2):
    # 1. Definimos los Pesos y el Sesgo (Bias)
    # Estos valores normalmente se aprenden, aqu√≠ los asignamos manualmente
    w1, w2 = 0.5, 0.5
    bias = -0.7

    # 2. Suma ponderada: (x1 * w1) + (x2 * w2) + bias
    suma = (x1 * w1) + (x2 * w2) + bias

    # 3. Funci√≥n de activaci√≥n (Escal√≥n de Heaviside)
    # Si la suma es mayor a 0, la neurona se dispara (1)
    if suma > 0:
        return 1
    else:
        return 0

# Prueba de la tabla de verdad AND
entradas = [(0, 0), (0, 1), (1, 0), (1, 1)]

print("Entrada | Salida")
print("--------|-------")
for e in entradas:
    resultado = perceptron_and(e[0], e[1])
    print(f" {e}  |   {resultado}")
#+end_src

#+RESULTS:
: Entrada | Salida
: --------|-------
:  (0, 0)  |   0
:  (0, 1)  |   0
:  (1, 0)  |   0
:  (1, 1)  |   1




* Codigo C python

#+BEGIN_SRC python
import math
import random

EPOCAS = 300000
K = 0.03  # tasa de aprendizaje

# Pesos y bias globales (como en el c√≥digo C)
Pesos = [0.0, 0.0]
bias = 0.5
Error = 0.0


def sigmoide(s: float) -> float:
    # Versi√≥n correcta de la sigmoide log√≠stica:
    # 1 / (1 + e^{-s})
    return 1.0 / (1.0 + math.exp(-s))


def pesos_initNt():
    """Inicializa los pesos de forma aleatoria en [0,1)."""
    global Pesos
    Pesos = [random.random() for _ in range(2)]


def EntNt(x0: float, x1: float, target: float) -> float:
    """
    Funci√≥n de entrenamiento del perceptr√≥n (una iteraci√≥n para un patr√≥n).
    Modifica Pesos y bias de forma global.
    """
    global Pesos, bias, Error

    # net = w0*x0 + w1*x1 - bias
    net = Pesos[0] * x0 + Pesos[1] * x1 - bias
    net = sigmoide(net)

    Error = target - net

    # Actualizaci√≥n de bias (se asume entrada de bias = 1)
    bias -= K * Error

    # Variaci√≥n de los pesos sin√°pticos
    delta0 = K * Error * x0
    delta1 = K * Error * x1

    # Ajuste de pesos
    Pesos[0] += delta0
    Pesos[1] += delta1

    return net


def InitNt(x0: float, x1: float) -> float:
    """
    Funci√≥n que usa pesos fijos (de ejemplo) para calcular la salida.
    Equivalente a la parte comentada en C.
    """
    # net = 70.934807*x0 + 93.935219*x1 - 187.886169;
    net = 70.934807 * x0 + 93.935219 * x1 - 187.886169
    net = sigmoide(net)
    return net


def main():
    global Pesos, bias, Error

    pesos_initNt()

    for i in range(EPOCAS):
        print("------------------------")
        print(f"Salida Entrenamiento Epoca {i}")

        apr = EntNt(1, 1, 0)
        print(f"1,1 = {apr:.6f}")

        apr = EntNt(1, 0, 1)
        print(f"1,0 = {apr:.6f}")

        apr = EntNt(0, 1, 1)
        print(f"0,1 = {apr:.6f}")

        apr = EntNt(0, 0, 0)
        print(f"0,0 = {apr:.6f}")

        print("\nPesos de cada epoca")
        print(f"Peso 0 = {Pesos[0]:.6f}")
        print(f"Peso 1 = {Pesos[1]:.6f}")
        print(f"Bias   = {bias:.6f}")
        print(f"Error  = {Error:.6f}")
        print("------------------------")

    # Si quieres probar con los pesos fijos del comentario de C:
    # print("Resultados con InitNt:")
    # print("1,1 =", InitNt(1, 1))
    # print("1,0 =", InitNt(1, 0))
    # print("0,1 =", InitNt(0, 1))
    # print("0,0 =", InitNt(0, 0))


if __name__ == "__main__":
    main()
#+END_SRC


* Redes Neuronales Multicapa (Multilayer Perceptron)

** Introducci√≥n

Una *red neuronal multicapa* o *Perceptr√≥n Multicapa (MLP)* es un modelo
de aprendizaje supervisado que extiende al perceptr√≥n simple mediante
la inclusi√≥n de *una o m√°s capas ocultas*. Estas capas permiten modelar
*relaciones no lineales complejas* entre las variables de entrada y la salida.

Los MLP constituyen la base conceptual del *Deep Learning* moderno:

- El perceptr√≥n simple solo puede resolver problemas *linealmente separables*.
- Muchos problemas reales (visi√≥n, texto, se√±ales) son *no lineales*.
- Agregar capas ocultas + funciones de activaci√≥n no lineales permite
  aproximar funciones mucho m√°s complejas (teorema del aproximador universal).

Ejemplos cl√°sicos (con 2 entradas):

- AND  ‚Üí ‚úì separable linealmente
- OR   ‚Üí ‚úì separable linealmente
- XOR  ‚Üí ‚úó *no* es separable linealmente

El problema XOR demuestra la necesidad de introducir:

- *Capas ocultas* (capacidad de representar interacciones no triviales),
- *Funciones de activaci√≥n no lineales*.

Un MLP t√≠pico est√° compuesto por:

1. *Capa de entrada*  
   Recibe el vector de caracter√≠sticas \(\mathbf{x}\).

2. *Capas ocultas*  
   Realizan transformaciones lineales + no lineales sobre las
   representaciones intermedias.

3. *Capa de salida*  
   Produce la predicci√≥n final (clase, probabilidad, valor continuo, etc.).

Estructura conceptual:

#+begin_example
x ‚Üí Capa Oculta 1 ‚Üí Capa Oculta 2 ‚Üí ‚Ä¶ ‚Üí Capa de salida ‚Üí ≈∑
#+end_example

Cada ‚Äúflecha‚Äù representa una transformaci√≥n lineal (multiplicaci√≥n por
matriz de pesos + suma de bias) seguida de una funci√≥n de activaci√≥n.

** Modelo matem√°tico

*** Neurona individual

Cada neurona recibe un vector de entrada \(\mathbf{x} \in \mathbb{R}^n\) y calcula:

\[
z = \sum_{i=1}^{n} w_i x_i + b
\]

\[
a = f(z)
\]

Donde:

- \(w_i\): pesos sin√°pticos de la neurona,
- \(b\): t√©rmino de sesgo (bias),
- \(f(\cdot)\): funci√≥n de activaci√≥n,
- \(z\): combinaci√≥n lineal de las entradas,
- \(a\): salida (activaci√≥n) de la neurona.

En forma vectorial para una neurona:

\[
z = \mathbf{w}^\top \mathbf{x} + b
\]

\[
a = f(z)
\]

*** Forma matricial de una capa

En una capa con m√∫ltiples neuronas, se usa notaci√≥n matricial:

- \(\mathbf{a}^{(l-1)}\): vector de activaciones de la capa anterior,
- \(\mathbf{W}^{(l)}\): matriz de pesos de la capa \(l\),
- \(\mathbf{b}^{(l)}\): vector de bias de la capa \(l\),
- \(\mathbf{z}^{(l)}\): preactivaciones de la capa \(l\),
- \(\mathbf{a}^{(l)}\): activaciones de la capa \(l\).

C√°lculo:

\[
\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}
\]

\[
\mathbf{a}^{(l)} = f(\mathbf{z}^{(l)})
\]

donde \(f\) se aplica componente a componente.

Repitiendo este proceso desde la capa de entrada hasta la salida,
obtenemos la predicci√≥n del MLP.

** Funciones de activaci√≥n

Las funciones de activaci√≥n son componentes fundamentales en las redes
neuronales multicapa. Su funci√≥n principal es introducir *no linealidad*
en el modelo.

Sin funciones de activaci√≥n no lineales:

- cada capa ser√≠a solo una transformaci√≥n lineal,
- y la composici√≥n de m√∫ltiples transformaciones lineales es *otra*
  transformaci√≥n lineal,
- por lo tanto, una ‚Äúred profunda‚Äù sin no linealidad se comporta como
  un *modelo lineal simple*, independientemente del n√∫mero de capas.

*** ¬øPara qu√© sirven las funciones de activaci√≥n?

Las funciones de activaci√≥n permiten:

- Introducir *no linealidad* en la red.
- Modelar relaciones complejas entre variables de entrada y salida.
- Aprender fronteras de decisi√≥n no lineales en problemas de clasificaci√≥n.
- Aproximar cualquier funci√≥n continua bajo ciertas condiciones
  (teorema del aproximador universal).

Recordemos que una neurona realiza:

\[
z = \sum_{i=1}^{n} w_i x_i + b
\]

\[
a = f(z)
\]

Donde \(f\) es la funci√≥n de activaci√≥n.

** Clasificaci√≥n de las funciones de activaci√≥n

Las funciones de activaci√≥n pueden clasificarse seg√∫n:

- su forma (escal√≥n, sigmoide, lineal por partes, etc.),
- su rango de salida,
- su uso (capas ocultas vs capa de salida),
- su comportamiento para valores grandes de \(|z|\).

*** Funciones de activaci√≥n cl√°sicas

**** Funci√≥n escal√≥n (Step Function)

\[
f(z) =
\begin{cases}
1 & \text{si } z \ge 0 \\
0 & \text{si } z < 0
\end{cases}
\]

Caracter√≠sticas:

- Usada en el perceptr√≥n simple original.
- No es continua ni derivable (no adecuada para descenso de gradiente).
- Genera salidas binarias (0/1).

Uso:

- Modelos te√≥ricos e hist√≥ricos.
- Introducci√≥n al concepto de neurona como ‚Äúdisparar / no disparar‚Äù.
- No se utiliza en redes multicapa modernas para entrenamiento con
  backpropagation.

**** Sigmoide log√≠stica

\[
f(z) = \frac{1}{1 + e^{-z}}
\]

Caracter√≠sticas:

- Salida en el intervalo \((0, 1)\).
- Puede interpretarse como una probabilidad.
- Es suave y derivable en todo \(\mathbb{R}\).

Ventajas:

- Interpretaci√≥n probabil√≠stica directa.
- Hist√≥ricamente muy usada en redes neuronales tempranas.

Desventajas:

- Para \(|z|\) grandes, la funci√≥n se *satura* cerca de 0 o 1:
  - la derivada es muy peque√±a,
  - aparece el problema de *vanishing gradient*,
  - el entrenamiento de redes profundas se vuelve lento o ineficaz.

Uso t√≠pico actual:

- Capa de salida en algunos modelos de clasificaci√≥n binaria (aunque
  en deep learning moderno tambi√©n se usan otras combinaciones).

**** Tangente hiperb√≥lica (tanh)

\[
f(z) = \tanh(z)
\]

Caracter√≠sticas:

- Salida en el intervalo \((-1, 1)\).
- Es sim√©trica alrededor de 0 (centrada en cero).

Ventajas:

- En comparaci√≥n con la sigmoide log√≠stica, su salida centrada en cero:
  - puede favorecer una convergencia algo m√°s r√°pida,
  - reduce ciertos sesgos en las activaciones.

Desventajas:

- Tambi√©n se satura para \(|z|\) grandes.
- Sigue presentando *vanishing gradient* en redes muy profundas.

Uso cl√°sico:

- Capas ocultas en redes no demasiado profundas, antes de la adopci√≥n
  masiva de ReLU.

*** Funciones de activaci√≥n modernas

**** ReLU (Rectified Linear Unit)

\[
f(z) = \max(0, z)
\]

Caracter√≠sticas:

- Funci√≥n lineal por partes:
  - para \(z < 0\): salida 0,
  - para \(z \ge 0\): salida \(z\).
- Muy sencilla y eficiente de calcular.

Ventajas:

- No se satura para valores positivos grandes (derivada constante 1).
- Reduce considerablemente el problema del *vanishing gradient*.
- Ha permitido entrenar redes profundas con muchas capas.

Desventajas:

- *Dead neurons*: si una neurona recibe valores de \(z\) siempre
  negativos, su salida es siempre 0 y el gradiente puede quedar en 0
  ‚Üí deja de aprender.

Uso t√≠pico:

- Funci√≥n est√°ndar en *capas ocultas* de MLP y CNN modernos.

**** Leaky ReLU

\[
f(z) =
\begin{cases}
z & \text{si } z \ge 0 \\
\alpha z & \text{si } z < 0
\end{cases}
\]

donde \(\alpha\) es un peque√±o n√∫mero positivo (por ejemplo, 0.01).

Caracter√≠sticas:

- Variante de ReLU que, en lugar de ‚Äúapagar‚Äù totalmente la neurona para
  \(z < 0\), permite un peque√±o gradiente negativo.

Ventajas:

- Reduce el problema de neuronas muertas (*dead ReLU*).
- Mantiene muchas ventajas de ReLU.

Uso t√≠pico:

- Alternativa a ReLU cuando se observa que muchas neuronas quedan
  inactivas de manera permanente.

**** ELU (Exponential Linear Unit)

\[
f(z) =
\begin{cases}
z & \text{si } z \ge 0 \\
\alpha (e^{z} - 1) & \text{si } z < 0
\end{cases}
\]

Caracter√≠sticas:

- Para \(z \ge 0\): igual que ReLU.
- Para \(z < 0\): decae de forma exponencial, con salida negativa acotada.

Ventajas:

- Puede acelerar la convergencia en ciertos casos.
- Las salidas negativas ayudan a centrar la activaci√≥n alrededor de 0,
  lo que puede mejorar la propagaci√≥n del gradiente.

Uso t√≠pico:

- Capas ocultas, en algunos modelos donde se ha observado mejor
  rendimiento que con ReLU est√°ndar.

*** Funciones de activaci√≥n en la capa de salida

La funci√≥n de activaci√≥n de la *capa de salida* depende del tipo de
problema:

**** Clasificaci√≥n binaria

Se usa t√≠picamente una funci√≥n *sigmoide* para obtener una probabilidad
en \((0,1)\):

\[
\hat{y} = \sigma(z) \in (0,1)
\]

donde \(\hat{y}\) se interpreta como la probabilidad de clase ‚Äú1‚Äù.

**** Clasificaci√≥n multiclase (mutuamente excluyentes)

Se usa la funci√≥n *softmax*:

\[
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}
\]

- Convierte un vector de puntajes \(\mathbf{z}\) en un vector de
  probabilidades que:
  - son positivas,
  - y suman 1.

**** Regresi√≥n

- Se usa generalmente una funci√≥n de activaci√≥n *lineal* en la salida:
  \[
    f(z) = z
  \]
- La red puede entonces producir valores reales sin restricci√≥n de
  rango (o con restricciones adicionales impuestas por el preprocesado).

*** Impacto en el entrenamiento

La elecci√≥n de la funci√≥n de activaci√≥n afecta:

- La *velocidad de convergencia*.
- La *estabilidad* del entrenamiento.
- El *flujo del gradiente* a trav√©s de las capas.
- La capacidad de representar ciertas distribuciones de salida.

Una elecci√≥n inadecuada:

- puede causar vanishing/exploding gradient,
- puede impedir que la red aprenda adecuadamente,
- o requerir tiempos de entrenamiento excesivos.

** Propagaci√≥n hacia adelante (Forward Propagation)

La *propagaci√≥n hacia adelante* es el proceso mediante el cual la red
calcula su salida a partir de una entrada dada.

Pasos generales:

1. Se recibe el vector de entrada \(\mathbf{x}\).
2. Se calcula sucesivamente:
   - \(\mathbf{z}^{(1)}\), \(\mathbf{a}^{(1)}\) (primera capa oculta),
   - \(\mathbf{z}^{(2)}\), \(\mathbf{a}^{(2)}\), etc.
3. Se obtiene la activaci√≥n de la capa de salida \(\mathbf{a}^{(L)}\),
   que corresponde a la predicci√≥n \(\hat{\mathbf{y}}\).

Podemos verlo como una composici√≥n de funciones:

\[
\mathbf{a}^{(L)} = f^{(L)}\left( \mathbf{W}^{(L)} \, f^{(L-1)}\left( \dots f^{(1)}\left(\mathbf{W}^{(1)} \mathbf{x} + \mathbf{b}^{(1)}\right) \dots \right) + \mathbf{b}^{(L)} \right)
\]

o, de forma m√°s compacta:

\[
\hat{\mathbf{y}} = F(\mathbf{x}; \theta)
\]

donde \(\theta\) denota el conjunto de todos los pesos y bias de la red.

** Funciones de p√©rdida

Las funciones de p√©rdida (o *funciones de coste*) miden el error entre:

- la predicci√≥n del modelo \(\hat{y}\) (o \(\hat{\mathbf{y}}\)),
- y el valor real \(y\) (o \(\mathbf{y}\)).

El objetivo del entrenamiento es encontrar par√°metros \(\theta\) que
*minimicen* la p√©rdida promedio sobre el conjunto de entrenamiento.

*** Error cuadr√°tico medio (MSE)

Com√∫n en problemas de regresi√≥n:

\[
\mathcal{L}_{\text{MSE}} = \frac{1}{n} \sum_{k=1}^{n} (y_k - \hat{y}_k)^2
\]

donde:

- \(n\) es el n√∫mero de muestras,
- \(y_k\) es el valor real de la muestra \(k\),
- \(\hat{y}_k\) es la predicci√≥n del modelo.

*** Entrop√≠a cruzada (Cross-Entropy)

Muy utilizada en clasificaci√≥n.

- Para clasificaci√≥n binaria:

\[
\mathcal{L}_{\text{binaria}} = - \frac{1}{n} \sum_{k=1}^{n} \left[ y_k \log(\hat{y}_k) + (1 - y_k)\log(1 - \hat{y}_k) \right]
\]

- Para clasificaci√≥n multiclase (one-hot \(\mathbf{y}\) y softmax \(\hat{\mathbf{y}}\)):

\[
\mathcal{L}_{\text{multiclase}} = - \frac{1}{n} \sum_{k=1}^{n} \sum_{c=1}^{C} y_{k,c} \log(\hat{y}_{k,c})
\]

donde:

- \(C\) es el n√∫mero de clases,
- \(y_{k,c}\) es 1 si la muestra \(k\) pertenece a la clase \(c\), y 0 en caso contrario,
- \(\hat{y}_{k,c}\) es la probabilidad predicha para la clase \(c\).

** Backpropagation

*Backpropagation* es el algoritmo fundamental para entrenar MLP. Se
basa en la aplicaci√≥n sistem√°tica de la *regla de la cadena* del c√°lculo
diferencial para propagar el error desde la capa de salida hacia las
capas anteriores.

Para un peso gen√©rico \(w\), la derivada de la p√©rdida se expresa como:

\[
\frac{\partial \mathcal{L}}{\partial w} =
\frac{\partial \mathcal{L}}{\partial a}
\cdot \frac{\partial a}{\partial z}
\cdot \frac{\partial z}{\partial w}
\]

donde:

- \(\frac{\partial \mathcal{L}}{\partial a}\): cu√°nto cambia la p√©rdida
  si cambia la activaci√≥n \(a\),
- \(\frac{\partial a}{\partial z}\): deriva de la funci√≥n de activaci√≥n,
- \(\frac{\partial z}{\partial w}\): relaci√≥n lineal entre \(z\) y el
  peso \(w\).

El algoritmo:

1. Calcula un *forward pass* (de entrada a salida).
2. Calcula la p√©rdida \(\mathcal{L}\).
3. Propaga gradientes hacia atr√°s usando la regla de la cadena.
4. Obtiene \(\frac{\partial \mathcal{L}}{\partial w}\) y
   \(\frac{\partial \mathcal{L}}{\partial b}\) para todos los pesos y
   bias de la red.
5. Usa estos gradientes para actualizar los par√°metros.

** Descenso de gradiente

El *descenso de gradiente* (gradient descent) es la regla de
actualizaci√≥n b√°sica para minimizar la funci√≥n de p√©rdida.

Para un peso \(w\):

\[
w := w - \eta \, \frac{\partial \mathcal{L}}{\partial w}
\]

donde:

- \(\eta\) es la *tasa de aprendizaje* (learning rate),
- \(\frac{\partial \mathcal{L}}{\partial w}\) es el gradiente de la
  p√©rdida respecto a \(w\).

Interpretaci√≥n:

- Nos movemos en la direcci√≥n *opuesta* al gradiente (descenso),
- La magnitud del paso est√° controlada por \(\eta\).

En la pr√°ctica:

- Se usan variantes como:
  - *Stochastic Gradient Descent (SGD)*,
  - SGD con *momentum*,
  - *Adam*, *RMSProp*, etc.
- Estas variantes mejoran:
  - la velocidad de convergencia,
  - la estabilidad num√©rica,
  - la capacidad de escapar de m√≠nimos locales poco profundos.


* Ejemplo Clasificaci√≥n del dataset Iris con MLP

Este apartado muestra un ejemplo completo en Python usando el dataset
cl√°sico Iris y una red neuronal feedforward (Perceptr√≥n Multicapa)
usando la librer√≠a scikit-learn.

El objetivo es clasificar flores Iris en tres clases:

- Setosa
- Versicolor
- Virginica


Importar librer√≠as

#+begin_src python
import numpy as np
from sklearn.datasets import load_iris 
from sklearn.model_selection import train_test_split 
from sklearn.preprocessing import StandardScaler 
from sklearn.neural_network import MLPClassifier 
from sklearn.metrics import accuracy_score, classification_report
#+end_src

Cargar el dataset Iris

#+begin_src python
iris = load_iris()
X = iris.data #
#Caracter√≠sticas (150 x 4)
y = iris.target # Clases (150,)
print(X.shape) print(y.shape)
#+end_src

Las 4 caracter√≠sticas son:

- Largo del s√©palo
- Ancho del s√©palo
- Largo del p√©talo
- Ancho del p√©talo

Las clases est√°n codificadas como:

- 0 ‚Üí Setosa
- 1 ‚Üí Versicolor
- 2 ‚Üí Virginica

El siguiente fragmento de c√≥digo realiza la partici√≥n del conjunto de
datos original en dos subconjuntos disjuntos: uno destinado al
entrenamiento del modelo y otro a su evaluaci√≥n.

#+begin_src python
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y )
#+end_src

Prop√≥sito de la partici√≥n:

En aprendizaje autom√°tico supervisado, es fundamental evaluar la
capacidad de generalizaci√≥n de un modelo. Para ello, los datos
disponibles se dividen en:

- *Conjunto de entrenamiento*: utilizado para ajustar los par√°metros del modelo (pesos y sesgos).
- *Conjunto de prueba*: utilizado exclusivamente para medir el desempe√±o
  del modelo sobre datos no vistos durante el entrenamiento.

Esta separaci√≥n permite detectar fen√≥menos como overfitting y
underfitting, y proporciona una estimaci√≥n m√°s realista del
rendimiento esperado en producci√≥n.

*El par√°metro*:
#+BEGIN_SRC python
test_size=0.2
#+END_SRC
indica que el 20 % del conjunto total de datos se reserva para el
conjunto de prueba, mientras que el 80 % restante se utiliza para
entrenamiento. Esta proporci√≥n es com√∫n en la pr√°ctica y representa un
compromiso razonable entre:

- disponer de suficientes datos para entrenar el modelo, y
- contar con una muestra representativa para evaluar su generalizaci√≥n.

** Reproducibilidad del experimento

El par√°metro:

#+BEGIN_SRC python
random_state=42
#+END_SRC

fija la semilla del generador de n√∫meros aleatorios utilizado durante
la partici√≥n.  Esto garantiza que la divisi√≥n de los datos sea
reproducible, es decir, que m√∫ltiples ejecuciones del mismo c√≥digo
produzcan exactamente la misma separaci√≥n entre entrenamiento y
prueba.

La reproducibilidad es un requisito esencial en entornos cient√≠ficos y
acad√©micos, ya que permite validar y comparar resultados de manera
consistente.

** Estratificaci√≥n de clases

El par√°metro:

#+BEGIN_SRC python
stratify=y
#+END_SRC

indica que la divisi√≥n debe realizarse de forma estratificada,
conservando la proporci√≥n original de cada clase en ambos
subconjuntos.

Esto es especialmente importante en problemas de clasificaci√≥n, ya que
una divisi√≥n aleatoria sin estratificaci√≥n podr√≠a provocar:

- conjuntos de entrenamiento o prueba con clases desbalanceadas,
- m√©tricas de desempe√±o enga√±osas,
- modelos que no aprendan adecuadamente clases minoritarias.

Mediante la estratificaci√≥n, se asegura que tanto el conjunto de
entrenamiento como el de prueba sean representativos de la
distribuci√≥n real de las clases.

** Importancia en redes neuronales

En el contexto de redes neuronales (incluyendo MLP):

- el entrenamiento ajusta los pesos minimizando una funci√≥n de p√©rdida
  sobre X_train,

- la evaluaci√≥n sobre X_test permite medir la capacidad del modelo
  para generalizar,

- una mala partici√≥n puede conducir a conclusiones err√≥neas sobre el
  desempe√±o del modelo.

Por esta raz√≥n, la divisi√≥n adecuada del conjunto de datos constituye
un paso cr√≠tico previo al entrenamiento y no debe considerarse un
detalle menor de implementaci√≥n.


** Normalizaci√≥n de los datos

La normalizaci√≥n de los datos de entrada es un paso cr√≠tico en el
entrenamiento de redes neuronales, ya que influye directamente en la
estabilidad num√©rica, la velocidad de convergencia y la eficacia del
aprendizaje.

En una red neuronal, los pesos se ajustan mediante m√©todos de
optimizaci√≥n basados en gradientes. Si las variables de entrada
presentan escalas muy diferentes, el proceso de entrenamiento puede
volverse ineficiente o inestable.

En muchos conjuntos de datos, las caracter√≠sticas pueden tener rangos muy distintos. Por ejemplo:

- una variable puede tomar valores entre 0 y 1,
- otra entre 0 y 10‚Å∂,
- otra puede incluir valores negativos.

Cuando estos datos se introducen directamente en una red neuronal:

- los gradientes asociados a variables de gran escala dominan la actualizaci√≥n de los pesos,
- las funciones de activaci√≥n pueden saturarse,
- el descenso por gradiente se vuelve lento o err√°tico.

La normalizaci√≥n busca homogeneizar la escala de las entradas,
permitiendo que todas las caracter√≠sticas contribuyan de manera
equilibrada al aprendizaje.


Una de las t√©cnicas m√°s utilizadas es la estandarizaci√≥n, implementada
en scikit-learn mediante la clase StandardScaler.

#+begin_src python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test)
#+end_src

Este procedimiento transforma cada caracter√≠stica \(x\) seg√∫n la siguiente expresi√≥n:

\[
x' = \frac{x - \mu}{\sigma}
\]

donde:

- \( \mu \) es la media de la caracter√≠stica,
- \( \sigma \) es la desviaci√≥n est√°ndar de la caracter√≠stica.

Como resultado de esta transformaci√≥n, cada variable queda con:

- media aproximadamente igual a 0,
- desviaci√≥n est√°ndar igual a 1.

** Definir el Perceptr√≥n Multicapa (MLP)


El siguiente fragmento de c√≥digo define un *Perceptr√≥n Multicapa* (Multilayer Perceptron, MLP)
para un problema de clasificaci√≥n multiclase, utilizando la implementaci√≥n provista por
la biblioteca *scikit-learn*.

#+begin_src python
mlp = MLPClassifier(
    hidden_layer_sizes=(10, 10),
    activation='relu',
    solver='adam',
    learning_rate_init=0.001,
    max_iter=2000,
    random_state=42
)
#+end_src

Este modelo corresponde a una red neuronal *feedforward completamente conectada*,
entrenada mediante *backpropagation* y optimizada usando m√©todos de descenso por gradiente.

*** Arquitectura de la red neuronal

La arquitectura del MLP queda determinada por el n√∫mero de caracter√≠sticas de entrada,
las capas ocultas definidas expl√≠citamente y el n√∫mero de neuronas en la capa de salida.

*** Capa de entrada

- La capa de entrada est√° compuesta por *4 neuronas*.
- Cada neurona representa una caracter√≠stica del vector de entrada.
- Esta capa no aplica transformaciones, √∫nicamente propaga los valores hacia la primera capa oculta.

Formalmente, el vector de entrada se expresa como:

\[
\mathbf{x} = (x_1, x_2, x_3, x_4)
\]

*** Capas ocultas

El par√°metro:

#+begin_src python
hidden_layer_sizes=(10, 10)
#+end_src

define *dos capas ocultas*, cada una con *10 neuronas*.

Caracter√≠sticas principales:

- Son capas *densas (fully connected)*.
- Cada neurona recibe como entrada la salida de *todas* las neuronas de la capa anterior.
- Permiten aprender representaciones no lineales del espacio de caracter√≠sticas.

Cada capa oculta implementa la transformaci√≥n:

\[
\mathbf{h}^{(l)} = f\left( \mathbf{W}^{(l)} \mathbf{h}^{(l-1)} + \mathbf{b}^{(l)} \right)
\]

donde:

- \( \mathbf{W}^{(l)} \) es la matriz de pesos,
- \( \mathbf{b}^{(l)} \) es el vector de sesgos,
- \( f(\cdot) \) es la funci√≥n de activaci√≥n.

*** Funci√≥n de activaci√≥n

El par√°metro:

#+begin_src python
activation='relu'
#+end_src

indica el uso de la funci√≥n *ReLU (Rectified Linear Unit)*, definida como:

\[
\text{ReLU}(z) = \max(0, z)
\]

Esta funci√≥n se utiliza porque:

- introduce no linealidad,
- reduce el problema del *vanishing gradient*,
- mejora la estabilidad del entrenamiento,
- es computacionalmente eficiente.

*** Capa de salida

- La capa de salida est√° compuesta por *3 neuronas*.
- Cada neurona corresponde a una de las clases del problema.
- Internamente, el modelo utiliza una funci√≥n *softmax* para obtener probabilidades.

La clase predicha se obtiene mediante la operaci√≥n *argmax* sobre las salidas.

*** Entrenamiento del modelo

El entrenamiento se realiza mediante el optimizador *Adam*:

#+begin_src python
solver='adam'
#+end_src

Adam combina:
- momentum
- tasas de aprendizaje adaptativas

lo que permite una convergencia m√°s r√°pida y estable en redes con m√∫ltiples capas.

La tasa de aprendizaje inicial se define como:

\[
\eta = 0.001
\]

controlando el tama√±o de los pasos durante la actualizaci√≥n de los pesos.

** N√∫mero de iteraciones

El par√°metro:

#+begin_src python
max_iter=2000
#+end_src

establece el n√∫mero m√°ximo de √©pocas de entrenamiento.
Una √©poca corresponde a un pase completo sobre el conjunto de entrenamiento.

Un n√∫mero elevado de √©pocas favorece la convergencia, aunque incrementa el riesgo de *overfitting*.

** Reproducibilidad

El par√°metro:

#+begin_src python
random_state=42
#+end_src

fija la semilla del generador de n√∫meros aleatorios, garantizando resultados reproducibles
en la inicializaci√≥n de los pesos y el proceso de entrenamiento.



** Entrenamiento del modelo

El entrenamiento de√± Perceptr√≥n Multicapa (MLP) consiste en ajustar
los pesos y sesgos de la red para minimizar el error de predicci√≥n
sobre los datos de entrenamiento.

#+begin_src python
mlp.fit(X_train, y_train)
#+end_src

Durante este proceso ocurren los siguientes pasos fundamentales:

*** Propagaci√≥n hacia adelante (forward pass)

Cada muestra de entrada x atraviesa la red capa por capa.

En cada neurona se calcula una combinaci√≥n lineal y se aplica una funci√≥n de activaci√≥n.

Se obtiene una salida y que representa la predicci√≥n del modelo.

*** C√°lculo del error

La salida predicha se compara con la etiqueta real ùë¶.
Se utiliza una funci√≥n de p√©rdida (por ejemplo, log-loss para clasificaci√≥n multiclase).

*** Backpropagation

El error se propaga desde la capa de salida hacia las capas
anteriores. Se calculan los gradientes del error respecto a cada peso
y sesgo. Se aplica la regla de la cadena del c√°lculo diferencial.

*** Descenso de gradiente con Adam

- Adam combina Momentum y RMSProp.
- Ajusta autom√°ticamente la tasa de aprendizaje para cada par√°metro.
- Proporciona convergencia r√°pida y estable.

** Evaluaci√≥n del modelo

Una vez entrenado el modelo, se eval√∫a su desempe√±o usando datos no vistos durante el entrenamiento.

#+begin_src python
y_pred = mlp.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred)) print("\nReporte de clasificaci√≥n:\n") print(classification_report(y_test, y_pred, target_names=iris.target_names))
#+end_src

*** M√©tricas utilizadas

- Accuracy: proporci√≥n total de predicciones correctas.
- Precision: qu√© tan confiables son las predicciones positivas.
- Recall: capacidad del modelo para encontrar todos los ejemplos de una clase.
- F1-score: balance entre precisi√≥n y recall.

En el dataset Iris, el accuracy suele estar en el rango del 95% al
100%, debido a su baja dimensionalidad y buena separaci√≥n entre
clases.

** Predicci√≥n con una nueva flor

El modelo entrenado puede utilizarse para predecir nuevas muestras.

#+begin_src python

#[largo_sepalo, ancho_sepalo, largo_petalo, ancho_petalo]

flor_nueva = np.array([[5.1, 3.5, 1.4, 0.2]])
#Normalizaci√≥n con el mismo scaler del entrenamiento
flor_nueva = scaler.transform(flor_nueva)
prediccion = mlp.predict(flor_nueva) print("Clase predicha:", iris.target_names[prediccion[0]])
#+end_src

Es fundamental aplicar la misma normalizaci√≥n usada en el entrenamiento para mantener coherencia en las escalas.

** Interpretaci√≥n matem√°tica del MLP

Cada neurona de la red realiza el siguiente c√°lculo:

#+begin_example
z = w ¬∑ x + b a = f(z)
#+end_example

Donde: ùë§ es el vector de pesos ùë• es el vector de entradas ùëè es el sesgo (bias) ùëì
es la funci√≥n de activaci√≥n (ReLU en las capas ocultas). La capa de salida utiliza la funci√≥n Softmax:

#+begin_latex
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}
#+end_latex

Esto permite interpretar las salidas como probabilidades para cada clase.

* Ejemplo Clasificaci√≥n de C√°ncer de Mama con MLP 

Este apartado muestra un ejemplo completo en Python usando el dataset
*Breast Cancer Wisconsin (Diagnostic)* y un *Perceptr√≥n Multicapa (MLP)*
usando la librer√≠a scikit-learn.

El objetivo es clasificar tumores en dos categor√≠as:

- 0 ‚Üí Maligno
- 1 ‚Üí Benigno

Este problema es un caso t√≠pico de **clasificaci√≥n binaria** en el
√°mbito m√©dico, donde es crucial:

- minimizar falsos negativos (tumor maligno clasificado como benigno),
- mantener una buena precisi√≥n general del modelo.

** Importar librer√≠as

#+begin_src python
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
#+end_src

En este bloque:

- =load_breast_cancer=: carga el dataset de c√°ncer de mama.
- =train_test_split=: divide en entrenamiento y prueba.
- =StandardScaler=: aplica estandarizaci√≥n a las caracter√≠sticas.
- =MLPClassifier=: implementa un Perceptr√≥n Multicapa (MLP).
- =accuracy_score= y =classification_report=: permiten evaluar el modelo.

** Cargar el dataset Breast Cancer

#+begin_src python
data = load_breast_cancer()
X = data.data      # Caracter√≠sticas (569 x 30)
y = data.target    # Etiquetas (569,)

print("Dimensiones de X:", X.shape)
print("Clases num√©ricas:", np.unique(y))
print("Nombres de clases:", data.target_names)
#+end_src

Este dataset contiene:

- 569 muestras (pacientes).
- 30 caracter√≠sticas num√©ricas que describen propiedades de los tumores
  (radio, textura, per√≠metro, √°rea, suavidad, compacidad, etc.).
- 2 clases:
  - 0 ‚Üí malignant (maligno)
  - 1 ‚Üí benign (benigno)

Cada muestra corresponde a una imagen de tejido mamario analizada
digitalmente. Las 30 caracter√≠sticas se derivan de medidas estad√≠sticas
de la forma, textura y estructura del tumor.

*** Importancia del dominio

En aplicaciones m√©dicas, la interpretaci√≥n de las predicciones es muy
sensible:

- un *falso negativo* (maligno etiquetado como benigno) puede retrasar
  un diagn√≥stico cr√≠tico;
- un *falso positivo* (benigno etiquetado como maligno) puede generar
  ansiedad y procedimientos innecesarios.

Por ello, adem√°s de la *accuracy*, suelen analizarse:

- sensibilidad (*recall*) para la clase ‚Äúmaligno‚Äù,
- especificidad,
- matriz de confusi√≥n, etc.

** Partici√≥n del conjunto de datos

Dividimos el dataset en entrenamiento y prueba:

#+begin_src python
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.3,
    random_state=42,
    stratify=y
)
#+end_src

*** Significado de los par√°metros

- =test_size=0.3=:
  - 30 % de los datos se reservan para el *conjunto de prueba*.
  - 70 % se usan para entrenar el modelo.
  - En este caso:
    - Entrenamiento: ‚âà 398 muestras.
    - Prueba: ‚âà 171 muestras.

- =random_state=42=:
  - Fija la semilla del generador de n√∫meros aleatorios.
  - Permite que la partici√≥n sea reproducible: el mismo c√≥digo genera
    siempre la misma divisi√≥n.

- =stratify=y=:
  - Asegura que la proporci√≥n de clases (maligno/benigno) sea similar
    tanto en entrenamiento como en prueba.
  - Esto es crucial en problemas m√©dicos, donde el balance de clases
    puede influir fuertemente en las m√©tricas.

*** Prop√≥sito de la partici√≥n

En aprendizaje autom√°tico supervisado:

- El *conjunto de entrenamiento* se usa para ajustar los par√°metros
  (pesos y sesgos) del modelo.
- El *conjunto de prueba* se usa *solo* para evaluar la capacidad de
  generalizaci√≥n sobre datos no vistos.

Esta separaci√≥n es esencial para:

- detectar *overfitting* (el modelo memoriza el entrenamiento pero
  generaliza mal),
- obtener una estimaci√≥n realista del rendimiento.

** Normalizaci√≥n (Estandarizaci√≥n)

Las caracter√≠sticas tienen escalas muy diferentes (√°reas grandes,
texturas peque√±as, etc.). Esto puede causar:

- problemas num√©ricos,
- gradientes desbalanceados,
- convergencia lenta o inestable.

Por ello, aplicamos estandarizaci√≥n:

#+begin_src python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
#+end_src

Este procedimiento transforma cada caracter√≠stica \(x\) seg√∫n:

#+begin_latex
x' = \frac{x - \mu}{\sigma}
#+end_latex

donde:

- \(\mu\) es la media de la caracter√≠stica calculada sobre el conjunto
  de entrenamiento,
- \(\sigma\) es la desviaci√≥n est√°ndar de dicha caracter√≠stica.

Despu√©s de la transformaci√≥n:

- cada variable tiene media aproximadamente 0,
- y desviaci√≥n est√°ndar aproximadamente 1.

*** Importante

- Solo se llama a =fit_transform= en =X_train=:
  - =fit= calcula \(\mu\) y \(\sigma\) usando *solo entrenamiento*.
  - =transform= aplica la transformaci√≥n.
- Para =X_test= se usa √∫nicamente =transform=:
  - se reescalan los datos de prueba con los mismos par√°metros
    (\(\mu\) y \(\sigma\)) obtenidos del entrenamiento.
- Esto evita *filtrar informaci√≥n del conjunto de prueba* hacia el
  proceso de entrenamiento (data leakage).

** Definici√≥n del Perceptr√≥n Multicapa (MLP)

Definimos un MLP para clasificaci√≥n binaria:

#+begin_src python
mlp = MLPClassifier(
    hidden_layer_sizes=(30, 15),
    activation='relu',
    solver='adam',
    max_iter=1000,
    random_state=42
)
#+end_src

*** Arquitectura del modelo

El MLP es una red neuronal *feedforward* completamente conectada.

- *Capa de entrada*:
  - Tiene tantas neuronas como caracter√≠sticas de entrada: 30.
  - Cada componente del vector \(\mathbf{x} \in \mathbb{R}^{30}\)
    representa una caracter√≠stica del tumor.

- *Capas ocultas*:
  - Primer capa oculta: 30 neuronas.
  - Segunda capa oculta: 15 neuronas.
  - Se especifican con el par√°metro:
    #+begin_src python
hidden_layer_sizes = (30, 15)
    #+end_src

  Cada neurona en una capa oculta:
  - recibe como entrada la salida de todas las neuronas de la capa
    anterior (capas densas),
  - aplica una transformaci√≥n lineal seguida de una funci√≥n de
    activaci√≥n no lineal.

- *Capa de salida*:
  - Para clasificaci√≥n binaria, internamente el MLP de scikit-learn
    puede usar:
    - 1 neurona con activaci√≥n log√≠stica (sigmoide),
    - o una representaci√≥n equivalente a 2 clases.
  - La salida se interpreta como una probabilidad de pertenecer a la
    clase ‚Äú1‚Äù (benigno).

*** Funci√≥n de activaci√≥n ReLU

El par√°metro:

#+begin_src python
activation = 'relu'
#+end_src

indica el uso de la funci√≥n *ReLU (Rectified Linear Unit)* en las capas
ocultas:

#+begin_latex
\text{ReLU}(z) = \max(0, z)
#+end_latex

Ventajas de ReLU:

- Introduce no linealidad (permite aproximar funciones no lineales).
- Reduce el problema del *vanishing gradient* en comparaci√≥n con
  funciones como sigmoide o tanh.
- Es simple y eficiente de calcular.

*** Optimizador Adam

El par√°metro:

#+begin_src python
solver = 'adam'
#+end_src

selecciona el optimizador *Adam* (Adaptive Moment Estimation), que:

- combina ideas de Momentum y RMSProp,
- mantiene promedios m√≥viles de:
  - los gradientes,
  - los gradientes al cuadrado,
- adapta la tasa de aprendizaje para cada par√°metro.

Esto suele producir:

- convergencia r√°pida,
- estabilidad num√©rica,
- buen desempe√±o sin necesidad de mucha sinton√≠a manual.

*** N√∫mero m√°ximo de iteraciones

#+begin_src python
max_iter = 1000
#+end_src

- Indica el n√∫mero m√°ximo de √©pocas (o iteraciones sobre los datos)
  para entrenar la red.
- Un valor alto permite que el modelo converja, aunque si es excesivo
  puede aumentar el riesgo de *overfitting* (la red se ajusta demasiado
  al entrenamiento).

*** Reproducibilidad

#+begin_src python
random_state = 42
#+end_src

- Fija la semilla para la inicializaci√≥n de pesos y el muestreo interno.
- Permite reproducir exactamente los mismos resultados entre ejecuciones.

** Entrenamiento del modelo

Entrenamos el MLP ajustando pesos y sesgos para minimizar el error de
clasificaci√≥n en el conjunto de entrenamiento:

#+begin_src python
mlp.fit(X_train, y_train)
#+end_src

*** Proceso interno (visi√≥n conceptual)

1. *Propagaci√≥n hacia adelante*:
   - Cada muestra \(\mathbf{x}\) pasa por las capas:
     \[
       \mathbf{h}^{(1)} = f_1(W^{(1)} \mathbf{x} + \mathbf{b}^{(1)})
     \]
     \[
       \mathbf{h}^{(2)} = f_2(W^{(2)} \mathbf{h}^{(1)} + \mathbf{b}^{(2)})
     \]
     \[
       \hat{y} = \sigma(W^{(3)} \mathbf{h}^{(2)} + \mathbf{b}^{(3)})
     \]
   - \(\hat{y}\) es la probabilidad estimada de que el tumor sea benigno
     (clase 1).

2. *C√°lculo del error*:
   - La salida \(\hat{y}\) se compara con la etiqueta real \(y \in \{0, 1\}\).
   - En problemas binarios, se usa t√≠picamente la *entrop√≠a cruzada
     binaria* (o log-loss):
     \[
       L(y, \hat{y}) = -\left[y \log(\hat{y}) + (1 - y)\log(1 - \hat{y})\right]
     \]

3. *Backpropagation*:
   - Se calculan las derivadas parciales de la p√©rdida con respecto a
     todos los pesos y sesgos mediante la regla de la cadena.
   - Se propaga el error desde la capa de salida hacia las capas
     ocultas.

4. *Actualizaci√≥n de pesos*:
   - El optimizador Adam actualiza cada par√°metro en la direcci√≥n que
     reduce la p√©rdida:
     \[
       \theta \leftarrow \theta - \eta \cdot \hat{g}
     \]
     donde \(\hat{g}\) es una versi√≥n adaptada del gradiente, y
     \(\eta\) la tasa de aprendizaje efectiva.

** Evaluaci√≥n del modelo

Una vez entrenado, evaluamos el modelo sobre el conjunto de prueba:

#+begin_src python
# Predicci√≥n
y_pred = mlp.predict(X_test)

# M√©tricas
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificaci√≥n:\n")
print(classification_report(y_test, y_pred, target_names=data.target_names))
#+end_src

*** M√©tricas principales

- *Accuracy*:
  - Proporci√≥n de predicciones correctas:
    \[
      \text{Accuracy} = \frac{\text{n√∫mero de aciertos}}{\text{n√∫mero total de muestras}}
    \]
- *Precision*:
  - De todos los ejemplos predichos como positivos, qu√© fracci√≥n son
    realmente positivos.
  - Importante para evitar falsos positivos.

- *Recall (Sensibilidad)*:
  - De todos los ejemplos realmente positivos, qu√© fracci√≥n se detecta
    correctamente.
  - En diagn√≥stico m√©dico, el recall para la clase ‚Äúmaligno‚Äù es cr√≠tico
    (minimizar falsos negativos).

- *F1-score*:
  - Media arm√≥nica de precision y recall:
    \[
      F1 = 2 \cdot \frac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}
    \]
  - √ötil cuando hay cierto desbalance entre clases.

El dataset Breast Cancer suele producir *accuracy* muy altas (por
encima de 95 %) con modelos bien entrenados, debido a que las
caracter√≠sticas est√°n relativamente bien separadas.

** Interpretaci√≥n matem√°tica de la salida binaria

En este modelo binario, la capa de salida puede verse como una neurona
con activaci√≥n *sigmoide (log√≠stica)*:

#+begin_latex
\sigma(z) = \frac{1}{1 + e^{-z}}
#+end_latex

donde:

- \(z = \mathbf{w} \cdot \mathbf{h} + b\),
- \(\mathbf{h}\) es el vector de activaciones de la √∫ltima capa oculta.

La salida \(\sigma(z)\) se interpreta como:

- \(\sigma(z) \approx 1\): alta probabilidad de clase 1 (benigno),
- \(\sigma(z) \approx 0\): alta probabilidad de clase 0 (maligno).

En scikit-learn, la predicci√≥n de clase se realiza t√≠picamente como:

- Si \(\sigma(z) \geq 0.5\) ‚Üí clase 1 (benigno).
- Si \(\sigma(z) < 0.5\) ‚Üí clase 0 (maligno).

Este umbral puede modificarse en contextos m√©dicos, por ejemplo:

- usar un umbral menor que 0.5 para aumentar la sensibilidad a tumores
  malignos (aceptando m√°s falsos positivos).

** Predicci√≥n de una nueva muestra

Podemos usar el modelo entrenado para predecir el diagn√≥stico de un
nuevo paciente.

En este ejemplo, tomamos la primera muestra del set de prueba (ya
normalizada) y realizamos la predicci√≥n:

#+begin_src python
# Ejemplo con la primera fila del set de prueba
nuevo_paciente = X_test[0:1]     # forma (1, 30)
pred = mlp.predict(nuevo_paciente)
print("Resultado del diagn√≥stico:", data.target_names[pred[0]])
#+end_src

*** Comentarios importantes

- Es fundamental que la nueva muestra haya sido procesada con el mismo:

  1. Conjunto de caracter√≠sticas (mismas columnas y orden).
  2. Mismo procedimiento de normalizaci√≥n (mismo =scaler=, con las
     medias y desviaciones aprendidas en el entrenamiento).

- En la pr√°ctica, se suele:

  - guardar el modelo entrenado (por ejemplo con =joblib=),
  - guardar tambi√©n el objeto =StandardScaler=,
  - aplicar ambos de manera coherente a los nuevos datos.

** Resumen conceptual

Este ejemplo ilustra varios conceptos clave en el uso de redes
neuronales (MLP) para clasificaci√≥n binaria en un contexto m√©dico:

- Importancia de:
  - Partici√≥n entrenamiento/prueba estratificada.
  - Normalizaci√≥n de caracter√≠sticas.
  - Arquitectura de red (capas y neuronas).
  - Funci√≥n de activaci√≥n (ReLU).
  - Optimizador (Adam) y n√∫mero de iteraciones.

- Interpretaci√≥n de la salida:
  - Probabilidad generada por una funci√≥n sigmoide.
  - Decisi√≥n de clase basada en un umbral.

- Evaluaci√≥n:
  - No basta con accuracy: hay que considerar precision, recall y F1,
    especialmente para la clase de inter√©s (por ejemplo, ‚Äúmaligno‚Äù).

Este mismo flujo (carga, partici√≥n, normalizaci√≥n, definici√≥n de modelo,
entrenamiento, evaluaci√≥n, predicci√≥n) puede adaptarse a otros modelos
(√°rboles, SVM, LSTM, etc.) y a otros datasets de clasificaci√≥n binaria
o multiclase.


* Juego de Bala y Salto con MLP

** Introducci√≥n
*** ¬øQu√© es este juego?

Este es un juego que combina mec√°nicas de juego simples con
aprendizaje autom√°tico (Machine Learning). El objetivo es entrenar una
red neuronal (MLP - Multi-Layer Perceptron) para que aprenda a jugar
imitando tu estilo de juego.

*** Concepto principal

- T√∫ juegas en modo MANUAL y el juego registra tus decisiones.
- El modelo MLP aprende de tus patrones de juego.
- En modo AUTO, el MLP juega por ti usando lo que aprendi√≥.

*** Objetivo del juego

Esquivar las balas que vienen desde la derecha saltando en el momento adecuado. El MLP aprende cu√°ndo saltar bas√°ndose en:
- La velocidad de la bala
- La distancia entre el jugador y la bala

** Requisitos e Instalaci√≥n
*** Dependencias necesarias

El juego requiere las siguientes librer√≠as de Python:

#+BEGIN_SRC python
pygame >= 2.6.0
scikit-learn >= 1.0.0
matplotlib >= 3.5.0
numpy >= 1.21.0
#+END_SRC

*** Instalaci√≥n

#+BEGIN_SRC bash
pip install pygame scikit-learn matplotlib numpy
#+END_SRC

*** Estructura de archivos

El proyecto contiene:

- =juego_pygame_mlp.py= :: Juego principal con MLP
- =juego_pygame_mlp_plot.py= :: Script para visualizar datos del CSV
- =datos_mlp.csv= :: Datos exportados (se genera al usar la opci√≥n C)
- =assets/= :: Carpeta con sprites y fondos del juego

** C√≥mo Jugar
*** Iniciar el juego

#+BEGIN_SRC bash
python juego_pygame_mlp.py
#+END_SRC

*** Men√∫ principal

Al iniciar ver√°s un men√∫ con las siguientes opciones:

| Tecla | Acci√≥n |
|-------+--------|
| M | Modo Manual (reinicia dataset y borra modelo) |
| A | Modo Auto (usa MLP; sin modelo NO salta) |
| T | Entrenar MLP |
| C | Exportar datos a CSV |
| F | Fullscreen (toggle) |
| Q | Salir |

*** Controles durante el juego

| Tecla | Acci√≥n |
|-------+--------|
| ESPACIO | Saltar (solo en modo manual) |
| ESC / P | Volver al men√∫ |
| F | Alternar pantalla completa |
| Q | Salir del juego |

** Modo Manual: Recolectando Datos
*** ¬øQu√© hace el modo manual?

En modo manual, t√∫ controlas al personaje y el juego registra autom√°ticamente:
- La velocidad de cada bala
- La distancia entre el jugador y la bala
- Si decidiste saltar (1) o no saltar (0) en cada frame

*** C√≥mo jugar en modo manual

1. Presiona =M= en el men√∫ para entrar en modo manual
2. El juego se reinicia y borra cualquier modelo anterior
3. Juega normalmente usando ESPACIO para saltar
4. El juego registra tus decisiones en cada frame donde hay una bala activa

*** Consejos para recolectar buenos datos

- Juega de forma natural, como lo har√≠as normalmente
- Mezcla situaciones: a veces salta temprano, a veces tarde, a veces no saltes
- Juega varias partidas para tener m√°s datos
- Intenta tener al menos 80+ muestras antes de entrenar (ver√°s el contador en el men√∫)

*** Registro de datos

El juego registra datos en cada frame donde:
- La bala est√° disparada
- El jugador est√° en el suelo (para decisiones de salto)
- O est√° en el aire (marcado como salto=1 durante todo el tiempo en el aire)

** Entrenamiento del Modelo MLP
*** ¬øQu√© es un MLP?

MLP (Multi-Layer Perceptron) es un tipo de red neuronal artificial que:
- Tiene capas ocultas entre la entrada y la salida
- Puede aprender patrones no lineales
- En este juego: aprende a predecir cu√°ndo saltar bas√°ndose en velocidad y distancia

*** Arquitectura del modelo

El MLP usado en este juego tiene:
- Entrada: 2 caracter√≠sticas (velocidad_bala, distancia)
- Capas ocultas: (24, 12) neuronas
- Salida: 1 neurona (probabilidad de salto: 0 o 1)
- Activaci√≥n: ReLU
- Optimizador: Adam

*** C√≥mo entrenar

1. Recolecta datos en modo manual (al menos 80 muestras)
2. Presiona =T= en el men√∫ para entrenar
3. El modelo se entrena autom√°ticamente:
   - Divide los datos en entrenamiento (80%) y prueba (20%)
   - Normaliza las caracter√≠sticas con StandardScaler
   - Entrena el MLP con hasta 3000 iteraciones
4. Ver√°s un mensaje con la precisi√≥n (accuracy) del modelo

*** Casos especiales

- Si tienes menos de 80 muestras: el entrenamiento fallar√° con un mensaje
- Si solo tienes una clase (solo 0s o solo 1s): se crea un "modelo trivial" que siempre devuelve esa clase
- Para un modelo √∫til: necesitas datos con ambas clases (0 y 1)

*** Interpretando los resultados

- Accuracy ‚âà 0.5-0.6: El modelo no est√° aprendiendo bien, necesitas m√°s datos variados
- Accuracy ‚âà 0.7-0.8: El modelo est√° aprendiendo, pero puede mejorar
- Accuracy ‚âà 0.8-0.9: Buen modelo, est√° capturando tus patrones
- Accuracy > 0.9: Excelente, el modelo imita muy bien tu estilo

** Modo Auto: El MLP Juega Solo
*** ¬øQu√© hace el modo auto?

En modo auto, el MLP toma las decisiones de salto bas√°ndose en lo que aprendi√≥ de ti.

*** C√≥mo activar modo auto

1. Primero debes entrenar un modelo (presiona =T=)
2. Luego presiona =A= en el men√∫
3. El juego se reinicia y el MLP controla los saltos

*** Visualizaci√≥n en tiempo real

Mientras juegas en modo auto, ver√°s en la esquina superior izquierda:
- =proba_salto‚âà0.XX= :: La probabilidad que el modelo calcula de que deber√≠a saltar

*** Limitaciones del modo auto

- Si no hay modelo entrenado, el modo auto no saltar√° nunca
- El modelo solo puede hacer lo que aprendi√≥ de tus datos
- Si tus datos son inconsistentes, el modelo tambi√©n lo ser√°

** Exportaci√≥n y Visualizaci√≥n de Datos
*** Exportar a CSV

1. En el men√∫, presiona =C=
2. Se crea/sobrescribe el archivo =datos_mlp.csv=
3. El CSV contiene tres columnas:
   - =velocidad_bala= :: Velocidad de la bala (negativa, en p√≠xeles/frame)
   - =distancia= :: Distancia entre jugador y bala (en p√≠xeles)
   - =salto= :: 1 si saltaste, 0 si no saltaste

*** Visualizar los datos

Para ver gr√°ficas de tus datos:

#+BEGIN_SRC bash
python juego_pygame_mlp_plot.py
#+END_SRC

Esto abre dos ventanas:
- Gr√°fica 2D: Distancia vs Velocidad (colores: rojo=salto, azul=no salto)
- Gr√°fica 3D: Distancia, Velocidad y Clase (0 abajo, 1 arriba)

*** Interpretando las gr√°ficas

- Si ves dos nubes bien separadas: tus datos son consistentes, el modelo deber√≠a aprender bien
- Si las nubes est√°n mezcladas: tus decisiones son m√°s variadas, el modelo puede tener m√°s dificultad
- Si solo ves una nube: solo tienes una clase, necesitas m√°s variedad en tus datos

** Arquitectura del C√≥digo
*** Estructura principal

El c√≥digo est√° organizado en una clase =Juego= con los siguientes m√≥dulos:

- =__init__= :: Inicializaci√≥n de pygame, ventana, estado del juego
- =_apply_resolution= :: Manejo de escalado y resoluci√≥n
- =_cargar_assets= :: Carga de sprites e im√°genes
- =_reset_estado_juego= :: Reinicia posiciones y estado
- =disparar_bala= / =reset_bala= :: L√≥gica de las balas
- =iniciar_salto= / =manejar_salto= :: F√≠sica del salto
- =registrar_decision_manual= :: Guarda datos mientras juegas
- =entrenar_modelo= :: Entrena el MLP con los datos recolectados
- =decision_auto_saltar= :: El MLP decide si saltar o no
- =mostrar_menu= :: Men√∫ principal
- =loop= :: Bucle principal del juego

*** Clase Sample

#+BEGIN_SRC python
@dataclass
class Sample:
    velocidad_bala: float
    distancia: float
    salto: int  # 1 si salt√≥ EN ESE FRAME, 0 si no
#+END_SRC

Cada muestra representa una decisi√≥n en un frame espec√≠fico.

*** Flujo de datos

1. Modo Manual:
   - Juegas ‚Üí =registrar_decision_manual()= ‚Üí =datos_modelo.append(Sample(...))=
   
2. Entrenamiento:
   - =datos_modelo= ‚Üí =entrenar_modelo()= ‚Üí MLP entrenado guardado en =self.modelo=
   
3. Modo Auto:
   - Cada frame ‚Üí =decision_auto_saltar()= ‚Üí MLP predice ‚Üí Salta o no salta

** Par√°metros Configurables
*** Par√°metros del juego

| Variable | Valor | Descripci√≥n |
|----------+-------+-------------|
| =BASE_W, BASE_H= | 1080, 720 | Tama√±o base de la ventana |
| =velocidad_bala= | -12 a -6 | Rango de velocidad de las balas |
| =salto_vel_inicial= | 15.0 | Velocidad inicial del salto |
| =gravedad= | 1.0 | Fuerza de gravedad |
| =fondo_speed= | 3 | Velocidad de desplazamiento del fondo |

*** Par√°metros del MLP

| Variable | Valor | Descripci√≥n |
|----------+-------+-------------|
| =hidden_layer_sizes= | (24, 12) | Neuronas en cada capa oculta |
| =activation= | "relu" | Funci√≥n de activaci√≥n |
| =solver= | "adam" | Algoritmo de optimizaci√≥n |
| =max_iter= | 3000 | M√°ximo de iteraciones de entrenamiento |
| =test_size= | 0.2 | 20% de los datos para prueba |

*** Par√°metros de registro

| Variable | Valor | Descripci√≥n |
|----------+-------+-------------|
| =decision_window= | 500 | Ventana de decisi√≥n (ya no se usa, registra todo) |
| =min_samples= | 80 | M√≠nimo de muestras para entrenar |

** Mejores Pr√°cticas
*** Recolectando datos de calidad

- Juega varias partidas (no solo una)
- Var√≠a tu estilo: a veces conservador, a veces agresivo
- Aseg√∫rate de tener ejemplos de ambas clases (saltos y no-saltos)
- Recolecta al menos 200-300 muestras para un modelo robusto

*** Entrenando el modelo

- Siempre revisa el accuracy: si es muy bajo (<0.6), recolecta m√°s datos
- Si el accuracy es perfecto (1.0), puede ser sobreajuste: prueba con m√°s datos de prueba
- Exporta el CSV y visualiza los datos para ver si hay patrones claros

*** Jugando en modo auto

- Observa la probabilidad en tiempo real (=proba_salto‚âàXX=)
- Si el modelo nunca salta o siempre salta, revisa tus datos
- Compara el comportamiento del modelo con c√≥mo t√∫ jugar√≠as

** Soluci√≥n de Problemas
*** El modelo no aprende (accuracy < 0.5)

- Posibles causas:
  - Datos insuficientes (< 80 muestras)
  - Solo una clase en los datos (solo 0s o solo 1s)
  - Datos muy inconsistentes o aleatorios
- Soluci√≥n:
  - Recolecta m√°s datos variados
  - Aseg√∫rate de tener ejemplos de ambas clases
  - Juega de forma m√°s consistente

*** El modo auto no salta nunca

- Verifica que el modelo est√© entrenado (=Modelo: s√≠= en el men√∫)
- Si el modelo es trivial de clase 0, siempre dir√° "no saltar"
- Soluci√≥n: recolecta datos donde s√≠ saltas y reentrena

*** El modo auto salta demasiado

- El modelo aprendi√≥ que siempre debes saltar
- Soluci√≥n: recolecta m√°s datos donde NO saltas y reentrena

*** Las gr√°ficas no se muestran

- Verifica que tengas =matplotlib= instalado
- Verifica que el CSV tenga datos v√°lidos
- Ejecuta =juego_pygame_mlp_plot.py= desde la terminal

*** El juego se ve lento o con lag

- Reduce los FPS en =reloj.tick(45)= a un valor menor (ej: 30)
- Cierra otras aplicaciones que consuman recursos
- Verifica que tu sistema tenga aceleraci√≥n gr√°fica habilitada

** Conceptos T√©cnicos Avanzados
*** ¬øPor qu√© MLP y no otro algoritmo?

- MLP puede aprender patrones no lineales (la relaci√≥n velocidad-distancia-salto no es lineal)
- Es relativamente simple y r√°pido de entrenar
- Funciona bien con pocas caracter√≠sticas (solo 2 en este caso)

*** Normalizaci√≥n (StandardScaler)

Las caracter√≠sticas se normalizan porque:
- La velocidad de la bala y la distancia tienen escalas muy diferentes
- El MLP funciona mejor con datos normalizados
- Ayuda a que el entrenamiento converja m√°s r√°pido

*** Divisi√≥n train/test

- 80% entrenamiento, 20% prueba
- Estratificado (=stratify=y=) para mantener proporci√≥n de clases
- El accuracy en test es m√°s confiable que en entrenamiento

*** Overfitting y Underfitting

- Overfitting: El modelo memoriza los datos de entrenamiento pero falla en nuevos datos
- Underfitting: El modelo no aprende lo suficiente
- En este juego: si accuracy test << accuracy train ‚Üí overfitting


**  C√≥digo de Ejemplo
*** Cargar y visualizar datos manualmente

#+BEGIN_SRC python
import csv
import matplotlib.pyplot as plt

# Cargar CSV
xs, ys, cs = [], [], []
with open("datos_mlp.csv", "r") as f:
    reader = csv.DictReader(f)
    for row in reader:
        xs.append(float(row["distancia"]))
        ys.append(float(row["velocidad_bala"]))
        cs.append(int(row["salto"]))

# Separar por clases
xs_0 = [x for x, c in zip(xs, cs) if c == 0]
ys_0 = [y for y, c in zip(ys, cs) if c == 0]
xs_1 = [x for x, c in zip(xs, cs) if c == 1]
ys_1 = [y for y, c in zip(ys, cs) if c == 1]

# Graficar
plt.scatter(xs_0, ys_0, c="blue", label="No salto")
plt.scatter(xs_1, ys_1, c="red", label="Salto")
plt.xlabel("Distancia")
plt.ylabel("Velocidad")
plt.legend()
plt.show()
#+END_SRC

*** Entrenar modelo desde CSV

#+BEGIN_SRC python
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
import csv

# Cargar datos
X, y = [], []
with open("datos_mlp.csv", "r") as f:
    reader = csv.DictReader(f)
    for row in reader:
        X.append([float(row["velocidad_bala"]), float(row["distancia"])])
        y.append(int(row["salto"]))

# Normalizar
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Entrenar
modelo = MLPClassifier(hidden_layer_sizes=(24, 12), max_iter=3000)
modelo.fit(X_scaled, y)

# Predecir
nueva_velocidad = -8.5
nueva_distancia = 250.0
X_nuevo = scaler.transform([[nueva_velocidad, nueva_distancia]])
probabilidad = modelo.predict_proba(X_nuevo)[0][1]
print(f"Probabilidad de salto: {probabilidad:.2f}")
#+END_SRC




* M√©tricas de Evaluaci√≥n para Machine Learning

** Introducci√≥n
*** ¬øQu√© son las m√©tricas de evaluaci√≥n?

Las m√©tricas de evaluaci√≥n son medidas num√©ricas que nos permiten cuantificar qu√© tan bien est√° funcionando un modelo de Machine Learning. Nos ayudan a:
- Comparar diferentes modelos
- Entender las fortalezas y debilidades del modelo
- Decidir si un modelo es √∫til para nuestro problema
- Detectar problemas como sobreajuste o sesgo

*** ¬øPor qu√© son importantes?

Un modelo puede tener un accuracy alto pero a√∫n as√≠ tener problemas graves. Por ejemplo:
- Un modelo que siempre predice "no salto" tendr√≠a 90% accuracy si el 90% de los casos son "no salto"
- Pero ser√≠a in√∫til porque nunca saltar√≠a cuando deber√≠a

Las m√©tricas nos ayudan a detectar estos problemas.

** Matriz de Confusi√≥n: La Base de Todo
*** ¬øQu√© es una matriz de confusi√≥n?

La matriz de confusi√≥n es una tabla que muestra c√≥mo se clasificaron las predicciones del modelo comparadas con los valores reales.

*** Estructura de la matriz (2 clases)

Para un problema de clasificaci√≥n binaria (como nuestro juego: salto=1, no salto=0):

#+BEGIN_EXAMPLE
                    Predicci√≥n
                 No Salto  Salto
Real  No Salto     TN      FP
      Salto        FN      TP
#+END_EXAMPLE

Donde:
- =TP= (True Positive): Predijo salto y era salto ‚úì
- =TN= (True Negative): Predijo no salto y era no salto ‚úì
- =FP= (False Positive): Predijo salto pero era no salto ‚úó
- =FN= (False Negative): Predijo no salto pero era salto ‚úó

*** Interpretaci√≥n en el contexto del juego

| Caso | Significado en el juego |
|------+--------------------------|
| TP | El modelo salt√≥ y era correcto hacerlo |
| TN | El modelo no salt√≥ y era correcto no saltar |
| FP | El modelo salt√≥ innecesariamente (gasto de salto) |
| FN | El modelo NO salt√≥ cuando deber√≠a haber saltado (¬°colisi√≥n!) |

*** Ejemplo pr√°ctico

Supongamos que el modelo hizo 100 predicciones:

#+BEGIN_EXAMPLE
                    Predicci√≥n
                 No Salto  Salto  Total
Real  No Salto      70      10     80
      Salto          5      15     20
      Total          75      25    100
#+END_EXAMPLE

- TP = 15 (salt√≥ correctamente 15 veces)
- TN = 70 (no salt√≥ correctamente 70 veces)
- FP = 10 (salt√≥ innecesariamente 10 veces)
- FN = 5 (no salt√≥ cuando deb√≠a 5 veces ‚Üí ¬°5 colisiones!)

** Accuracy (Precisi√≥n General)
*** Definici√≥n

Accuracy mide la proporci√≥n de predicciones correctas sobre el total:

\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} = \frac{\text{Predicciones correctas}}{\text{Total de predicciones}}
\]

*** C√°lculo del ejemplo anterior

\[
\text{Accuracy} = \frac{15 + 70}{100} = \frac{85}{100} = 0.85 = 85\%
\]

*** Ventajas

- F√°cil de entender: "¬øQu√© porcentaje acert√≥?"
- √ötil cuando las clases est√°n balanceadas
- Buena m√©trica general para comparar modelos

*** Desventajas

- Puede ser enga√±osa con clases desbalanceadas
- No distingue entre tipos de errores
- Un modelo que siempre predice la clase mayoritaria puede tener buen accuracy

*** Ejemplo del problema

Si en el juego el 90% de los casos son "no salto":
- Un modelo que siempre dice "no salto" tendr√≠a 90% accuracy
- Pero ser√≠a in√∫til porque nunca saltar√≠a
- Accuracy alto ‚â† modelo bueno

*** Cu√°ndo usar Accuracy

- Clases balanceadas (50-50 o similar)
- Todos los errores tienen el mismo costo
- Quieres una m√©trica simple y general

** Precision (Precisi√≥n)
*** Definici√≥n

Precision mide: "De todas las veces que predije salto, ¬øcu√°ntas eran correctas?"

\[
\text{Precision} = \frac{TP}{TP + FP} = \frac{\text{Verdaderos positivos}}{\text{Todos los positivos predichos}}
\]

*** C√°lculo del ejemplo

\[
\text{Precision} = \frac{15}{15 + 10} = \frac{15}{25} = 0.60 = 60\%
\]

*** Interpretaci√≥n

- De las 25 veces que el modelo decidi√≥ saltar, solo 15 eran correctas
- 10 veces salt√≥ innecesariamente (FP)
- "Cuando el modelo dice que hay que saltar, ¬øqu√© tan confiable es?"

*** En el contexto del juego

- Precision alta: Cuando el modelo decide saltar, casi siempre es correcto
- Precision baja: El modelo salta demasiado, muchas veces innecesariamente
- Costo: Saltos innecesarios no son cr√≠ticos, pero desperdician recursos

*** Cu√°ndo es importante

- Los falsos positivos son costosos
- Quieres minimizar acciones innecesarias
- Ejemplo: Sistema de spam (no quieres marcar emails leg√≠timos como spam)

** Recall (Sensibilidad o Exhaustividad)
*** Definici√≥n

Recall mide: "De todos los casos donde realmente deb√≠a saltar, ¬øcu√°ntos detect√©?"

\[
\text{Recall} = \frac{TP}{TP + FN} = \frac{\text{Verdaderos positivos}}{\text{Todos los positivos reales}}
\]

*** C√°lculo del ejemplo

\[
\text{Recall} = \frac{15}{15 + 5} = \frac{15}{20} = 0.75 = 75\%
\]

*** Interpretaci√≥n

- De las 20 veces que realmente deb√≠a saltar, el modelo detect√≥ 15
- 5 veces no salt√≥ cuando deb√≠a (FN) ‚Üí ¬°5 colisiones!
- "¬øQu√© porcentaje de las situaciones peligrosas detecta el modelo?"

*** En el contexto del juego

- Recall alto: El modelo detecta casi todas las situaciones donde debe saltar
- Recall bajo: El modelo se pierde muchas situaciones peligrosas ‚Üí muchas colisiones
- Costo: Falsos negativos son MUY costosos (colisiones = perder)

*** Cu√°ndo es cr√≠tico

- Los falsos negativos son muy costosos
- Es mejor "sobre-detectar" que "sub-detectar"
- Ejemplos: Detecci√≥n de c√°ncer, detecci√≥n de fraude, nuestro juego

*** Trade-off Precision vs Recall

Generalmente hay un trade-off:
- Si aumentas el umbral de decisi√≥n ‚Üí m√°s Precision, menos Recall
- Si disminuyes el umbral ‚Üí m√°s Recall, menos Precision

En el juego:
- Umbral alto (0.7): Solo salta cuando est√° muy seguro ‚Üí alta Precision, bajo Recall
- Umbral bajo (0.3): Salta con m√°s frecuencia ‚Üí bajo Precision, alto Recall

** F1-Score: El Balance Perfecto
*** Definici√≥n

F1-Score es la media arm√≥nica de Precision y Recall:

\[
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = \frac{2 \times TP}{2 \times TP + FP + FN}
\]

*** C√°lculo del ejemplo

\[
F1 = 2 \times \frac{0.60 \times 0.75}{0.60 + 0.75} = 2 \times \frac{0.45}{1.35} = 0.667 = 66.7\%
\]

*** ¬øPor qu√© media arm√≥nica y no aritm√©tica?

La media arm√≥nica penaliza m√°s cuando una m√©trica es muy baja:
- Si Precision = 0.1 y Recall = 0.9 ‚Üí F1 = 0.18 (bajo)
- Si Precision = 0.5 y Recall = 0.5 ‚Üí F1 = 0.5 (mejor balance)

*** Ventajas

- Balancea Precision y Recall
- √ötil cuando necesitas ambas m√©tricas
- No se ve afectado por clases desbalanceadas tanto como Accuracy

*** Desventajas

- Puede ocultar problemas si una m√©trica es muy baja
- No siempre es la m√©trica m√°s importante

*** Cu√°ndo usar F1-Score

- Necesitas balance entre Precision y Recall
- Las clases est√°n desbalanceadas
- Quieres una m√©trica √∫nica que considere ambos aspectos

** Especificidad
*** Definici√≥n

Especificidad mide: "De todos los casos donde NO deb√≠a saltar, ¬øcu√°ntos detect√© correctamente?"

\[
\text{Especificidad} = \frac{TN}{TN + FP} = \frac{\text{Verdaderos negativos}}{\text{Todos los negativos reales}}
\]

*** C√°lculo del ejemplo

\[
\text{Especificidad} = \frac{70}{70 + 10} = \frac{70}{80} = 0.875 = 87.5\%
\]

*** Interpretaci√≥n

- De las 80 veces que NO deb√≠a saltar, el modelo acert√≥ 70
- 10 veces salt√≥ innecesariamente
- Es el "Recall de la clase negativa"

*** En el contexto del juego

- Especificidad alta: El modelo rara vez salta innecesariamente
- Especificidad baja: El modelo salta demasiado cuando no es necesario

** Comparaci√≥n de M√©tricas: Tabla Resumen
*** Valores del ejemplo

| M√©trica | Valor | Interpretaci√≥n |
|---------+-------+----------------|
| Accuracy | 85% | 85 de cada 100 predicciones fueron correctas |
| Precision | 60% | De cada 10 saltos predichos, 6 eran correctos |
| Recall | 75% | De cada 10 situaciones peligrosas, detect√≥ 7.5 |
| F1-Score | 66.7% | Balance entre Precision y Recall |
| Especificidad | 87.5% | De cada 10 casos seguros, detect√≥ 8.75 correctamente |

*** ¬øQu√© m√©trica usar?

| Situaci√≥n | M√©trica recomendada |
|-----------+---------------------|
| Clases balanceadas, errores igual costo | Accuracy |
| Falsos positivos muy costosos | Precision |
| Falsos negativos muy costosos | Recall |
| Necesitas balance Precision/Recall | F1-Score |
| Clases muy desbalanceadas | F1-Score o Recall |
| Quieres ver todo el panorama | Matriz de confusi√≥n + todas |

** Casos de Uso en el Juego
*** Escenario 1: Modelo Conservador

Un modelo que casi nunca salta:

#+BEGIN_EXAMPLE
                    Predicci√≥n
                 No Salto  Salto
Real  No Salto      75       5
      Salto         15       5
#+END_EXAMPLE

- Accuracy: 80% (80/100)
- Precision: 50% (5/10) - Cuando salta, acierta la mitad
- Recall: 25% (5/20) - Solo detecta 1 de cada 4 peligros ‚Üí ¬°MUCHAS COLISIONES!
- F1: 33.3%

**Veredicto**: Mal modelo para el juego. Aunque tiene buen accuracy, tiene muy bajo Recall ‚Üí muchas colisiones.

*** Escenario 2: Modelo Agresivo

Un modelo que salta muy frecuentemente:

#+BEGIN_EXAMPLE
                    Predicci√≥n
                 No Salto  Salto
Real  No Salto      50      30
      Salto           2      18
#+END_EXAMPLE

- Accuracy: 68% (68/100)
- Precision: 37.5% (18/48) - Muchos saltos innecesarios
- Recall: 90% (18/20) - Detecta casi todos los peligros
- F1: 53.3%

**Veredicto**: Mejor que el conservador. Aunque tiene muchos saltos innecesarios, evita casi todas las colisiones.

*** Escenario 3: Modelo Balanceado (Ideal)

Un modelo bien entrenado:

#+BEGIN_EXAMPLE
                    Predicci√≥n
                 No Salto  Salto
Real  No Salto      70      10
      Salto           3      17
#+END_EXAMPLE

- Accuracy: 87% (87/100)
- Precision: 63% (17/27)
- Recall: 85% (17/20) - Detecta la mayor√≠a de peligros
- F1: 72.3%

**Veredicto**: Buen modelo. Balance entre evitar colisiones y no saltar innecesariamente.

** Implementaci√≥n en Python
*** C√°lculo manual de m√©tricas

#+BEGIN_SRC python
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# Ejemplo con predicciones y valores reales
y_real = [0, 0, 0, 1, 1, 1, 0, 1, 0, 1]
y_pred = [0, 0, 1, 1, 1, 0, 0, 1, 0, 1]

# Matriz de confusi√≥n
cm = confusion_matrix(y_real, y_pred)
print("Matriz de confusi√≥n:")
print(cm)
# [[4 1]   # TN=4, FP=1
#  [1 4]]  # FN=1, TP=4

# M√©tricas
accuracy = accuracy_score(y_real, y_pred)
precision = precision_score(y_real, y_pred)
recall = recall_score(y_real, y_pred)
f1 = f1_score(y_real, y_pred)

print(f"Accuracy: {accuracy:.2%}")
print(f"Precision: {precision:.2%}")
print(f"Recall: {recall:.2%}")
print(f"F1-Score: {f1:.2%}")
#+END_SRC

*** Reporte completo de clasificaci√≥n

#+BEGIN_SRC python
from sklearn.metrics import classification_report

y_real = [0, 0, 0, 1, 1, 1, 0, 1, 0, 1]
y_pred = [0, 0, 1, 1, 1, 0, 0, 1, 0, 1]

report = classification_report(y_real, y_pred, target_names=['No Salto', 'Salto'])
print(report)
#+END_SRC

Salida esperada:
#+BEGIN_EXAMPLE
              precision    recall  f1-score   support

    No Salto       0.80      0.80      0.80         5
       Salto       0.80      0.80      0.80         5

    accuracy                           0.80        10
   macro avg       0.80      0.80      0.80        10
weighted avg       0.80      0.80      0.80        10
#+END_EXAMPLE

*** Visualizaci√≥n de la matriz de confusi√≥n

#+BEGIN_SRC python
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

y_real = [0, 0, 0, 1, 1, 1, 0, 1, 0, 1]
y_pred = [0, 0, 1, 1, 1, 0, 0, 1, 0, 1]

cm = confusion_matrix(y_real, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['No Salto', 'Salto'],
            yticklabels=['No Salto', 'Salto'])
plt.ylabel('Real')
plt.xlabel('Predicci√≥n')
plt.title('Matriz de Confusi√≥n')
plt.show()
#+END_SRC

** Mejorando el Juego con M√©tricas
*** A√±adir m√©tricas al entrenamiento

Podemos modificar =entrenar_modelo()= para mostrar m√°s m√©tricas:

#+BEGIN_SRC python
from sklearn.metrics import classification_report, confusion_matrix

def entrenar_modelo_mejorado(self) -> Tuple[bool, str]:
    # ... c√≥digo de entrenamiento existente ...
    
    # Predicciones en el conjunto de prueba
    y_pred = clf.predict(X_test)
    
    # Matriz de confusi√≥n
    cm = confusion_matrix(y_test, y_pred)
    print("\nMatriz de Confusi√≥n:")
    print(cm)
    
    # Reporte completo
    report = classification_report(y_test, y_pred, 
                                   target_names=['No Salto', 'Salto'])
    print("\nReporte de Clasificaci√≥n:")
    print(report)
    
    # M√©tricas individuales
    from sklearn.metrics import precision_score, recall_score, f1_score
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    return True, (f"MLP entrenado. Accuracy: {acc:.3f}, "
                  f"Precision: {precision:.3f}, "
                  f"Recall: {recall:.3f}, "
                  f"F1: {f1:.3f}")
#+END_SRC

*** Interpretar resultados en el juego

Si el modelo tiene:
- Recall bajo (< 0.6): Muchas colisiones ‚Üí recolecta m√°s datos donde saltas
- Precision bajo (< 0.5): Muchos saltos innecesarios ‚Üí recolecta m√°s datos donde NO saltas
- F1 bajo (< 0.6): El modelo no est√° aprendiendo bien ‚Üí m√°s datos variados

** Curvas ROC y AUC
*** ¬øQu√© es la curva ROC?

ROC (Receiver Operating Characteristic) muestra el trade-off entre:
- Tasa de Verdaderos Positivos (Recall/TPR) en el eje Y
- Tasa de Falsos Positivos (FPR = FP/(FP+TN)) en el eje X

*** ¬øQu√© es AUC?

AUC (Area Under Curve) es el √°rea bajo la curva ROC:
- AUC = 1.0: Clasificador perfecto
- AUC = 0.5: Clasificador aleatorio (no mejor que adivinar)
- AUC > 0.7: Buen clasificador
- AUC > 0.9: Excelente clasificador

*** C√≥digo para generar curva ROC

#+BEGIN_SRC python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Obtener probabilidades (no solo predicciones)
y_proba = modelo.predict_proba(X_test)[:, 1]

# Calcular curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
auc = roc_auc_score(y_test, y_proba)

# Graficar
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.grid(True)
plt.show()
#+END_SRC

*** Interpretaci√≥n

- Curva cerca de la esquina superior izquierda ‚Üí mejor modelo
- AUC alto ‚Üí modelo puede distinguir bien entre clases
- √ötil para comparar diferentes modelos o umbrales

** M√©tricas para Clases Desbalanceadas
*** El problema

Cuando una clase es mucho m√°s frecuente que la otra:
- Accuracy puede ser enga√±oso
- Un modelo que siempre predice la clase mayoritaria puede tener buen accuracy

*** Soluciones

1. **F1-Score**: Ya lo vimos, balancea Precision y Recall

2. **Precision-Recall Curve**: Similar a ROC pero mejor para clases desbalanceadas

#+BEGIN_SRC python
from sklearn.metrics import precision_recall_curve, auc

precision_vals, recall_vals, thresholds = precision_recall_curve(y_test, y_proba)
pr_auc = auc(recall_vals, precision_vals)

plt.plot(recall_vals, precision_vals)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title(f'Precision-Recall Curve (AUC = {pr_auc:.2f})')
plt.show()
#+END_SRC

3. **Matthews Correlation Coefficient (MCC)**:

\[
MCC = \frac{TP \times TN - FP \times FN}{\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}
\]

- Rango: -1 a +1
- +1: Predicci√≥n perfecta
- 0: Predicci√≥n aleatoria
- -1: Predicci√≥n inversa perfecta
- √ötil para clases desbalanceadas

#+BEGIN_SRC python
from sklearn.metrics import matthews_corrcoef

mcc = matthews_corrcoef(y_test, y_pred)
print(f"MCC: {mcc:.3f}")
#+END_SRC

** Resumen: Gu√≠a R√°pida
*** Tabla de m√©tricas clave

| M√©trica | F√≥rmula | Rango | ¬øQu√© mide? |
|---------+---------+-------+------------|
| Accuracy | (TP+TN)/(TP+TN+FP+FN) | 0-1 | Proporci√≥n de aciertos totales |
| Precision | TP/(TP+FP) | 0-1 | Confiabilidad de predicciones positivas |
| Recall | TP/(TP+FN) | 0-1 | Detecci√≥n de casos positivos reales |
| F1-Score | 2√ó(P√óR)/(P+R) | 0-1 | Balance Precision/Recall |
| Especificidad | TN/(TN+FP) | 0-1 | Detecci√≥n de casos negativos reales |
| AUC-ROC | √Årea bajo curva ROC | 0-1 | Capacidad de distinguir clases |
| MCC | (TP√óTN-FP√óFN)/‚àö(...) | -1 a +1 | Correlaci√≥n general (balanceada) |

*** Decisi√≥n r√°pida: ¬øQu√© m√©trica usar?

#+BEGIN_EXAMPLE
¬øLas clases est√°n balanceadas?
‚îú‚îÄ S√ç ‚Üí Accuracy es √∫til
‚îî‚îÄ NO ‚Üí Usa F1-Score o MCC

¬øLos falsos negativos son cr√≠ticos?
‚îú‚îÄ S√ç ‚Üí Recall es la m√°s importante
‚îî‚îÄ NO ‚Üí Precision puede ser m√°s importante

¬øNecesitas una m√©trica √∫nica?
‚îú‚îÄ S√ç ‚Üí F1-Score o MCC
‚îî‚îÄ NO ‚Üí Revisa Precision, Recall y Accuracy juntas
#+END_EXAMPLE

*** Checklist de evaluaci√≥n

Antes de aceptar un modelo, verifica:

- [ ] Accuracy > umbral m√≠nimo (ej: 0.7)
- [ ] Recall > umbral m√≠nimo (ej: 0.7) - especialmente si FN son cr√≠ticos
- [ ] Precision > umbral m√≠nimo (ej: 0.6) - si FP son costosos
- [ ] F1-Score muestra buen balance
- [ ] Matriz de confusi√≥n no muestra patrones extra√±os
- [ ] M√©tricas en test son similares a entrenamiento (no overfitting)

** Ejercicios Pr√°cticos
*** Ejercicio 1: Calcular m√©tricas manualmente

Dada esta matriz de confusi√≥n:

#+BEGIN_EXAMPLE
                    Predicci√≥n
                 No Salto  Salto
Real  No Salto      60      20
      Salto         10      10
#+END_EXAMPLE

Calcula:
- TP, TN, FP, FN
- Accuracy
- Precision
- Recall
- F1-Score
- Especificidad

**Soluci√≥n**:
- TP = 10, TN = 60, FP = 20, FN = 10
- Accuracy = 70/100 = 0.70
- Precision = 10/30 = 0.33
- Recall = 10/20 = 0.50
- F1 = 2√ó(0.33√ó0.50)/(0.33+0.50) = 0.40
- Especificidad = 60/80 = 0.75

*** Ejercicio 2: Interpretar resultados

Un modelo tiene:
- Accuracy: 85%
- Precision: 40%
- Recall: 90%

¬øEs un buen modelo para el juego? ¬øPor qu√©?

**Soluci√≥n**: 
- Recall alto (90%) es bueno ‚Üí detecta casi todos los peligros
- Precision bajo (40%) ‚Üí muchos saltos innecesarios
- Para el juego: Es aceptable porque evitar colisiones (Recall) es m√°s importante que saltos innecesarios (Precision)

*** Ejercicio 3: Mejorar un modelo

Un modelo tiene Recall = 0.5. ¬øQu√© puedes hacer para mejorarlo?

**Soluci√≥n**:
- Recolectar m√°s datos donde realmente debes saltar
- Disminuir el umbral de decisi√≥n (de 0.5 a 0.3, por ejemplo)
- Ajustar hiperpar√°metros del MLP
- A√±adir m√°s caracter√≠sticas al modelo

** Referencias y Recursos
*** Documentaci√≥n oficial

- scikit-learn metrics: https://scikit-learn.org/stable/modules/model_evaluation.html
- Confusion matrix: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html

*** Lecturas recomendadas

- "Hands-On Machine Learning" - Aur√©lien G√©ron (Cap√≠tulo sobre evaluaci√≥n)
- "Pattern Recognition and Machine Learning" - Christopher Bishop
- "The Elements of Statistical Learning" - Hastie, Tibshirani, Friedman

*** Herramientas √∫tiles

- scikit-learn: M√©tricas implementadas
- Yellowbrick: Visualizaciones de m√©tricas
- Weka: Suite completa de ML con evaluaci√≥n

** Conclusi√≥n

Las m√©tricas de evaluaci√≥n son esenciales para entender y mejorar modelos de Machine Learning. No hay una m√©trica "perfecta" - la elecci√≥n depende de:
- Tu problema espec√≠fico
- El costo de diferentes tipos de errores
- El balance de clases
- Tus objetivos

Para el juego de salto:
- **Recall es cr√≠tico** (evitar colisiones)
- **Precision es importante** (no saltar innecesariamente)
- **F1-Score** da un buen balance general
- **Accuracy** puede ser enga√±oso si las clases est√°n desbalanceadas

Recuerda: Un modelo con 90% accuracy puede ser in√∫til si tiene 10% Recall (muchas colisiones). Siempre revisa m√∫ltiples m√©tricas.


* Redes Neuronales LSTM (Long Short-Term Memory)

Las redes neuronales LSTM (*Long Short-Term Memory*) son un tipo especial
de **Red Neuronal Recurrente (RNN)** dise√±ada para trabajar con datos
**secuenciales** y, en particular, para **recordar dependencias a largo
plazo**.

Se utilizan cuando el *orden* de los datos importa:

- Texto (oraciones, p√°rrafos, documentos).
- Series temporales (precios, temperatura, se√±ales).
- Audio y voz.
- Secuencias de eventos (logs, clics, acciones de usuario, etc.).

Su principal aporte es resolver (o al menos mitigar fuertemente) el
problema del **desvanecimiento del gradiente (vanishing gradient)** que
afecta a las RNN simples cuando manejan secuencias largas.

** Estructura general de una RNN

En una RNN ‚Äúsimple‚Äù, en cada paso temporal \(t\):

- Se recibe una entrada \(x_t\).
- Se tiene un estado oculto anterior \(h_{t-1}\).
- Se actualiza el estado oculto actual \(h_t\) con:

#+begin_latex
h_t = \phi(W_{xh} x_t + W_{hh} h_{t-1} + b_h)
#+end_latex

donde:

- \(W_{xh}\) y \(W_{hh}\) son matrices de pesos,
- \(b_h\) es el sesgo,
- \(\phi\) es una funci√≥n de activaci√≥n (t√≠picamente =tanh= o =ReLU=).

El estado final (o todos los estados) se usan para hacer predicciones.

*** Problema: vanishing y exploding gradients

Durante el entrenamiento, se aplica *Backpropagation Through Time (BPTT)*,
es decir, se retropropagan los gradientes a trav√©s de todos los pasos
temporales.

En secuencias largas:

- Los gradientes pueden volverse **muy peque√±os** ‚Üí la red ‚Äúolvida‚Äù las
  dependencias lejanas (problema de *vanishing gradient*).
- O volverse **muy grandes** ‚Üí inestabilidad num√©rica (problema de
  *exploding gradient*).

Consecuencia: las RNN simples tienen dificultades para **aprender
relaciones de largo plazo**, por ejemplo, la dependencia entre una
palabra al principio de una oraci√≥n y otra al final.

** Motivaci√≥n de las LSTM

Las LSTM fueron propuestas para permitir que la red:

- **Mantenga informaci√≥n relevante durante muchos pasos temporales**.
- **Controle qu√© recordar y qu√© olvidar**.
- Facilite el flujo de gradiente a trav√©s del tiempo, reduciendo el
  problema del desvanecimiento.

La idea principal es introducir una **celda de memoria** y un sistema de
**puertas (gates)** que regulan el flujo de informaci√≥n.

** Arquitectura interna de una celda LSTM

En lugar de solo tener el estado oculto \(h_t\), la LSTM mantiene:

- un **estado de memoria** \(c_t\) (a veces llamado *cell state*),
- un **estado oculto** \(h_t\) (la ‚Äúsalida‚Äù en ese paso).

En cada paso temporal \(t\), la LSTM procesa:

- la entrada actual \(x_t\),
- el estado oculto anterior \(h_{t-1}\),
- el estado de memoria anterior \(c_{t-1}\).

Y calcula:

- una *puerta de olvido* \(f_t\),
- una *puerta de entrada* \(i_t\),
- una *candidata de memoria* \(\tilde{c}_t\),
- una *puerta de salida* \(o_t\),
- el nuevo estado de memoria \(c_t\),
- el nuevo estado oculto \(h_t\).

*** Ecuaciones de la LSTM

T√≠picamente, las ecuaciones de una LSTM (versi√≥n ‚Äúest√°ndar‚Äù) son:

#+begin_latex
\begin{aligned}
f_t &= \sigma(W_f [h_{t-1}, x_t] + b_f) \\
i_t &= \sigma(W_i [h_{t-1}, x_t] + b_i) \\
\tilde{c}_t &= \tanh(W_c [h_{t-1}, x_t] + b_c) \\
c_t &= f_t \odot c_{t-1} + i_t \odot \tilde{c}_t \\
o_t &= \sigma(W_o [h_{t-1}, x_t] + b_o) \\
h_t &= o_t \odot \tanh(c_t)
\end{aligned}
#+end_latex

donde:

- \(\sigma\) es la funci√≥n sigmoide,
- \(\tanh\) es la tangente hiperb√≥lica,
- \(\odot\) es el producto elemento a elemento,
- \([h_{t-1}, x_t]\) indica la concatenaci√≥n de vectores.

*** Interpretaci√≥n de las puertas

- \(f_t\) (*forget gate* o puerta de olvido):  
  - Toma valores en \([0,1]\) (por la sigmoide).
  - Decide cu√°nto de la memoria anterior \(c_{t-1}\) se conserva.
  - Si \(f_t \approx 1\) ‚Üí se mantiene casi toda la memoria anterior.
  - Si \(f_t \approx 0\) ‚Üí se olvida casi todo.

- \(i_t\) (*input gate* o puerta de entrada):  
  - Controla cu√°nta de la nueva informaci√≥n candidata \(\tilde{c}_t\) se
    incorpora a la memoria.
  - Valores cercanos a 1 permiten ‚Äúescribir‚Äù nueva informaci√≥n; valores
    cercanos a 0 bloquean escritura.

- \(\tilde{c}_t\) (candidata de memoria):  
  - Es el nuevo contenido potencial para la memoria.
  - Se combina con \(i_t\) para actualizar \(c_t\).

- \(c_t\) (*cell state*):  
  - Es la memoria principal de la LSTM.
  - Se actualiza como:
    \[
      c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c}_t
    \]
  - Puede transportar informaci√≥n durante muchos pasos, ya que el
    gradiente puede fluir a lo largo de \(c_t\) con menos atenuaci√≥n.

- \(o_t\) (*output gate* o puerta de salida):  
  - Controla qu√© parte de la memoria \(c_t\) se expone como salida \(h_t\).

- \(h_t\) (estado oculto / salida):  
  - Es la ‚Äúrepresentaci√≥n‚Äù que se usa para producir salidas en cada
    paso, o para alimentar capas posteriores.

** Intuici√≥n conceptual

Una forma intuitiva de entender una LSTM es verla como una **celda de
memoria con una ‚Äúllave de escritura‚Äù, una ‚Äúllave de borrado‚Äù y una
‚Äúllave de lectura‚Äù**:

- *Olvido*: la red decide qu√© partes de la memoria vieja ya no son
  relevantes y las borra parcialmente (puerta \(f_t\)).
- *Escritura*: la red decide qu√© nueva informaci√≥n vale la pena guardar
  (puerta \(i_t\) y candidata \(\tilde{c}_t\)).
- *Lectura*: la red decide qu√© parte de la memoria compartir como salida
  (puerta \(o_t\)).

Esto permite que la red conserve informaci√≥n importante durante muchos
pasos temporales, por ejemplo:

- el tema general de una oraci√≥n,
- la tendencia de una serie temporal,
- el contexto de una conversaci√≥n, etc.

** Entrenamiento de una LSTM

El entrenamiento de una LSTM sigue el mismo esquema general que otras
redes neuronales:

1. **Forward pass**:
   - La secuencia completa \((x_1, x_2, \dots, x_T)\) se ingresa paso a
     paso.
   - En cada paso se actualizan \(c_t\) y \(h_t\).
   - Se produce una salida (por ejemplo, en cada paso o solo al final).

2. **C√°lculo de la p√©rdida**:
   - Se compara la salida de la red con la etiqueta real.
   - Se usa una funci√≥n de p√©rdida acorde al problema:
     - Clasificaci√≥n: entrop√≠a cruzada (multiclase o binaria).
     - Regresi√≥n: error cuadr√°tico medio (MSE), etc.

3. **Backpropagation Through Time (BPTT)**:
   - Se retropropaga el gradiente desde el √∫ltimo paso hacia los
     primeros.
   - Se actualizan los pesos de todas las puertas y conexiones.

4. **Actualizaci√≥n de par√°metros**:
   - Se utilizan optimizadores como SGD, Adam, RMSprop.
   - En la pr√°ctica, Adam y RMSprop son muy populares en LSTM.

Gracias a la estructura de memoria, los gradientes a trav√©s de \(c_t\)
tienden a **no desaparecer tan r√°pido** como en una RNN simple.

** Tipos de tareas t√≠picas con LSTM

Las LSTM se aplican a muchas tareas de secuencia:

- *Modelado de lenguaje*:
  - Predecir la siguiente palabra de una oraci√≥n.
  - Asignar probabilidad a una secuencia de palabras.

- *Traducci√≥n autom√°tica*:
  - Modelos encoder‚Äìdecoder (LSTM para codificar una oraci√≥n, otra LSTM
    para decodificar en otro idioma).

- *Etiquetado secuencial*:
  - Etiquetado de partes del habla (POS tagging).
  - Reconocimiento de entidades nombradas (NER).

- *Series temporales*:
  - Predicci√≥n de valores futuros (ej. precios de acciones).
  - Detecci√≥n de anomal√≠as en se√±ales.

- *Procesamiento de audio / voz*:
  - Reconocimiento de voz.
  - S√≠ntesis de voz (en combinaci√≥n con otras arquitecturas).

** Variantes y extensiones de LSTM

A partir de la LSTM est√°ndar, han surgido m√∫ltiples variantes:

- *LSTM bidireccional (Bidirectional LSTM)*:
  - Procesa la secuencia en dos direcciones:
    - de izquierda a derecha (forward),
    - de derecha a izquierda (backward).
  - Se concatena la informaci√≥n de ambos sentidos.
  - √ötil cuando se tiene acceso a la secuencia completa (texto, frases).

- *Pilado de LSTMs (Stacked LSTM)*:
  - Varias capas LSTM apiladas una sobre otra.
  - Las salidas de una capa sirven de entradas a la siguiente.
  - Permite aprender representaciones m√°s complejas.

- *LSTM con atenci√≥n (Attention)*:
  - Combinaci√≥n de LSTM con mecanismos de atenci√≥n.
  - El modelo decide a qu√© partes de la secuencia ‚Äúprestar m√°s atenci√≥n‚Äù
    al hacer una predicci√≥n.

- *GRU (Gated Recurrent Unit)*:
  - Variante simplificada de LSTM (menos puertas, menos par√°metros).
  - Suele tener rendimiento comparable en muchos problemas.

** Implementaci√≥n b√°sica en Python (Keras)

A modo de ejemplo muy simple (no ligado a un dataset espec√≠fico):

#+begin_src python
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Supongamos una secuencia de longitud 10 con 5 features por timestep
timesteps = 10
features = 5
num_samples = 100
num_classes = 3

# Datos aleatorios de ejemplo (solo para ilustrar la forma)
X = np.random.randn(num_samples, timesteps, features)
y = np.random.randint(0, num_classes, size=(num_samples,))

# One-hot encoding
y_onehot = tf.keras.utils.to_categorical(y, num_classes=num_classes)

# Definir modelo LSTM
model = Sequential([
    LSTM(32, input_shape=(timesteps, features)),
    Dense(num_classes, activation='softmax')
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

# Entrenamiento de ejemplo
model.fit(X, y_onehot, epochs=10, batch_size=16)
#+end_src

En este ejemplo:

- La entrada tiene forma =(num_samples, timesteps, features)=.
- La LSTM devuelve un vector (el √∫ltimo estado oculto).
- La capa =Dense= con softmax produce una distribuci√≥n de probabilidad
  sobre las clases.

** Ventajas y limitaciones de LSTM

*** Ventajas

- Manejan mejor dependencias de largo plazo que las RNN simples.
- Funcionan bien en problemas donde el orden y el contexto importan.
- Son muy flexibles y pueden combinarse con otras arquitecturas
  (convolucionales, atenci√≥n, etc.).

*** Limitaciones

- Entrenamiento relativamente costoso (m√°s par√°metros que RNN simple).
- Dif√≠ciles de paralelizar completamente debido a su naturaleza
  secuencial.
- En tareas muy complejas y con grandes vol√∫menes de datos, han sido en
  muchos casos superadas por arquitecturas basadas en *transformers*.

** Conclusi√≥n

Las LSTM representan un paso fundamental en la historia de las redes
neuronales para secuencias:

- resolvieron en gran medida el problema del desvanecimiento del
  gradiente en RNN,
- permitieron avances significativos en NLP, series temporales y voz,
- siguen siendo una herramienta muy √∫til y educativa para entender c√≥mo
  las redes pueden ‚Äúrecordar‚Äù informaci√≥n a lo largo del tiempo.

Aun cuando hoy en d√≠a los *transformers* dominen muchas aplicaciones de
NLP, las LSTM siguen siendo:

- una excelente base conceptual,
- √∫tiles en problemas con secuencias peque√±as o recursos limitados,
- y una parte importante de la ‚Äúcaja de herramientas‚Äù de cualquier
  persona que trabaja con aprendizaje profundo y datos secuenciales.


* Ejemplo Clasificaci√≥n del dataset Iris con una red LSTM

Este apartado muestra un ejemplo completo en Python usando el dataset
cl√°sico Iris y una red neuronal recurrente del tipo *LSTM* (Long Short-Term Memory)
usando la librer√≠a *Keras* (TensorFlow).

El objetivo es clasificar flores Iris en tres clases:

- Setosa
- Versicolor
- Virginica

A diferencia del MLP (Perceptr√≥n Multicapa), la LSTM est√° dise√±ada
para procesar datos *secuenciales*. En este ejemplo, forzamos la
estructura secuencial tratando las 4 caracter√≠sticas de Iris como una
secuencia de 4 pasos temporales.

** Importar librer√≠as

#+begin_src python
import numpy as np

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.utils import to_categorical
#+end_src

** Cargar el dataset Iris

#+begin_src python
iris = load_iris()
X = iris.data      # Caracter√≠sticas (150 x 4)
y = iris.target    # Clases (150,)

print(X.shape)     # (150, 4)
print(y.shape)     # (150,)
#+end_src

Las 4 caracter√≠sticas son:

- Largo del s√©palo
- Ancho del s√©palo
- Largo del p√©talo
- Ancho del p√©talo

Las clases est√°n codificadas como:

- 0 ‚Üí Setosa
- 1 ‚Üí Versicolor
- 2 ‚Üí Virginica

** Partici√≥n entrenamiento / prueba

El siguiente fragmento de c√≥digo realiza la partici√≥n del conjunto de
datos original en dos subconjuntos disjuntos: uno destinado al
entrenamiento del modelo y otro a su evaluaci√≥n.

#+begin_src python
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)
#+end_src

*** Prop√≥sito de la partici√≥n

En aprendizaje autom√°tico supervisado, es fundamental evaluar la
capacidad de generalizaci√≥n de un modelo. Para ello, los datos
disponibles se dividen en:

- *Conjunto de entrenamiento*: utilizado para ajustar los par√°metros del modelo (pesos y sesgos).
- *Conjunto de prueba*: utilizado exclusivamente para medir el desempe√±o del modelo sobre datos no vistos durante el entrenamiento.

Esta separaci√≥n permite detectar fen√≥menos como overfitting y
underfitting, y proporciona una estimaci√≥n m√°s realista del
rendimiento esperado en producci√≥n.

*** Par√°metro test_size

#+begin_src python
test_size = 0.2
#+end_src

indica que el 20 % del conjunto total de datos se reserva para el
conjunto de prueba, mientras que el 80 % restante se utiliza para
entrenamiento.

*** Reproducibilidad del experimento

El par√°metro:

#+begin_src python
random_state = 42
#+end_src

fija la semilla del generador de n√∫meros aleatorios utilizado durante
la partici√≥n. Esto garantiza que la divisi√≥n de los datos sea
reproducible.

*** Estratificaci√≥n de clases

El par√°metro:

#+begin_src python
stratify = y
#+end_src

indica que la divisi√≥n debe realizarse de forma estratificada,
conservando la proporci√≥n original de cada clase en ambos
subconjuntos.

** Normalizaci√≥n de los datos

La normalizaci√≥n de los datos de entrada es un paso cr√≠tico en el
entrenamiento de redes neuronales (incluyendo LSTM), ya que influye
directamente en la estabilidad num√©rica, la velocidad de convergencia
y la eficacia del aprendizaje.

Usaremos estandarizaci√≥n con =StandardScaler=:

#+begin_src python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
#+end_src

Cada caracter√≠stica \(x\) se transforma seg√∫n:

#+begin_latex
x' = \frac{x - \mu}{\sigma}
#+end_latex

donde:

- \( \mu \) es la media de la caracter√≠stica,
- \( \sigma \) es la desviaci√≥n est√°ndar.

El resultado es:

- media aproximadamente 0,
- desviaci√≥n est√°ndar aproximadamente 1.

** Preparar los datos para LSTM

Las LSTM en Keras esperan entradas con forma:

- \((n\_muestras, n\_timesteps, n\_features)\)

En Iris, tenemos 4 caracter√≠sticas. Una forma simple de usar LSTM es:

- considerar una secuencia de longitud 4 (=timesteps=4=),
- con 1 caracter√≠stica por paso (=features=1=).

Esto implica reestructurar cada muestra de forma (4,) a (4, 1):

#+begin_src python
# Reshape para LSTM: (n_muestras, timesteps=4, features=1)
X_train_lstm = X_train.reshape((X_train.shape[0], 4, 1))
X_test_lstm = X_test.reshape((X_test.shape[0], 4, 1))

print(X_train_lstm.shape)  # (120, 4, 1)
print(X_test_lstm.shape)   # (30, 4, 1)
#+end_src

Adem√°s, para clasificaci√≥n multiclase con Keras, se suele usar
one-hot encoding de las etiquetas:

#+begin_src python
num_classes = len(np.unique(y))
y_train_cat = to_categorical(y_train, num_classes=num_classes)
y_test_cat = to_categorical(y_test, num_classes=num_classes)
#+end_src

** Definir la red LSTM

Definimos un modelo secuencial con una capa LSTM y una capa densa de
salida con softmax:

#+begin_src python
model = Sequential([
    LSTM(
        units=16,           # n√∫mero de unidades LSTM
        activation='tanh',  # activaci√≥n interna
        input_shape=(4, 1)  # (timesteps=4, features=1)
    ),
    Dense(num_classes, activation='softmax')
])
#+end_src

*** Arquitectura de la red

- *Capa de entrada*:
  - Forma: (4, 1)
  - 4 pasos "temporales" (cada uno con 1 valor), derivados de las 4 caracter√≠sticas.

- *Capa LSTM*:
  - =units=16=: 16 unidades de memoria.
  - Procesa la secuencia \((x_1, x_2, x_3, x_4)\) y genera una representaci√≥n que captura
    dependencias entre pasos.

- *Capa de salida (Dense + softmax)*:
  - 3 neuronas (una por clase).
  - Activaci√≥n softmax para obtener probabilidades.

** Compilaci√≥n del modelo

Escogemos una funci√≥n de p√©rdida apropiada para clasificaci√≥n
multiclase y un optimizador:

#+begin_src python
model.compile(
    loss='categorical_crossentropy',
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=['accuracy']
)
#+end_src

- =categorical_crossentropy=: log-loss multiclase.
- *Adam*: optimizador basado en descenso de gradiente con momento y tasas
  de aprendizaje adaptativas.
- Tasa de aprendizaje inicial \(\eta = 0.001\).

** Entrenamiento del modelo LSTM

#+begin_src python
history = model.fit(
    X_train_lstm,
    y_train_cat,
    epochs=200,         # n√∫mero de √©pocas
    batch_size=16,
    validation_split=0.1,
    verbose=1
)
#+end_src

Durante el entrenamiento:

*** Propagaci√≥n hacia adelante (forward pass)

- Cada muestra de entrada se considera como una secuencia de 4 pasos.
- En cada paso, la LSTM actualiza su:
  - estado oculto \(h_t\),
  - estado de memoria \(c_t\).

*** C√°lculo del error

- La salida softmax se compara con la etiqueta real codificada en one-hot.
- Se calcula la p√©rdida mediante entrop√≠a cruzada categ√≥rica.

*** Backpropagation Through Time (BPTT)

- El error se propaga hacia atr√°s a lo largo del tiempo (sobre los 4 pasos).
- Se calculan los gradientes de los pesos de la LSTM y de la capa de salida.

*** Descenso de gradiente con Adam

- Adam combina Momentum y RMSProp.
- Ajusta autom√°ticamente la tasa de aprendizaje para cada par√°metro.
- Proporciona convergencia r√°pida y estable.

** Evaluaci√≥n del modelo

Una vez entrenado el modelo, se eval√∫a su desempe√±o usando datos no
vistos (conjunto de prueba).

#+begin_src python
# Probabilidades por clase
y_pred_proba = model.predict(X_test_lstm)

# Clase predicha = √≠ndice de la probabilidad m√°xima
y_pred = np.argmax(y_pred_proba, axis=1)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificaci√≥n:\n")
print(classification_report(y_test, y_pred, target_names=iris.target_names))
#+end_src

*** M√©tricas utilizadas

- *Accuracy*: proporci√≥n total de predicciones correctas.
- *Precision*: qu√© tan confiables son las predicciones positivas.
- *Recall*: capacidad del modelo para encontrar todos los ejemplos de una clase.
- *F1-score*: balance entre precisi√≥n y recall.

En el dataset Iris, el accuracy tambi√©n suele estar en el rango del
95 % al 100 %.

** Predicci√≥n con una nueva flor

El modelo entrenado puede utilizarse para predecir nuevas muestras.
Es importante repetir el mismo preprocesamiento: normalizaci√≥n y
reshape para LSTM.

#+begin_src python
# [largo_sepalo, ancho_sepalo, largo_petalo, ancho_petalo]
flor_nueva = np.array([[5.1, 3.5, 1.4, 0.2]])

# 1) Normalizaci√≥n con el mismo scaler del entrenamiento
flor_nueva_scaled = scaler.transform(flor_nueva)

# 2) Reshape para LSTM: (1, timesteps=4, features=1)
flor_nueva_lstm = flor_nueva_scaled.reshape((1, 4, 1))

# 3) Predicci√≥n
proba = model.predict(flor_nueva_lstm)
prediccion = np.argmax(proba, axis=1)

print("Clase predicha:", iris.target_names[prediccion[0]])
#+end_src

Es fundamental aplicar la misma normalizaci√≥n y la misma estructura de
entrada (forma (1, 4, 1)) que se usaron en el entrenamiento.

** Interpretaci√≥n matem√°tica b√°sica de la LSTM

En una LSTM, en cada paso temporal \(t\) se procesan:

- la entrada \(x_t\),
- el estado oculto anterior \(h_{t-1}\),
- el estado de memoria anterior \(c_{t-1}\).

La LSTM utiliza *puertas* que controlan el flujo de informaci√≥n:

#+begin_latex
\begin{aligned}
f_t &= \sigma(W_f [h_{t-1}, x_t] + b_f) \\
i_t &= \sigma(W_i [h_{t-1}, x_t] + b_i) \\
\tilde{c}_t &= \tanh(W_c [h_{t-1}, x_t] + b_c) \\
c_t &= f_t \odot c_{t-1} + i_t \odot \tilde{c}_t \\
o_t &= \sigma(W_o [h_{t-1}, x_t] + b_o) \\
h_t &= o_t \odot \tanh(c_t)
\end{aligned}
#+end_latex

donde:

- \(\sigma\) es la funci√≥n sigmoide,
- \(\odot\) denota el producto elemento a elemento.

Al final de la secuencia (tras los 4 pasos), el √∫ltimo estado oculto
\(h_T\) se pasa a la capa densa con funci√≥n softmax:

#+begin_latex
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}
#+end_latex

lo que permite interpretar las salidas como probabilidades para cada
clase (Setosa, Versicolor, Virginica).







* Bibliograf√≠a  Deep Learning

** Te√≥rica y Acad√©mica :MATEMATICAS:FUNDAMENTOS:
Libros dise√±ados para entender el "porqu√©" de los algoritmos.

*** Deep Learning
- *Autores:* Ian Goodfellow, Yoshua Bengio y Aaron Courville.
- *Editorial:* MIT Press (2016).
- *Nota:* Considerada la "Biblia" de la IA. Cubre √°lgebra lineal, probabilidad y arquitecturas complejas.
- *Web:* [[https://www.deeplearningbook.org/][Acceso gratuito a la versi√≥n web (HTML)]]

*** Neural Networks and Deep Learning: A Textbook
- *Autor:* Charu C. Aggarwal.
- *Editorial:* Springer (2018).
- *Enfoque:* Muy estructurado para estudiantes de ingenier√≠a y computaci√≥n.

** Pr√°ctica y Programaci√≥n :PYTHON:PYTORCH:KERAS:
Libros enfocados en la implementaci√≥n inmediata usando librer√≠as de Python.

*** Deep Learning with Python (3rd Edition)
- *Autor:* Fran√ßois Chollet (Creador de Keras).
- *Editorial:* Manning Publications (2025).
- *Por qu√© leerlo:* Explicaciones excepcionales sobre la intuici√≥n detr√°s de las redes neuronales.
- *Enlace:* [[https://www.manning.com/books/deep-learning-with-python-third-edition][P√°gina del libro]]

*** Hands-On Machine Learning with Scikit-Learn and PyTorch
- *Autor:* Aur√©lien G√©ron.
- *Editorial:* O'Reilly Media (Edici√≥n 2025).
- *Enfoque:* Es el manual m√°s completo para pasar de la teor√≠a a la pr√°ctica industrial. Cubre desde regresiones simples hasta Transformers.

** Aprendizaje "Desde Cero" :NUMPY:LOGICA:
Ideales para entender c√≥mo funciona el "motor" de una red neuronal sin usar herramientas autom√°ticas.

*** Grokking Deep Learning
- *Autor:* Andrew Trask.
- *Editorial:* Manning Publications.
- *Descripci√≥n:* Aprender√°s a programar redes neuronales usando solo =NumPy=. Ideal si quieres entender la "caja negra".

*** Neural Networks from Scratch (NNFS)
- *Autores:* Harrison Kinsley (Sentdex) y Daniel Kukie≈Ça.
- *Descripci√≥n:* Basado en c√≥digo puro de Python. Muy popular entre autodidactas.
- *Web:* [[https://nnfs.io/][Sitio Oficial de NNFS]]

** Tabla Comparativa para Elecci√≥n R√°pida

| Libro      | Nivel        | Enfoque Principal  | Tecnolog√≠a           |
|------------+--------------+--------------------+----------------------|
| Goodfellow | Avanzado     | Teor√≠a/Matem√°ticas | Gen√©rico             |
| Chollet    | Intermedio   | Intuici√≥n          | Keras/TensorFlow     |
| G√©ron      | Todos        | Pr√°ctica/Industria | PyTorch/Scikit-Learn |
| Trask      | Principiante | L√≥gica Interna     | NumPy                |



