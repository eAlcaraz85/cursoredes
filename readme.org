#+TITLE: Redes Neuronales Artificiales
#+AUTHOR: Eduardo Alcaraz
#+LANGUAGE: es
#+LaTeX_HEADER: \usepackage[spanish]{inputenc}
#+SETUPFILE: /home/likcos/Dropbox/org/cursos/redesneuronales/theme-readtheorg-local.setup
#+EXPORT_FILE_NAME: index.html
#+OPTIONS: num:nil
#+OPTIONS: tex:mathjax
#+HTML_HEAD: <style> #content{max-width:1800px;}</style>
#+HTML_HEAD: <style>pre.src {background-color: #303030; color: #e5e5e5;}</style>




* Presentaci√≥n del Curso
** Objetivo general
  Este curso tiene como objetivo proporcionar una
  comprensi√≥n *profunda y progresiva* de las redes neuronales
  artificiales, desde sus fundamentos te√≥ricos hasta las principales
  arquitecturas modernas utilizadas en la industria y la
  investigaci√≥n.


- Fundamentos matem√°ticos y conceptuales
- Funcionamiento interno de una red neuronal
- Entrenamiento y optimizaci√≥n
- Arquitecturas principales
- Intuici√≥n pr√°ctica y casos de uso



* Instalaci√≥n de requerimientos

** Verificaci√≥n de Python
Antes de instalar las dependencias, verifique que el sistema cuente con Python
versi√≥n 3.9 o superior.

#+BEGIN_SRC bash
python --version
#+END_SRC

En caso de que el comando anterior no est√© disponible, intente:

#+BEGIN_SRC bash
python3 --version
#+END_SRC

** Creaci√≥n del entorno virtual
Se recomienda crear un entorno virtual para aislar las dependencias del proyecto
y evitar conflictos entre versiones de librer√≠as.

#+BEGIN_SRC bash
python -m venv mlp_env
#+END_SRC

** Activaci√≥n del entorno virtual

La activaci√≥n del entorno virtual depende del sistema operativo y del int√©rprete
de comandos utilizado.

*** GNU/Linux y macOS
#+BEGIN_SRC bash
source mlp_env/bin/activate
#+END_SRC

*** Windows ‚Äì S√≠mbolo del sistema (CMD)
Si se utiliza el *S√≠mbolo del sistema* (cmd.exe), ejecute:

#+BEGIN_SRC bat
mlp_env\Scripts\activate.bat
#+END_SRC

*** Windows ‚Äì PowerShell
Si se utiliza *Windows PowerShell*, ejecute:

#+BEGIN_SRC powershell
mlp_env\Scripts\Activate.ps1
#+END_SRC

En caso de que la ejecuci√≥n de scripts est√© deshabilitada, habil√≠tela
temporalmente con:

#+BEGIN_SRC powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process
#+END_SRC

Posteriormente, vuelva a ejecutar el comando de activaci√≥n.

*** Windows ‚Äì Git Bash
Si se utiliza *Git Bash*, ejecute:

#+BEGIN_SRC bash
source mlp_env/Scripts/activate
#+END_SRC

Una vez activado el entorno virtual, el nombre del entorno aparecer√° entre
par√©ntesis al inicio de la l√≠nea de comandos.

** Actualizaci√≥n del gestor de paquetes
Antes de instalar las librer√≠as, se recomienda actualizar el gestor de paquetes
=pip=.

#+BEGIN_SRC bash
pip install --upgrade pip
#+END_SRC

** Instalaci√≥n de dependencias
Ejecute el siguiente comando para instalar los requerimientos del m√≥dulo
Perceptr√≥n Multicapa *feedforward*.

#+BEGIN_SRC bash
pip install numpy matplotlib scikit-learn pygame
#+END_SRC

** Verificaci√≥n de la instalaci√≥n
Para verificar que las dependencias se instalaron correctamente, ejecute Python
en modo interactivo:

#+BEGIN_SRC bash
python
#+END_SRC

Posteriormente, importe las librer√≠as:

#+BEGIN_SRC python
import numpy
import matplotlib
import sklearn
import pygame
print("Instalaci√≥n de requerimientos completada correctamente")
#+END_SRC

** Desactivaci√≥n del entorno virtual
Una vez finalizado el trabajo, el entorno virtual puede desactivarse con el
siguiente comando:

#+BEGIN_SRC bash
deactivate
#+END_SRC

* Manual de Entornos Virtuales en Python

** Introducci√≥n
El uso de entornos virtuales es esencial para mantener las
dependencias de tus proyectos aisladas. En este manual aprender√°s a
gestionarlos usando el m√≥dulo est√°ndar =venv=.

** Flujo de Trabajo B√°sico

*** 1. Creaci√≥n del entorno
Para crear un entorno virtual, navega a la ra√≠z de tu proyecto en la terminal (o dentro de un buffer de Emacs con =M-x shell=) y ejecuta:

#+begin_src bash
python -m venv .venv
#+end_src

*Nota:* El nombre =.venv= es una convenci√≥n que hace que el directorio sea oculto en sistemas Unix.

*** 2. Activaci√≥n
La activaci√≥n depende de tu sistema operativo:

**** En Windows (PowerShell)
#+begin_src powershell
.\.venv\Scripts\Activate.ps1
#+end_src

**** En macOS / Linux
#+begin_src bash
source .venv/bin/activate
#+end_src

** Gesti√≥n de paquetes
Una vez activado (ver√°s el prefijo =(.venv)= en tu prompt), puedes instalar librer√≠as:

#+begin_src bash
pip install requests pandas
#+end_src


** El archivo de Requerimientos
Es fundamental para la reproducibilidad del proyecto.

** Exportar dependencias
#+begin_src bash
pip freeze > requirements.txt
#+end_src

** Instalar desde el archivo
#+begin_src bash
pip install -r requirements.txt
#+end_src

** Tips de Limpieza
Para salir del entorno virtual:
#+begin_src bash
deactivate
#+end_src

Para borrar el entorno, simplemente elimina la carpeta:
#+begin_src bash
rm -rf .venv  # En Linux/macOS
rmdir /s /q .venv  # En Windows
#+end_src

---
#+BEGIN_QUOTE
"Keep your global Python clean, keep your projects isolated."
#+END_QUOTE




** Entornos Virtuales Python (Edici√≥n Windows)

** Requisitos Previos
1. Tener instalado Python (descargado de [[https://www.python.org/][python.org]] o la Microsoft Store).
2. Durante la instalaci√≥n, aseg√∫rate de marcar la casilla: **"Add Python to PATH"**.

** Flujo de Trabajo en Windows

*** 1. Crear el Entorno Virtual
Abre tu terminal (PowerShell o CMD) en la carpeta de tu proyecto. El comando es el mismo para ambos:

#+begin_src powershell
python -m venv venv
#+end_src

*** 2. El Paso Cr√≠tico: La Activaci√≥n
En Windows, la activaci√≥n depende de qu√© terminal est√©s usando.

**** Opci√≥n A: PowerShell (Recomendado)
Si es la primera vez que usas scripts en Windows, podr√≠as recibir un error de seguridad. Primero, ejecuta esto como administrador (solo una vez):
#+begin_src powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
#+end_src

Luego, para activar el entorno:
#+begin_src powershell
.\venv\Scripts\Activate.ps1
#+end_src

**** Opci√≥n B: S√≠mbolo del Sistema (CMD)
#+begin_src cmd
.\venv\Scripts\activate.bat
#+end_src

*** 3. Confirmaci√≥n
Sabr√°s que el entorno est√° activo porque el nombre =(venv)= aparecer√° a la izquierda de la ruta en tu terminal:
#+example
(venv) C:\Proyectos\MiProyecto>
#+example

** Gesti√≥n de Librer√≠as con PIP

*** Instalaci√≥n de paquetes
Una vez activo el entorno, instala lo que necesites:
#+begin_src powershell
pip install pandas requests openpyxl
#+end_src

*** Congelar dependencias (Compartir proyecto)
Para que otros participantes tengan exactamente lo mismo que t√∫:
#+begin_src powershell
pip freeze > requirements.txt
#+end_src

*** Instalar desde un archivo recibido
Si un compa√±ero te pasa su =requirements.txt=:
#+begin_src powershell
pip install -r requirements.txt
#+end_src

** Uso de Entornos en Emacs (Windows)

Para que Emacs en Windows gestione bien el entorno, a√±ade esto a tu archivo de configuraci√≥n (=init.el= o =.emacs=):

*** Instalaci√≥n del paquete pyvenv
#+begin_src elisp
(use-package pyvenv
  :ensure t
  :config
  (pyvenv-mode 1))
#+end_src

*** C√≥mo activarlo dentro de Emacs
1. Presiona =M-x pyvenv-activate=.
2. Emacs te pedir√° la ruta. Navega hasta la carpeta =venv= de tu proyecto.
3. Al seleccionarla, Emacs usar√° ese int√©rprete de Python para todos los scripts que ejecutes.

** Soluci√≥n de Problemas Comunes en Windows

| Error / Problema | Soluci√≥n |
| :--- | :--- |
| "python" no se reconoce | Reinstala Python y marca "Add to PATH" o usa el comando `py`. |
| Error de "Execution Policy" | Ejecuta `Set-ExecutionPolicy RemoteSigned -Scope CurrentUser`. |
| No aparece el (venv) | Aseg√∫rate de usar el comando de activaci√≥n correcto para tu terminal (.ps1 vs .bat). |

** Desactivaci√≥n y Limpieza
Para salir del entorno:
#+begin_src powershell
deactivate
#+end_src

Si quieres borrar el entorno por completo (para empezar de cero):
#+begin_src powershell
rmdir /s /q venv
#+end_src

---
#+BEGIN_IMPORTANT
*Recordatorio:* Nunca incluyas la carpeta =venv= en tus archivos compartidos o en tu repositorio de Git. Solo comparte el c√≥digo y el archivo =requirements.txt=.
#+END_IMPORTANT








** Agregar a jupyter notebook

#+BEGIN_SRC shell
pip install ipykernel
python -m ipykernel install --user --name=redes --display-name="redes"
#+END_SRC

* Introducci√≥n a la Inteligencia Artificial (IA)
** Definici√≥n formal

La *Inteligencia Artificial* es el √°rea de la computaci√≥n que estudia
  c√≥mo construir sistemas capaces de realizar tareas que, si fueran
  realizadas por humanos, requerir√≠an inteligencia.

Esto incluye capacidades como:

- Aprender de la experiencia
- Razonar
- Reconocer patrones
- Tomar decisiones bajo incertidumbre

La IA no implica necesariamente consciencia; se centra en *comportamiento inteligente observable*.

** IA d√©bil vs IA fuerte

- *IA d√©bil*: sistemas especializados en una tarea concreta (la IA actual)
- *IA fuerte*: inteligencia general comparable a la humana (te√≥rica)

Las redes neuronales pertenecen claramente a la IA d√©bil.


* Machine Learning (Aprendizaje Autom√°tico)
  ** Relaci√≥n entre IA y ML
  El *Machine Learning (ML)* es una subdisciplina de la IA. Mientras la IA es el objetivo general, el ML es una de las herramientas principales para alcanzarlo.

Idea clave:
#+begin_quote
En lugar de programar reglas, el sistema aprende las reglas a partir de datos.
#+end_quote

** Tipos de aprendizaje

- *Supervisado*: datos con etiqueta (clasificaci√≥n, regresi√≥n)
- *No supervisado*: datos sin etiqueta (clustering, reducci√≥n de dimensi√≥n)
- *Por refuerzo*: aprendizaje mediante recompensa y castigo

Las redes neuronales pueden adaptarse a los tres esquemas.


* Historia de las Redes Neuronales
** Contexto hist√≥rico
Desde mediados del siglo XX, cient√≠ficos han intentado entender si la inteligencia pod√≠a ser replicada mediante modelos matem√°ticos.

** McCulloch y Pitts (1943)
Propusieron la primera neurona artificial basada en l√≥gica
booleana. Demostraron que redes de estas neuronas pod√≠an computar
cualquier funci√≥n l√≥gica.

Este trabajo sent√≥ las bases te√≥ricas de las redes neuronales.

** Perceptr√≥n y optimismo inicial
En los a√±os 50 y 60, el perceptr√≥n gener√≥ grandes expectativas al ser uno de los primeros sistemas que *aprend√≠a* autom√°ticamente.

** Cr√≠ticas y estancamiento
El libro *Perceptrons* (Minsky & Papert, 1969) demostr√≥ limitaciones severas del perceptr√≥n, provocando una fuerte ca√≠da en el inter√©s por las redes neuronales.

** Renacimiento moderno

Con mayor poder computacional, grandes bases de datos y mejores algoritmos, las redes neuronales resurgen como *Deep Learning*.





* La Neurona Artificial
** Motivaci√≥n
  Una red neuronal artificial es un modelo matem√°tico inspirado en la
  organizaci√≥n y conectividad de las neuronas biol√≥gicas, que abstrae
  su funcionamiento esencial para construir sistemas capaces de
  aprender representaciones a partir de datos mediante el ajuste de
  par√°metros.

** Componentes

- Entradas: variables num√©ricas
- Pesos: importancia relativa de cada entrada
- Bias: ajuste del umbral
- Activaci√≥n: decisi√≥n final

** Modelo matem√°tico
#+begin_src text
z = w¬∑x + b
a = f(z)
#+end_src

Este modelo es la unidad b√°sica de todas las redes neuronales modernas.


* El Perceptr√≥n
** Definici√≥n
  El perceptr√≥n es una neurona artificial entrenable utilizada para clasificaci√≥n binaria.

** Interpretaci√≥n geom√©trica
El perceptr√≥n aprende una *frontera de decisi√≥n lineal* que separa los datos en dos clases.

** Aprendizaje

Cuando el perceptr√≥n se equivoca, ajusta sus pesos para reducir el error.

** Limitaciones
No puede aprender relaciones no lineales, como XOR.


* ¬øQu√© es un problema linealmente separable?

**  Intuici√≥n b√°sica 

Un problema es linealmente separable si puedes separar las clases usando una l√≠nea recta (en 2D),
un plano (en 3D), o en general un hiperplano.
Si existe una sola frontera recta que divide perfectamente las clases, el problema es linealmente separable.



* Estructura de un Perceptr√≥n Simple


** Entradas (Inputs)
- Representadas como $x_1, x_2, ..., x_n$.
- Son los datos brutos o caracter√≠sticas que recibe el modelo.

** Pesos Sin√°pticos (Weights)
- Representados como $w_1, w_2, ..., w_n$.
- Determinan la importancia o influencia de cada entrada en el resultado final.

** Suma Ponderada (Weighted Sum)
- Es la combinaci√≥n lineal de las entradas y los pesos.
- La f√≥rmula matem√°tica es:
  $$z = \sum_{i=1}^{n} w_i x_i + b$$

  
** Sesgo (Bias)
- Representado generalmente como $b$ (o $w_0$).
- Permite desplazar la funci√≥n de activaci√≥n hacia la izquierda o derecha para ajustar mejor los datos.

** Funci√≥n de Activaci√≥n
- Decide si la neurona debe "dispararse" (activarse) o no.
- En el perceptr√≥n original de Rosenblatt, se utiliza la *Funci√≥n Escal√≥n* (Heaviside):
  - $f(z) = 1$ si $z > 0$
  - $f(z) = 0$ en caso contrario.

** Salida (Output)
- Es el resultado final del procesamiento ($\hat{y}$).
- En un perceptr√≥n simple, suele ser un valor binario (0 o 1).


* Ejemplo Tacos

** 1. El Escenario: La Decisi√≥n de la Cena
Para entender c√≥mo aprende una IA, vamos a usar un ejemplo de la vida real. Queremos que nuestra neurona artificial aprenda cu√°ndo estamos "Satisfechos" (1) o "Inconformes" (0).

*** Nuestras Entradas (Inputs)
- $x_0$: ¬øHay Tacos? (1 = S√≠, 0 = No)
- $x_1$: ¬øHay Refresco? (1 = S√≠, 0 = No)

*** El Peso (Weight): La Importancia
No todo nos hace igual de felices. Los **Pesos** ($w_0, w_1$) representan qu√© tanto nos importa cada ingrediente. 
- Si el peso del taco es alto, el taco es fundamental para nuestra felicidad.

** 2. ¬øC√≥mo toma la decisi√≥n? (La Suma y el Sesgo)
La neurona hace un c√°lculo matem√°tico simple:
$$net = (x_0 \cdot w_0) + (x_1 \cdot w_1) - \text{bias}$$

*** El Sesgo (Bias)
El **Bias** es nuestro "nivel de exigencia". Si el Bias es muy alto, necesitaremos mucha comida (pesos altos) para poder llegar a estar satisfechos.

** 3. El Descenso del Gradiente: ¬øC√≥mo "Aprende" la Neurona?
Cuando la neurona se equivoca, necesita ajustar sus pesos. Este proceso se llama **Descenso del Gradiente**.

*** El Error: La Br√∫jula
Si esper√°bamos estar felices (~target = 1~) pero la neurona dice que estamos tristes (~net = 0~), tenemos un **Error de 1**.
$$Error = Target - Net$$

*** El Ajuste (La Regla Delta)
Para corregir el error, cambiamos los pesos usando esta l√≥gica:
1. Miramos el **Error**.
2. Miramos la **Entrada** (¬øQui√©n tuvo la culpa? Si no hab√≠a tacos, el taco no pudo causar el error).
3. Aplicamos el **Learning Rate (K)**: Que es qu√© tan r√°pido queremos aprender.

$$Nuevo\_Peso = Peso\_Actual + (K \cdot Error \cdot Entrada)$$


Imagina que $K = 0.1$ y el Peso inicial del taco es $0.5$.
1. **Situaci√≥n:** Hay tacos ($x_0=1$), pero la red dice "Triste" ($net=0$). Nosotros quer√≠amos "Feliz" ($target=1$).
2. **C√°lculo del Error:** $1 - 0 = 1$.
3. **Ajuste del Peso:**
   - $Delta = 0.1 \cdot 1 \cdot 1 = 0.1$
   - $Nuevo\_Peso\_Taco = 0.5 + 0.1 = 0.6$

**Resultado:** La pr√≥xima vez que haya tacos, la neurona estar√° un poco m√°s cerca de hacernos felices. ¬°Eso es el aprendizaje!

Puntos importantes

- El **Gradiente** nos dice en qu√© direcci√≥n mover los pesos para que el error sea cero.
- El **Learning Rate** controla qu√© tan grandes son los pasos que damos hacia esa soluci√≥n.
- Si repetimos este proceso miles de veces (√âpocas), la neurona encontrar√° los pesos perfectos para nuestra felicidad.


** Perceptr√≥n ejemplo (Python)

1. Recibe entradas ($x_1, x_2, \dots$).
2. Las multiplica por pesos ($w_1, w_2, \dots$).
3. Suma un sesgo ($b$).
4. Aplica una funci√≥n de activaci√≥n (ej. Escal√≥n).

*** Perceptr√≥n para una compuerta "AND"
Este c√≥digo simula una neurona que solo se activa si ambas entradas son 1.

#+begin_src python :results output
def perceptron_and(x1, x2):
    # 1. Definimos los Pesos y el Sesgo (Bias)
    # Estos valores normalmente se aprenden, aqu√≠ los asignamos manualmente
    w1, w2 = 0.5, 0.5
    bias = -0.7

    # 2. Suma ponderada: (x1 * w1) + (x2 * w2) + bias
    suma = (x1 * w1) + (x2 * w2) + bias

    # 3. Funci√≥n de activaci√≥n (Escal√≥n de Heaviside)
    # Si la suma es mayor a 0, la neurona se dispara (1)
    if suma > 0:
        return 1
    else:
        return 0

# Prueba de la tabla de verdad AND
entradas = [(0, 0), (0, 1), (1, 0), (1, 1)]

print("Entrada | Salida")
print("--------|-------")
for e in entradas:
    resultado = perceptron_and(e[0], e[1])
    print(f" {e}  |   {resultado}")
#+end_src

#+RESULTS:
: Entrada | Salida
: --------|-------
:  (0, 0)  |   0
:  (0, 1)  |   0
:  (1, 0)  |   0
:  (1, 1)  |   1




* Codigo C python

#+BEGIN_SRC python
import math
import random

EPOCAS = 300000
K = 0.03  # tasa de aprendizaje

# Pesos y bias globales (como en el c√≥digo C)
Pesos = [0.0, 0.0]
bias = 0.5
Error = 0.0


def sigmoide(s: float) -> float:
    # Versi√≥n correcta de la sigmoide log√≠stica:
    # 1 / (1 + e^{-s})
    return 1.0 / (1.0 + math.exp(-s))


def pesos_initNt():
    """Inicializa los pesos de forma aleatoria en [0,1)."""
    global Pesos
    Pesos = [random.random() for _ in range(2)]


def EntNt(x0: float, x1: float, target: float) -> float:
    """
    Funci√≥n de entrenamiento del perceptr√≥n (una iteraci√≥n para un patr√≥n).
    Modifica Pesos y bias de forma global.
    """
    global Pesos, bias, Error

    # net = w0*x0 + w1*x1 - bias
    net = Pesos[0] * x0 + Pesos[1] * x1 - bias
    net = sigmoide(net)

    Error = target - net

    # Actualizaci√≥n de bias (se asume entrada de bias = 1)
    bias -= K * Error

    # Variaci√≥n de los pesos sin√°pticos
    delta0 = K * Error * x0
    delta1 = K * Error * x1

    # Ajuste de pesos
    Pesos[0] += delta0
    Pesos[1] += delta1

    return net


def InitNt(x0: float, x1: float) -> float:
    """
    Funci√≥n que usa pesos fijos (de ejemplo) para calcular la salida.
    Equivalente a la parte comentada en C.
    """
    # net = 70.934807*x0 + 93.935219*x1 - 187.886169;
    net = 70.934807 * x0 + 93.935219 * x1 - 187.886169
    net = sigmoide(net)
    return net


def main():
    global Pesos, bias, Error

    pesos_initNt()

    for i in range(EPOCAS):
        print("------------------------")
        print(f"Salida Entrenamiento Epoca {i}")

        apr = EntNt(1, 1, 0)
        print(f"1,1 = {apr:.6f}")

        apr = EntNt(1, 0, 1)
        print(f"1,0 = {apr:.6f}")

        apr = EntNt(0, 1, 1)
        print(f"0,1 = {apr:.6f}")

        apr = EntNt(0, 0, 0)
        print(f"0,0 = {apr:.6f}")

        print("\nPesos de cada epoca")
        print(f"Peso 0 = {Pesos[0]:.6f}")
        print(f"Peso 1 = {Pesos[1]:.6f}")
        print(f"Bias   = {bias:.6f}")
        print(f"Error  = {Error:.6f}")
        print("------------------------")

    # Si quieres probar con los pesos fijos del comentario de C:
    # print("Resultados con InitNt:")
    # print("1,1 =", InitNt(1, 1))
    # print("1,0 =", InitNt(1, 0))
    # print("0,1 =", InitNt(0, 1))
    # print("0,0 =", InitNt(0, 0))


if __name__ == "__main__":
    main()
#+END_SRC


* Redes Neuronales Multicapa (Multilayer Perceptron)

** Introducci√≥n

Una *red neuronal multicapa* o *Perceptr√≥n Multicapa (MLP)* es un modelo
de aprendizaje supervisado que extiende al perceptr√≥n simple mediante
la inclusi√≥n de *una o m√°s capas ocultas*. Estas capas permiten modelar
*relaciones no lineales complejas* entre las variables de entrada y la salida.

Los MLP constituyen la base conceptual del *Deep Learning* moderno:

- El perceptr√≥n simple solo puede resolver problemas *linealmente separables*.
- Muchos problemas reales (visi√≥n, texto, se√±ales) son *no lineales*.
- Agregar capas ocultas + funciones de activaci√≥n no lineales permite
  aproximar funciones mucho m√°s complejas (teorema del aproximador universal).

Ejemplos cl√°sicos (con 2 entradas):

- AND  ‚Üí ‚úì separable linealmente
- OR   ‚Üí ‚úì separable linealmente
- XOR  ‚Üí ‚úó *no* es separable linealmente

El problema XOR demuestra la necesidad de introducir:

- *Capas ocultas* (capacidad de representar interacciones no triviales),
- *Funciones de activaci√≥n no lineales*.

Un MLP t√≠pico est√° compuesto por:

1. *Capa de entrada*  
   Recibe el vector de caracter√≠sticas \(\mathbf{x}\).

2. *Capas ocultas*  
   Realizan transformaciones lineales + no lineales sobre las
   representaciones intermedias.

3. *Capa de salida*  
   Produce la predicci√≥n final (clase, probabilidad, valor continuo, etc.).

Estructura conceptual:

#+begin_example
x ‚Üí Capa Oculta 1 ‚Üí Capa Oculta 2 ‚Üí ‚Ä¶ ‚Üí Capa de salida ‚Üí ≈∑
#+end_example

Cada ‚Äúflecha‚Äù representa una transformaci√≥n lineal (multiplicaci√≥n por
matriz de pesos + suma de bias) seguida de una funci√≥n de activaci√≥n.

** Modelo matem√°tico

*** Neurona individual

Cada neurona recibe un vector de entrada \(\mathbf{x} \in \mathbb{R}^n\) y calcula:

\[
z = \sum_{i=1}^{n} w_i x_i + b
\]

\[
a = f(z)
\]

Donde:

- \(w_i\): pesos sin√°pticos de la neurona,
- \(b\): t√©rmino de sesgo (bias),
- \(f(\cdot)\): funci√≥n de activaci√≥n,
- \(z\): combinaci√≥n lineal de las entradas,
- \(a\): salida (activaci√≥n) de la neurona.

En forma vectorial para una neurona:

\[
z = \mathbf{w}^\top \mathbf{x} + b
\]

\[
a = f(z)
\]

*** Forma matricial de una capa

En una capa con m√∫ltiples neuronas, se usa notaci√≥n matricial:

- \(\mathbf{a}^{(l-1)}\): vector de activaciones de la capa anterior,
- \(\mathbf{W}^{(l)}\): matriz de pesos de la capa \(l\),
- \(\mathbf{b}^{(l)}\): vector de bias de la capa \(l\),
- \(\mathbf{z}^{(l)}\): preactivaciones de la capa \(l\),
- \(\mathbf{a}^{(l)}\): activaciones de la capa \(l\).

C√°lculo:

\[
\mathbf{z}^{(l)} = \mathbf{W}^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}
\]

\[
\mathbf{a}^{(l)} = f(\mathbf{z}^{(l)})
\]

donde \(f\) se aplica componente a componente.

Repitiendo este proceso desde la capa de entrada hasta la salida,
obtenemos la predicci√≥n del MLP.

** Funciones de activaci√≥n

Las funciones de activaci√≥n son componentes fundamentales en las redes
neuronales multicapa. Su funci√≥n principal es introducir *no linealidad*
en el modelo.

Sin funciones de activaci√≥n no lineales:

- cada capa ser√≠a solo una transformaci√≥n lineal,
- y la composici√≥n de m√∫ltiples transformaciones lineales es *otra*
  transformaci√≥n lineal,
- por lo tanto, una ‚Äúred profunda‚Äù sin no linealidad se comporta como
  un *modelo lineal simple*, independientemente del n√∫mero de capas.

*** ¬øPara qu√© sirven las funciones de activaci√≥n?

Las funciones de activaci√≥n permiten:

- Introducir *no linealidad* en la red.
- Modelar relaciones complejas entre variables de entrada y salida.
- Aprender fronteras de decisi√≥n no lineales en problemas de clasificaci√≥n.
- Aproximar cualquier funci√≥n continua bajo ciertas condiciones
  (teorema del aproximador universal).

Recordemos que una neurona realiza:

\[
z = \sum_{i=1}^{n} w_i x_i + b
\]

\[
a = f(z)
\]

Donde \(f\) es la funci√≥n de activaci√≥n.

** Clasificaci√≥n de las funciones de activaci√≥n

Las funciones de activaci√≥n pueden clasificarse seg√∫n:

- su forma (escal√≥n, sigmoide, lineal por partes, etc.),
- su rango de salida,
- su uso (capas ocultas vs capa de salida),
- su comportamiento para valores grandes de \(|z|\).

*** Funciones de activaci√≥n cl√°sicas

**** Funci√≥n escal√≥n (Step Function)

\[
f(z) =
\begin{cases}
1 & \text{si } z \ge 0 \\
0 & \text{si } z < 0
\end{cases}
\]

Caracter√≠sticas:

- Usada en el perceptr√≥n simple original.
- No es continua ni derivable (no adecuada para descenso de gradiente).
- Genera salidas binarias (0/1).

Uso:

- Modelos te√≥ricos e hist√≥ricos.
- Introducci√≥n al concepto de neurona como ‚Äúdisparar / no disparar‚Äù.
- No se utiliza en redes multicapa modernas para entrenamiento con
  backpropagation.

**** Sigmoide log√≠stica

\[
f(z) = \frac{1}{1 + e^{-z}}
\]

Caracter√≠sticas:

- Salida en el intervalo \((0, 1)\).
- Puede interpretarse como una probabilidad.
- Es suave y derivable en todo \(\mathbb{R}\).

Ventajas:

- Interpretaci√≥n probabil√≠stica directa.
- Hist√≥ricamente muy usada en redes neuronales tempranas.

Desventajas:

- Para \(|z|\) grandes, la funci√≥n se *satura* cerca de 0 o 1:
  - la derivada es muy peque√±a,
  - aparece el problema de *vanishing gradient*,
  - el entrenamiento de redes profundas se vuelve lento o ineficaz.

Uso t√≠pico actual:

- Capa de salida en algunos modelos de clasificaci√≥n binaria (aunque
  en deep learning moderno tambi√©n se usan otras combinaciones).

**** Tangente hiperb√≥lica (tanh)

\[
f(z) = \tanh(z)
\]

Caracter√≠sticas:

- Salida en el intervalo \((-1, 1)\).
- Es sim√©trica alrededor de 0 (centrada en cero).

Ventajas:

- En comparaci√≥n con la sigmoide log√≠stica, su salida centrada en cero:
  - puede favorecer una convergencia algo m√°s r√°pida,
  - reduce ciertos sesgos en las activaciones.

Desventajas:

- Tambi√©n se satura para \(|z|\) grandes.
- Sigue presentando *vanishing gradient* en redes muy profundas.

Uso cl√°sico:

- Capas ocultas en redes no demasiado profundas, antes de la adopci√≥n
  masiva de ReLU.

*** Funciones de activaci√≥n modernas

**** ReLU (Rectified Linear Unit)

\[
f(z) = \max(0, z)
\]

Caracter√≠sticas:

- Funci√≥n lineal por partes:
  - para \(z < 0\): salida 0,
  - para \(z \ge 0\): salida \(z\).
- Muy sencilla y eficiente de calcular.

Ventajas:

- No se satura para valores positivos grandes (derivada constante 1).
- Reduce considerablemente el problema del *vanishing gradient*.
- Ha permitido entrenar redes profundas con muchas capas.

Desventajas:

- *Dead neurons*: si una neurona recibe valores de \(z\) siempre
  negativos, su salida es siempre 0 y el gradiente puede quedar en 0
  ‚Üí deja de aprender.

Uso t√≠pico:

- Funci√≥n est√°ndar en *capas ocultas* de MLP y CNN modernos.

**** Leaky ReLU

\[
f(z) =
\begin{cases}
z & \text{si } z \ge 0 \\
\alpha z & \text{si } z < 0
\end{cases}
\]

donde \(\alpha\) es un peque√±o n√∫mero positivo (por ejemplo, 0.01).

Caracter√≠sticas:

- Variante de ReLU que, en lugar de ‚Äúapagar‚Äù totalmente la neurona para
  \(z < 0\), permite un peque√±o gradiente negativo.

Ventajas:

- Reduce el problema de neuronas muertas (*dead ReLU*).
- Mantiene muchas ventajas de ReLU.

Uso t√≠pico:

- Alternativa a ReLU cuando se observa que muchas neuronas quedan
  inactivas de manera permanente.

**** ELU (Exponential Linear Unit)

\[
f(z) =
\begin{cases}
z & \text{si } z \ge 0 \\
\alpha (e^{z} - 1) & \text{si } z < 0
\end{cases}
\]

Caracter√≠sticas:

- Para \(z \ge 0\): igual que ReLU.
- Para \(z < 0\): decae de forma exponencial, con salida negativa acotada.

Ventajas:

- Puede acelerar la convergencia en ciertos casos.
- Las salidas negativas ayudan a centrar la activaci√≥n alrededor de 0,
  lo que puede mejorar la propagaci√≥n del gradiente.

Uso t√≠pico:

- Capas ocultas, en algunos modelos donde se ha observado mejor
  rendimiento que con ReLU est√°ndar.

*** Funciones de activaci√≥n en la capa de salida

La funci√≥n de activaci√≥n de la *capa de salida* depende del tipo de
problema:

**** Clasificaci√≥n binaria

Se usa t√≠picamente una funci√≥n *sigmoide* para obtener una probabilidad
en \((0,1)\):

\[
\hat{y} = \sigma(z) \in (0,1)
\]

donde \(\hat{y}\) se interpreta como la probabilidad de clase ‚Äú1‚Äù.

**** Clasificaci√≥n multiclase (mutuamente excluyentes)

Se usa la funci√≥n *softmax*:

\[
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}
\]

- Convierte un vector de puntajes \(\mathbf{z}\) en un vector de
  probabilidades que:
  - son positivas,
  - y suman 1.

**** Regresi√≥n

- Se usa generalmente una funci√≥n de activaci√≥n *lineal* en la salida:
  \[
    f(z) = z
  \]
- La red puede entonces producir valores reales sin restricci√≥n de
  rango (o con restricciones adicionales impuestas por el preprocesado).

*** Impacto en el entrenamiento

La elecci√≥n de la funci√≥n de activaci√≥n afecta:

- La *velocidad de convergencia*.
- La *estabilidad* del entrenamiento.
- El *flujo del gradiente* a trav√©s de las capas.
- La capacidad de representar ciertas distribuciones de salida.

Una elecci√≥n inadecuada:

- puede causar vanishing/exploding gradient,
- puede impedir que la red aprenda adecuadamente,
- o requerir tiempos de entrenamiento excesivos.

** Propagaci√≥n hacia adelante (Forward Propagation)

La *propagaci√≥n hacia adelante* es el proceso mediante el cual la red
calcula su salida a partir de una entrada dada.

Pasos generales:

1. Se recibe el vector de entrada \(\mathbf{x}\).
2. Se calcula sucesivamente:
   - \(\mathbf{z}^{(1)}\), \(\mathbf{a}^{(1)}\) (primera capa oculta),
   - \(\mathbf{z}^{(2)}\), \(\mathbf{a}^{(2)}\), etc.
3. Se obtiene la activaci√≥n de la capa de salida \(\mathbf{a}^{(L)}\),
   que corresponde a la predicci√≥n \(\hat{\mathbf{y}}\).

Podemos verlo como una composici√≥n de funciones:

\[
\mathbf{a}^{(L)} = f^{(L)}\left( \mathbf{W}^{(L)} \, f^{(L-1)}\left( \dots f^{(1)}\left(\mathbf{W}^{(1)} \mathbf{x} + \mathbf{b}^{(1)}\right) \dots \right) + \mathbf{b}^{(L)} \right)
\]

o, de forma m√°s compacta:

\[
\hat{\mathbf{y}} = F(\mathbf{x}; \theta)
\]

donde \(\theta\) denota el conjunto de todos los pesos y bias de la red.

** Funciones de p√©rdida

Las funciones de p√©rdida (o *funciones de coste*) miden el error entre:

- la predicci√≥n del modelo \(\hat{y}\) (o \(\hat{\mathbf{y}}\)),
- y el valor real \(y\) (o \(\mathbf{y}\)).

El objetivo del entrenamiento es encontrar par√°metros \(\theta\) que
*minimicen* la p√©rdida promedio sobre el conjunto de entrenamiento.

*** Error cuadr√°tico medio (MSE)

Com√∫n en problemas de regresi√≥n:

\[
\mathcal{L}_{\text{MSE}} = \frac{1}{n} \sum_{k=1}^{n} (y_k - \hat{y}_k)^2
\]

donde:

- \(n\) es el n√∫mero de muestras,
- \(y_k\) es el valor real de la muestra \(k\),
- \(\hat{y}_k\) es la predicci√≥n del modelo.

*** Entrop√≠a cruzada (Cross-Entropy)

Muy utilizada en clasificaci√≥n.

- Para clasificaci√≥n binaria:

\[
\mathcal{L}_{\text{binaria}} = - \frac{1}{n} \sum_{k=1}^{n} \left[ y_k \log(\hat{y}_k) + (1 - y_k)\log(1 - \hat{y}_k) \right]
\]

- Para clasificaci√≥n multiclase (one-hot \(\mathbf{y}\) y softmax \(\hat{\mathbf{y}}\)):

\[
\mathcal{L}_{\text{multiclase}} = - \frac{1}{n} \sum_{k=1}^{n} \sum_{c=1}^{C} y_{k,c} \log(\hat{y}_{k,c})
\]

donde:

- \(C\) es el n√∫mero de clases,
- \(y_{k,c}\) es 1 si la muestra \(k\) pertenece a la clase \(c\), y 0 en caso contrario,
- \(\hat{y}_{k,c}\) es la probabilidad predicha para la clase \(c\).

** Backpropagation

*Backpropagation* es el algoritmo fundamental para entrenar MLP. Se
basa en la aplicaci√≥n sistem√°tica de la *regla de la cadena* del c√°lculo
diferencial para propagar el error desde la capa de salida hacia las
capas anteriores.

Para un peso gen√©rico \(w\), la derivada de la p√©rdida se expresa como:

\[
\frac{\partial \mathcal{L}}{\partial w} =
\frac{\partial \mathcal{L}}{\partial a}
\cdot \frac{\partial a}{\partial z}
\cdot \frac{\partial z}{\partial w}
\]

donde:

- \(\frac{\partial \mathcal{L}}{\partial a}\): cu√°nto cambia la p√©rdida
  si cambia la activaci√≥n \(a\),
- \(\frac{\partial a}{\partial z}\): deriva de la funci√≥n de activaci√≥n,
- \(\frac{\partial z}{\partial w}\): relaci√≥n lineal entre \(z\) y el
  peso \(w\).

El algoritmo:

1. Calcula un *forward pass* (de entrada a salida).
2. Calcula la p√©rdida \(\mathcal{L}\).
3. Propaga gradientes hacia atr√°s usando la regla de la cadena.
4. Obtiene \(\frac{\partial \mathcal{L}}{\partial w}\) y
   \(\frac{\partial \mathcal{L}}{\partial b}\) para todos los pesos y
   bias de la red.
5. Usa estos gradientes para actualizar los par√°metros.

** Descenso de gradiente

El *descenso de gradiente* (gradient descent) es la regla de
actualizaci√≥n b√°sica para minimizar la funci√≥n de p√©rdida.

Para un peso \(w\):

\[
w := w - \eta \, \frac{\partial \mathcal{L}}{\partial w}
\]

donde:

- \(\eta\) es la *tasa de aprendizaje* (learning rate),
- \(\frac{\partial \mathcal{L}}{\partial w}\) es el gradiente de la
  p√©rdida respecto a \(w\).

Interpretaci√≥n:

- Nos movemos en la direcci√≥n *opuesta* al gradiente (descenso),
- La magnitud del paso est√° controlada por \(\eta\).

En la pr√°ctica:

- Se usan variantes como:
  - *Stochastic Gradient Descent (SGD)*,
  - SGD con *momentum*,
  - *Adam*, *RMSProp*, etc.
- Estas variantes mejoran:
  - la velocidad de convergencia,
  - la estabilidad num√©rica,
  - la capacidad de escapar de m√≠nimos locales poco profundos.


* Ejemplo Clasificaci√≥n del dataset Iris con MLP

Este apartado muestra un ejemplo completo en Python usando el dataset
cl√°sico Iris y una red neuronal feedforward (Perceptr√≥n Multicapa)
usando la librer√≠a scikit-learn.

El objetivo es clasificar flores Iris en tres clases:

- Setosa
- Versicolor
- Virginica


Importar librer√≠as

#+begin_src python
import numpy as np
from sklearn.datasets import load_iris 
from sklearn.model_selection import train_test_split 
from sklearn.preprocessing import StandardScaler 
from sklearn.neural_network import MLPClassifier 
from sklearn.metrics import accuracy_score, classification_report
#+end_src

Cargar el dataset Iris

#+begin_src python
iris = load_iris()
X = iris.data # Caracter√≠sticas (150 x 4) y = iris.target # Clases (150,)
print(X.shape) print(y.shape)
#+end_src

Las 4 caracter√≠sticas son:

- Largo del s√©palo
- Ancho del s√©palo
- Largo del p√©talo
- Ancho del p√©talo

Las clases est√°n codificadas como:

- 0 ‚Üí Setosa
- 1 ‚Üí Versicolor
- 2 ‚Üí Virginica

El siguiente fragmento de c√≥digo realiza la partici√≥n del conjunto de
datos original en dos subconjuntos disjuntos: uno destinado al
entrenamiento del modelo y otro a su evaluaci√≥n.

#+begin_src python
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42, stratify=y )
#+end_src

Prop√≥sito de la partici√≥n:

En aprendizaje autom√°tico supervisado, es fundamental evaluar la
capacidad de generalizaci√≥n de un modelo. Para ello, los datos
disponibles se dividen en:

- *Conjunto de entrenamiento*: utilizado para ajustar los par√°metros del modelo (pesos y sesgos).
- *Conjunto de prueba*: utilizado exclusivamente para medir el desempe√±o del modelo sobre datos no vistos durante el entrenamiento.

Esta separaci√≥n permite detectar fen√≥menos como overfitting y
underfitting, y proporciona una estimaci√≥n m√°s realista del
rendimiento esperado en producci√≥n.

*El par√°metro*:
#+BEGIN_SRC python
test_size=0.2
#+END_SRC
indica que el 20 % del conjunto total de datos se reserva para el
conjunto de prueba, mientras que el 80 % restante se utiliza para
entrenamiento. Esta proporci√≥n es com√∫n en la pr√°ctica y representa un
compromiso razonable entre:

- disponer de suficientes datos para entrenar el modelo, y
- contar con una muestra representativa para evaluar su generalizaci√≥n.

** Reproducibilidad del experimento

El par√°metro:

#+BEGIN_SRC python
random_state=42
#+END_SRC

fija la semilla del generador de n√∫meros aleatorios utilizado durante
la partici√≥n.  Esto garantiza que la divisi√≥n de los datos sea
reproducible, es decir, que m√∫ltiples ejecuciones del mismo c√≥digo
produzcan exactamente la misma separaci√≥n entre entrenamiento y
prueba.

La reproducibilidad es un requisito esencial en entornos cient√≠ficos y
acad√©micos, ya que permite validar y comparar resultados de manera
consistente.

** Estratificaci√≥n de clases

El par√°metro:

#+BEGIN_SRC python
stratify=y
#+END_SRC

indica que la divisi√≥n debe realizarse de forma estratificada,
conservando la proporci√≥n original de cada clase en ambos
subconjuntos.

Esto es especialmente importante en problemas de clasificaci√≥n, ya que
una divisi√≥n aleatoria sin estratificaci√≥n podr√≠a provocar:

- conjuntos de entrenamiento o prueba con clases desbalanceadas,
- m√©tricas de desempe√±o enga√±osas,
- modelos que no aprendan adecuadamente clases minoritarias.

Mediante la estratificaci√≥n, se asegura que tanto el conjunto de
entrenamiento como el de prueba sean representativos de la
distribuci√≥n real de las clases.

** Importancia en redes neuronales

En el contexto de redes neuronales (incluyendo MLP):

- el entrenamiento ajusta los pesos minimizando una funci√≥n de p√©rdida
  sobre X_train,

- la evaluaci√≥n sobre X_test permite medir la capacidad del modelo
  para generalizar,

- una mala partici√≥n puede conducir a conclusiones err√≥neas sobre el
  desempe√±o del modelo.

Por esta raz√≥n, la divisi√≥n adecuada del conjunto de datos constituye
un paso cr√≠tico previo al entrenamiento y no debe considerarse un
detalle menor de implementaci√≥n.


** Normalizaci√≥n de los datos

La normalizaci√≥n de los datos de entrada es un paso cr√≠tico en el
entrenamiento de redes neuronales, ya que influye directamente en la
estabilidad num√©rica, la velocidad de convergencia y la eficacia del
aprendizaje.

En una red neuronal, los pesos se ajustan mediante m√©todos de
optimizaci√≥n basados en gradientes. Si las variables de entrada
presentan escalas muy diferentes, el proceso de entrenamiento puede
volverse ineficiente o inestable.

En muchos conjuntos de datos, las caracter√≠sticas pueden tener rangos muy distintos. Por ejemplo:

- una variable puede tomar valores entre 0 y 1,
- otra entre 0 y 10‚Å∂,
- otra puede incluir valores negativos.

Cuando estos datos se introducen directamente en una red neuronal:

- los gradientes asociados a variables de gran escala dominan la actualizaci√≥n de los pesos,
- las funciones de activaci√≥n pueden saturarse,
- el descenso por gradiente se vuelve lento o err√°tico.

La normalizaci√≥n busca homogeneizar la escala de las entradas,
permitiendo que todas las caracter√≠sticas contribuyan de manera
equilibrada al aprendizaje.


Una de las t√©cnicas m√°s utilizadas es la estandarizaci√≥n, implementada
en scikit-learn mediante la clase StandardScaler.

#+begin_src python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train) X_test = scaler.transform(X_test)
#+end_src

Este procedimiento transforma cada caracter√≠stica \(x\) seg√∫n la siguiente expresi√≥n:

\[
x' = \frac{x - \mu}{\sigma}
\]

donde:

- \( \mu \) es la media de la caracter√≠stica,
- \( \sigma \) es la desviaci√≥n est√°ndar de la caracter√≠stica.

Como resultado de esta transformaci√≥n, cada variable queda con:

- media aproximadamente igual a 0,
- desviaci√≥n est√°ndar igual a 1.

** Definir el Perceptr√≥n Multicapa (MLP)


El siguiente fragmento de c√≥digo define un *Perceptr√≥n Multicapa* (Multilayer Perceptron, MLP)
para un problema de clasificaci√≥n multiclase, utilizando la implementaci√≥n provista por
la biblioteca *scikit-learn*.

#+begin_src python
mlp = MLPClassifier(
    hidden_layer_sizes=(10, 10),
    activation='relu',
    solver='adam',
    learning_rate_init=0.001,
    max_iter=2000,
    random_state=42
)
#+end_src

Este modelo corresponde a una red neuronal *feedforward completamente conectada*,
entrenada mediante *backpropagation* y optimizada usando m√©todos de descenso por gradiente.

*** Arquitectura de la red neuronal

La arquitectura del MLP queda determinada por el n√∫mero de caracter√≠sticas de entrada,
las capas ocultas definidas expl√≠citamente y el n√∫mero de neuronas en la capa de salida.

*** Capa de entrada

- La capa de entrada est√° compuesta por *4 neuronas*.
- Cada neurona representa una caracter√≠stica del vector de entrada.
- Esta capa no aplica transformaciones, √∫nicamente propaga los valores hacia la primera capa oculta.

Formalmente, el vector de entrada se expresa como:

\[
\mathbf{x} = (x_1, x_2, x_3, x_4)
\]

*** Capas ocultas

El par√°metro:

#+begin_src python
hidden_layer_sizes=(10, 10)
#+end_src

define *dos capas ocultas*, cada una con *10 neuronas*.

Caracter√≠sticas principales:

- Son capas *densas (fully connected)*.
- Cada neurona recibe como entrada la salida de *todas* las neuronas de la capa anterior.
- Permiten aprender representaciones no lineales del espacio de caracter√≠sticas.

Cada capa oculta implementa la transformaci√≥n:

\[
\mathbf{h}^{(l)} = f\left( \mathbf{W}^{(l)} \mathbf{h}^{(l-1)} + \mathbf{b}^{(l)} \right)
\]

donde:

- \( \mathbf{W}^{(l)} \) es la matriz de pesos,
- \( \mathbf{b}^{(l)} \) es el vector de sesgos,
- \( f(\cdot) \) es la funci√≥n de activaci√≥n.

*** Funci√≥n de activaci√≥n

El par√°metro:

#+begin_src python
activation='relu'
#+end_src

indica el uso de la funci√≥n *ReLU (Rectified Linear Unit)*, definida como:

\[
\text{ReLU}(z) = \max(0, z)
\]

Esta funci√≥n se utiliza porque:

- introduce no linealidad,
- reduce el problema del *vanishing gradient*,
- mejora la estabilidad del entrenamiento,
- es computacionalmente eficiente.

*** Capa de salida

- La capa de salida est√° compuesta por *3 neuronas*.
- Cada neurona corresponde a una de las clases del problema.
- Internamente, el modelo utiliza una funci√≥n *softmax* para obtener probabilidades.

La clase predicha se obtiene mediante la operaci√≥n *argmax* sobre las salidas.

*** Entrenamiento del modelo

El entrenamiento se realiza mediante el optimizador *Adam*:

#+begin_src python
solver='adam'
#+end_src

Adam combina:
- momentum
- tasas de aprendizaje adaptativas

lo que permite una convergencia m√°s r√°pida y estable en redes con m√∫ltiples capas.

La tasa de aprendizaje inicial se define como:

\[
\eta = 0.001
\]

controlando el tama√±o de los pasos durante la actualizaci√≥n de los pesos.

** N√∫mero de iteraciones

El par√°metro:

#+begin_src python
max_iter=2000
#+end_src

establece el n√∫mero m√°ximo de √©pocas de entrenamiento.
Una √©poca corresponde a un pase completo sobre el conjunto de entrenamiento.

Un n√∫mero elevado de √©pocas favorece la convergencia, aunque incrementa el riesgo de *overfitting*.

** Reproducibilidad

El par√°metro:

#+begin_src python
random_state=42
#+end_src

fija la semilla del generador de n√∫meros aleatorios, garantizando resultados reproducibles
en la inicializaci√≥n de los pesos y el proceso de entrenamiento.



** Entrenamiento del modelo

El entrenamiento de√± Perceptr√≥n Multicapa (MLP) consiste en ajustar
los pesos y sesgos de la red para minimizar el error de predicci√≥n
sobre los datos de entrenamiento.

#+begin_src python
mlp.fit(X_train, y_train)
#+end_src

Durante este proceso ocurren los siguientes pasos fundamentales:

*** Propagaci√≥n hacia adelante (forward pass)

Cada muestra de entrada x atraviesa la red capa por capa.

En cada neurona se calcula una combinaci√≥n lineal y se aplica una funci√≥n de activaci√≥n.

Se obtiene una salida y que representa la predicci√≥n del modelo.

*** C√°lculo del error

La salida predicha se compara con la etiqueta real ùë¶.
Se utiliza una funci√≥n de p√©rdida (por ejemplo, log-loss para clasificaci√≥n multiclase).

*** Backpropagation

El error se propaga desde la capa de salida hacia las capas
anteriores. Se calculan los gradientes del error respecto a cada peso
y sesgo. Se aplica la regla de la cadena del c√°lculo diferencial.

*** Descenso de gradiente con Adam

- Adam combina Momentum y RMSProp.
- Ajusta autom√°ticamente la tasa de aprendizaje para cada par√°metro.
- Proporciona convergencia r√°pida y estable.

** Evaluaci√≥n del modelo

Una vez entrenado el modelo, se eval√∫a su desempe√±o usando datos no vistos durante el entrenamiento.

#+begin_src python
y_pred = mlp.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred)) print("\nReporte de clasificaci√≥n:\n") print(classification_report(y_test, y_pred, target_names=iris.target_names))
#+end_src

*** M√©tricas utilizadas

- Accuracy: proporci√≥n total de predicciones correctas.
- Precision: qu√© tan confiables son las predicciones positivas.
- Recall: capacidad del modelo para encontrar todos los ejemplos de una clase.
- F1-score: balance entre precisi√≥n y recall.

En el dataset Iris, el accuracy suele estar en el rango del 95% al
100%, debido a su baja dimensionalidad y buena separaci√≥n entre
clases.

** Predicci√≥n con una nueva flor

El modelo entrenado puede utilizarse para predecir nuevas muestras.

#+begin_src python

#[largo_sepalo, ancho_sepalo, largo_petalo, ancho_petalo]

flor_nueva = np.array([[5.1, 3.5, 1.4, 0.2]])
#Normalizaci√≥n con el mismo scaler del entrenamiento
flor_nueva = scaler.transform(flor_nueva)
prediccion = mlp.predict(flor_nueva) print("Clase predicha:", iris.target_names[prediccion[0]])
#+end_src

Es fundamental aplicar la misma normalizaci√≥n usada en el entrenamiento para mantener coherencia en las escalas.

** Interpretaci√≥n matem√°tica del MLP

Cada neurona de la red realiza el siguiente c√°lculo:

#+begin_example
z = w ¬∑ x + b a = f(z)
#+end_example

Donde: ùë§ es el vector de pesos ùë• es el vector de entradas ùëè es el sesgo (bias) ùëì
es la funci√≥n de activaci√≥n (ReLU en las capas ocultas). La capa de salida utiliza la funci√≥n Softmax:

#+begin_latex
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}
#+end_latex

Esto permite interpretar las salidas como probabilidades para cada clase.

* Ejemplo Clasificaci√≥n de C√°ncer de Mama con MLP 

Este apartado muestra un ejemplo completo en Python usando el dataset
*Breast Cancer Wisconsin (Diagnostic)* y un *Perceptr√≥n Multicapa (MLP)*
usando la librer√≠a scikit-learn.

El objetivo es clasificar tumores en dos categor√≠as:

- 0 ‚Üí Maligno
- 1 ‚Üí Benigno

Este problema es un caso t√≠pico de **clasificaci√≥n binaria** en el
√°mbito m√©dico, donde es crucial:

- minimizar falsos negativos (tumor maligno clasificado como benigno),
- mantener una buena precisi√≥n general del modelo.

** Importar librer√≠as

#+begin_src python
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
#+end_src

En este bloque:

- =load_breast_cancer=: carga el dataset de c√°ncer de mama.
- =train_test_split=: divide en entrenamiento y prueba.
- =StandardScaler=: aplica estandarizaci√≥n a las caracter√≠sticas.
- =MLPClassifier=: implementa un Perceptr√≥n Multicapa (MLP).
- =accuracy_score= y =classification_report=: permiten evaluar el modelo.

** Cargar el dataset Breast Cancer

#+begin_src python
data = load_breast_cancer()
X = data.data      # Caracter√≠sticas (569 x 30)
y = data.target    # Etiquetas (569,)

print("Dimensiones de X:", X.shape)
print("Clases num√©ricas:", np.unique(y))
print("Nombres de clases:", data.target_names)
#+end_src

Este dataset contiene:

- 569 muestras (pacientes).
- 30 caracter√≠sticas num√©ricas que describen propiedades de los tumores
  (radio, textura, per√≠metro, √°rea, suavidad, compacidad, etc.).
- 2 clases:
  - 0 ‚Üí malignant (maligno)
  - 1 ‚Üí benign (benigno)

Cada muestra corresponde a una imagen de tejido mamario analizada
digitalmente. Las 30 caracter√≠sticas se derivan de medidas estad√≠sticas
de la forma, textura y estructura del tumor.

*** Importancia del dominio

En aplicaciones m√©dicas, la interpretaci√≥n de las predicciones es muy
sensible:

- un *falso negativo* (maligno etiquetado como benigno) puede retrasar
  un diagn√≥stico cr√≠tico;
- un *falso positivo* (benigno etiquetado como maligno) puede generar
  ansiedad y procedimientos innecesarios.

Por ello, adem√°s de la *accuracy*, suelen analizarse:

- sensibilidad (*recall*) para la clase ‚Äúmaligno‚Äù,
- especificidad,
- matriz de confusi√≥n, etc.

** Partici√≥n del conjunto de datos

Dividimos el dataset en entrenamiento y prueba:

#+begin_src python
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.3,
    random_state=42,
    stratify=y
)
#+end_src

*** Significado de los par√°metros

- =test_size=0.3=:
  - 30 % de los datos se reservan para el *conjunto de prueba*.
  - 70 % se usan para entrenar el modelo.
  - En este caso:
    - Entrenamiento: ‚âà 398 muestras.
    - Prueba: ‚âà 171 muestras.

- =random_state=42=:
  - Fija la semilla del generador de n√∫meros aleatorios.
  - Permite que la partici√≥n sea reproducible: el mismo c√≥digo genera
    siempre la misma divisi√≥n.

- =stratify=y=:
  - Asegura que la proporci√≥n de clases (maligno/benigno) sea similar
    tanto en entrenamiento como en prueba.
  - Esto es crucial en problemas m√©dicos, donde el balance de clases
    puede influir fuertemente en las m√©tricas.

*** Prop√≥sito de la partici√≥n

En aprendizaje autom√°tico supervisado:

- El *conjunto de entrenamiento* se usa para ajustar los par√°metros
  (pesos y sesgos) del modelo.
- El *conjunto de prueba* se usa *solo* para evaluar la capacidad de
  generalizaci√≥n sobre datos no vistos.

Esta separaci√≥n es esencial para:

- detectar *overfitting* (el modelo memoriza el entrenamiento pero
  generaliza mal),
- obtener una estimaci√≥n realista del rendimiento.

** Normalizaci√≥n (Estandarizaci√≥n)

Las caracter√≠sticas tienen escalas muy diferentes (√°reas grandes,
texturas peque√±as, etc.). Esto puede causar:

- problemas num√©ricos,
- gradientes desbalanceados,
- convergencia lenta o inestable.

Por ello, aplicamos estandarizaci√≥n:

#+begin_src python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
#+end_src

Este procedimiento transforma cada caracter√≠stica \(x\) seg√∫n:

#+begin_latex
x' = \frac{x - \mu}{\sigma}
#+end_latex

donde:

- \(\mu\) es la media de la caracter√≠stica calculada sobre el conjunto
  de entrenamiento,
- \(\sigma\) es la desviaci√≥n est√°ndar de dicha caracter√≠stica.

Despu√©s de la transformaci√≥n:

- cada variable tiene media aproximadamente 0,
- y desviaci√≥n est√°ndar aproximadamente 1.

*** Importante

- Solo se llama a =fit_transform= en =X_train=:
  - =fit= calcula \(\mu\) y \(\sigma\) usando *solo entrenamiento*.
  - =transform= aplica la transformaci√≥n.
- Para =X_test= se usa √∫nicamente =transform=:
  - se reescalan los datos de prueba con los mismos par√°metros
    (\(\mu\) y \(\sigma\)) obtenidos del entrenamiento.
- Esto evita *filtrar informaci√≥n del conjunto de prueba* hacia el
  proceso de entrenamiento (data leakage).

** Definici√≥n del Perceptr√≥n Multicapa (MLP)

Definimos un MLP para clasificaci√≥n binaria:

#+begin_src python
mlp = MLPClassifier(
    hidden_layer_sizes=(30, 15),
    activation='relu',
    solver='adam',
    max_iter=1000,
    random_state=42
)
#+end_src

*** Arquitectura del modelo

El MLP es una red neuronal *feedforward* completamente conectada.

- *Capa de entrada*:
  - Tiene tantas neuronas como caracter√≠sticas de entrada: 30.
  - Cada componente del vector \(\mathbf{x} \in \mathbb{R}^{30}\)
    representa una caracter√≠stica del tumor.

- *Capas ocultas*:
  - Primer capa oculta: 30 neuronas.
  - Segunda capa oculta: 15 neuronas.
  - Se especifican con el par√°metro:
    #+begin_src python
hidden_layer_sizes = (30, 15)
    #+end_src

  Cada neurona en una capa oculta:
  - recibe como entrada la salida de todas las neuronas de la capa
    anterior (capas densas),
  - aplica una transformaci√≥n lineal seguida de una funci√≥n de
    activaci√≥n no lineal.

- *Capa de salida*:
  - Para clasificaci√≥n binaria, internamente el MLP de scikit-learn
    puede usar:
    - 1 neurona con activaci√≥n log√≠stica (sigmoide),
    - o una representaci√≥n equivalente a 2 clases.
  - La salida se interpreta como una probabilidad de pertenecer a la
    clase ‚Äú1‚Äù (benigno).

*** Funci√≥n de activaci√≥n ReLU

El par√°metro:

#+begin_src python
activation = 'relu'
#+end_src

indica el uso de la funci√≥n *ReLU (Rectified Linear Unit)* en las capas
ocultas:

#+begin_latex
\text{ReLU}(z) = \max(0, z)
#+end_latex

Ventajas de ReLU:

- Introduce no linealidad (permite aproximar funciones no lineales).
- Reduce el problema del *vanishing gradient* en comparaci√≥n con
  funciones como sigmoide o tanh.
- Es simple y eficiente de calcular.

*** Optimizador Adam

El par√°metro:

#+begin_src python
solver = 'adam'
#+end_src

selecciona el optimizador *Adam* (Adaptive Moment Estimation), que:

- combina ideas de Momentum y RMSProp,
- mantiene promedios m√≥viles de:
  - los gradientes,
  - los gradientes al cuadrado,
- adapta la tasa de aprendizaje para cada par√°metro.

Esto suele producir:

- convergencia r√°pida,
- estabilidad num√©rica,
- buen desempe√±o sin necesidad de mucha sinton√≠a manual.

*** N√∫mero m√°ximo de iteraciones

#+begin_src python
max_iter = 1000
#+end_src

- Indica el n√∫mero m√°ximo de √©pocas (o iteraciones sobre los datos)
  para entrenar la red.
- Un valor alto permite que el modelo converja, aunque si es excesivo
  puede aumentar el riesgo de *overfitting* (la red se ajusta demasiado
  al entrenamiento).

*** Reproducibilidad

#+begin_src python
random_state = 42
#+end_src

- Fija la semilla para la inicializaci√≥n de pesos y el muestreo interno.
- Permite reproducir exactamente los mismos resultados entre ejecuciones.

** Entrenamiento del modelo

Entrenamos el MLP ajustando pesos y sesgos para minimizar el error de
clasificaci√≥n en el conjunto de entrenamiento:

#+begin_src python
mlp.fit(X_train, y_train)
#+end_src

*** Proceso interno (visi√≥n conceptual)

1. *Propagaci√≥n hacia adelante*:
   - Cada muestra \(\mathbf{x}\) pasa por las capas:
     \[
       \mathbf{h}^{(1)} = f_1(W^{(1)} \mathbf{x} + \mathbf{b}^{(1)})
     \]
     \[
       \mathbf{h}^{(2)} = f_2(W^{(2)} \mathbf{h}^{(1)} + \mathbf{b}^{(2)})
     \]
     \[
       \hat{y} = \sigma(W^{(3)} \mathbf{h}^{(2)} + \mathbf{b}^{(3)})
     \]
   - \(\hat{y}\) es la probabilidad estimada de que el tumor sea benigno
     (clase 1).

2. *C√°lculo del error*:
   - La salida \(\hat{y}\) se compara con la etiqueta real \(y \in \{0, 1\}\).
   - En problemas binarios, se usa t√≠picamente la *entrop√≠a cruzada
     binaria* (o log-loss):
     \[
       L(y, \hat{y}) = -\left[y \log(\hat{y}) + (1 - y)\log(1 - \hat{y})\right]
     \]

3. *Backpropagation*:
   - Se calculan las derivadas parciales de la p√©rdida con respecto a
     todos los pesos y sesgos mediante la regla de la cadena.
   - Se propaga el error desde la capa de salida hacia las capas
     ocultas.

4. *Actualizaci√≥n de pesos*:
   - El optimizador Adam actualiza cada par√°metro en la direcci√≥n que
     reduce la p√©rdida:
     \[
       \theta \leftarrow \theta - \eta \cdot \hat{g}
     \]
     donde \(\hat{g}\) es una versi√≥n adaptada del gradiente, y
     \(\eta\) la tasa de aprendizaje efectiva.

** Evaluaci√≥n del modelo

Una vez entrenado, evaluamos el modelo sobre el conjunto de prueba:

#+begin_src python
# Predicci√≥n
y_pred = mlp.predict(X_test)

# M√©tricas
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificaci√≥n:\n")
print(classification_report(y_test, y_pred, target_names=data.target_names))
#+end_src

*** M√©tricas principales

- *Accuracy*:
  - Proporci√≥n de predicciones correctas:
    \[
      \text{Accuracy} = \frac{\text{n√∫mero de aciertos}}{\text{n√∫mero total de muestras}}
    \]
- *Precision*:
  - De todos los ejemplos predichos como positivos, qu√© fracci√≥n son
    realmente positivos.
  - Importante para evitar falsos positivos.

- *Recall (Sensibilidad)*:
  - De todos los ejemplos realmente positivos, qu√© fracci√≥n se detecta
    correctamente.
  - En diagn√≥stico m√©dico, el recall para la clase ‚Äúmaligno‚Äù es cr√≠tico
    (minimizar falsos negativos).

- *F1-score*:
  - Media arm√≥nica de precision y recall:
    \[
      F1 = 2 \cdot \frac{\text{precision} \cdot \text{recall}}{\text{precision} + \text{recall}}
    \]
  - √ötil cuando hay cierto desbalance entre clases.

El dataset Breast Cancer suele producir *accuracy* muy altas (por
encima de 95 %) con modelos bien entrenados, debido a que las
caracter√≠sticas est√°n relativamente bien separadas.

** Interpretaci√≥n matem√°tica de la salida binaria

En este modelo binario, la capa de salida puede verse como una neurona
con activaci√≥n *sigmoide (log√≠stica)*:

#+begin_latex
\sigma(z) = \frac{1}{1 + e^{-z}}
#+end_latex

donde:

- \(z = \mathbf{w} \cdot \mathbf{h} + b\),
- \(\mathbf{h}\) es el vector de activaciones de la √∫ltima capa oculta.

La salida \(\sigma(z)\) se interpreta como:

- \(\sigma(z) \approx 1\): alta probabilidad de clase 1 (benigno),
- \(\sigma(z) \approx 0\): alta probabilidad de clase 0 (maligno).

En scikit-learn, la predicci√≥n de clase se realiza t√≠picamente como:

- Si \(\sigma(z) \geq 0.5\) ‚Üí clase 1 (benigno).
- Si \(\sigma(z) < 0.5\) ‚Üí clase 0 (maligno).

Este umbral puede modificarse en contextos m√©dicos, por ejemplo:

- usar un umbral menor que 0.5 para aumentar la sensibilidad a tumores
  malignos (aceptando m√°s falsos positivos).

** Predicci√≥n de una nueva muestra

Podemos usar el modelo entrenado para predecir el diagn√≥stico de un
nuevo paciente.

En este ejemplo, tomamos la primera muestra del set de prueba (ya
normalizada) y realizamos la predicci√≥n:

#+begin_src python
# Ejemplo con la primera fila del set de prueba
nuevo_paciente = X_test[0:1]     # forma (1, 30)
pred = mlp.predict(nuevo_paciente)
print("Resultado del diagn√≥stico:", data.target_names[pred[0]])
#+end_src

*** Comentarios importantes

- Es fundamental que la nueva muestra haya sido procesada con el mismo:

  1. Conjunto de caracter√≠sticas (mismas columnas y orden).
  2. Mismo procedimiento de normalizaci√≥n (mismo =scaler=, con las
     medias y desviaciones aprendidas en el entrenamiento).

- En la pr√°ctica, se suele:

  - guardar el modelo entrenado (por ejemplo con =joblib=),
  - guardar tambi√©n el objeto =StandardScaler=,
  - aplicar ambos de manera coherente a los nuevos datos.

** Resumen conceptual

Este ejemplo ilustra varios conceptos clave en el uso de redes
neuronales (MLP) para clasificaci√≥n binaria en un contexto m√©dico:

- Importancia de:
  - Partici√≥n entrenamiento/prueba estratificada.
  - Normalizaci√≥n de caracter√≠sticas.
  - Arquitectura de red (capas y neuronas).
  - Funci√≥n de activaci√≥n (ReLU).
  - Optimizador (Adam) y n√∫mero de iteraciones.

- Interpretaci√≥n de la salida:
  - Probabilidad generada por una funci√≥n sigmoide.
  - Decisi√≥n de clase basada en un umbral.

- Evaluaci√≥n:
  - No basta con accuracy: hay que considerar precision, recall y F1,
    especialmente para la clase de inter√©s (por ejemplo, ‚Äúmaligno‚Äù).

Este mismo flujo (carga, partici√≥n, normalizaci√≥n, definici√≥n de modelo,
entrenamiento, evaluaci√≥n, predicci√≥n) puede adaptarse a otros modelos
(√°rboles, SVM, LSTM, etc.) y a otros datasets de clasificaci√≥n binaria
o multiclase.


* Redes Neuronales LSTM (Long Short-Term Memory)

Las redes neuronales LSTM (*Long Short-Term Memory*) son un tipo especial
de **Red Neuronal Recurrente (RNN)** dise√±ada para trabajar con datos
**secuenciales** y, en particular, para **recordar dependencias a largo
plazo**.

Se utilizan cuando el *orden* de los datos importa:

- Texto (oraciones, p√°rrafos, documentos).
- Series temporales (precios, temperatura, se√±ales).
- Audio y voz.
- Secuencias de eventos (logs, clics, acciones de usuario, etc.).

Su principal aporte es resolver (o al menos mitigar fuertemente) el
problema del **desvanecimiento del gradiente (vanishing gradient)** que
afecta a las RNN simples cuando manejan secuencias largas.

** Estructura general de una RNN

En una RNN ‚Äúsimple‚Äù, en cada paso temporal \(t\):

- Se recibe una entrada \(x_t\).
- Se tiene un estado oculto anterior \(h_{t-1}\).
- Se actualiza el estado oculto actual \(h_t\) con:

#+begin_latex
h_t = \phi(W_{xh} x_t + W_{hh} h_{t-1} + b_h)
#+end_latex

donde:

- \(W_{xh}\) y \(W_{hh}\) son matrices de pesos,
- \(b_h\) es el sesgo,
- \(\phi\) es una funci√≥n de activaci√≥n (t√≠picamente =tanh= o =ReLU=).

El estado final (o todos los estados) se usan para hacer predicciones.

*** Problema: vanishing y exploding gradients

Durante el entrenamiento, se aplica *Backpropagation Through Time (BPTT)*,
es decir, se retropropagan los gradientes a trav√©s de todos los pasos
temporales.

En secuencias largas:

- Los gradientes pueden volverse **muy peque√±os** ‚Üí la red ‚Äúolvida‚Äù las
  dependencias lejanas (problema de *vanishing gradient*).
- O volverse **muy grandes** ‚Üí inestabilidad num√©rica (problema de
  *exploding gradient*).

Consecuencia: las RNN simples tienen dificultades para **aprender
relaciones de largo plazo**, por ejemplo, la dependencia entre una
palabra al principio de una oraci√≥n y otra al final.

** Motivaci√≥n de las LSTM

Las LSTM fueron propuestas para permitir que la red:

- **Mantenga informaci√≥n relevante durante muchos pasos temporales**.
- **Controle qu√© recordar y qu√© olvidar**.
- Facilite el flujo de gradiente a trav√©s del tiempo, reduciendo el
  problema del desvanecimiento.

La idea principal es introducir una **celda de memoria** y un sistema de
**puertas (gates)** que regulan el flujo de informaci√≥n.

** Arquitectura interna de una celda LSTM

En lugar de solo tener el estado oculto \(h_t\), la LSTM mantiene:

- un **estado de memoria** \(c_t\) (a veces llamado *cell state*),
- un **estado oculto** \(h_t\) (la ‚Äúsalida‚Äù en ese paso).

En cada paso temporal \(t\), la LSTM procesa:

- la entrada actual \(x_t\),
- el estado oculto anterior \(h_{t-1}\),
- el estado de memoria anterior \(c_{t-1}\).

Y calcula:

- una *puerta de olvido* \(f_t\),
- una *puerta de entrada* \(i_t\),
- una *candidata de memoria* \(\tilde{c}_t\),
- una *puerta de salida* \(o_t\),
- el nuevo estado de memoria \(c_t\),
- el nuevo estado oculto \(h_t\).

*** Ecuaciones de la LSTM

T√≠picamente, las ecuaciones de una LSTM (versi√≥n ‚Äúest√°ndar‚Äù) son:

#+begin_latex
\begin{aligned}
f_t &= \sigma(W_f [h_{t-1}, x_t] + b_f) \\
i_t &= \sigma(W_i [h_{t-1}, x_t] + b_i) \\
\tilde{c}_t &= \tanh(W_c [h_{t-1}, x_t] + b_c) \\
c_t &= f_t \odot c_{t-1} + i_t \odot \tilde{c}_t \\
o_t &= \sigma(W_o [h_{t-1}, x_t] + b_o) \\
h_t &= o_t \odot \tanh(c_t)
\end{aligned}
#+end_latex

donde:

- \(\sigma\) es la funci√≥n sigmoide,
- \(\tanh\) es la tangente hiperb√≥lica,
- \(\odot\) es el producto elemento a elemento,
- \([h_{t-1}, x_t]\) indica la concatenaci√≥n de vectores.

*** Interpretaci√≥n de las puertas

- \(f_t\) (*forget gate* o puerta de olvido):  
  - Toma valores en \([0,1]\) (por la sigmoide).
  - Decide cu√°nto de la memoria anterior \(c_{t-1}\) se conserva.
  - Si \(f_t \approx 1\) ‚Üí se mantiene casi toda la memoria anterior.
  - Si \(f_t \approx 0\) ‚Üí se olvida casi todo.

- \(i_t\) (*input gate* o puerta de entrada):  
  - Controla cu√°nta de la nueva informaci√≥n candidata \(\tilde{c}_t\) se
    incorpora a la memoria.
  - Valores cercanos a 1 permiten ‚Äúescribir‚Äù nueva informaci√≥n; valores
    cercanos a 0 bloquean escritura.

- \(\tilde{c}_t\) (candidata de memoria):  
  - Es el nuevo contenido potencial para la memoria.
  - Se combina con \(i_t\) para actualizar \(c_t\).

- \(c_t\) (*cell state*):  
  - Es la memoria principal de la LSTM.
  - Se actualiza como:
    \[
      c_t = f_t \odot c_{t-1} + i_t \odot \tilde{c}_t
    \]
  - Puede transportar informaci√≥n durante muchos pasos, ya que el
    gradiente puede fluir a lo largo de \(c_t\) con menos atenuaci√≥n.

- \(o_t\) (*output gate* o puerta de salida):  
  - Controla qu√© parte de la memoria \(c_t\) se expone como salida \(h_t\).

- \(h_t\) (estado oculto / salida):  
  - Es la ‚Äúrepresentaci√≥n‚Äù que se usa para producir salidas en cada
    paso, o para alimentar capas posteriores.

** Intuici√≥n conceptual

Una forma intuitiva de entender una LSTM es verla como una **celda de
memoria con una ‚Äúllave de escritura‚Äù, una ‚Äúllave de borrado‚Äù y una
‚Äúllave de lectura‚Äù**:

- *Olvido*: la red decide qu√© partes de la memoria vieja ya no son
  relevantes y las borra parcialmente (puerta \(f_t\)).
- *Escritura*: la red decide qu√© nueva informaci√≥n vale la pena guardar
  (puerta \(i_t\) y candidata \(\tilde{c}_t\)).
- *Lectura*: la red decide qu√© parte de la memoria compartir como salida
  (puerta \(o_t\)).

Esto permite que la red conserve informaci√≥n importante durante muchos
pasos temporales, por ejemplo:

- el tema general de una oraci√≥n,
- la tendencia de una serie temporal,
- el contexto de una conversaci√≥n, etc.

** Entrenamiento de una LSTM

El entrenamiento de una LSTM sigue el mismo esquema general que otras
redes neuronales:

1. **Forward pass**:
   - La secuencia completa \((x_1, x_2, \dots, x_T)\) se ingresa paso a
     paso.
   - En cada paso se actualizan \(c_t\) y \(h_t\).
   - Se produce una salida (por ejemplo, en cada paso o solo al final).

2. **C√°lculo de la p√©rdida**:
   - Se compara la salida de la red con la etiqueta real.
   - Se usa una funci√≥n de p√©rdida acorde al problema:
     - Clasificaci√≥n: entrop√≠a cruzada (multiclase o binaria).
     - Regresi√≥n: error cuadr√°tico medio (MSE), etc.

3. **Backpropagation Through Time (BPTT)**:
   - Se retropropaga el gradiente desde el √∫ltimo paso hacia los
     primeros.
   - Se actualizan los pesos de todas las puertas y conexiones.

4. **Actualizaci√≥n de par√°metros**:
   - Se utilizan optimizadores como SGD, Adam, RMSprop.
   - En la pr√°ctica, Adam y RMSprop son muy populares en LSTM.

Gracias a la estructura de memoria, los gradientes a trav√©s de \(c_t\)
tienden a **no desaparecer tan r√°pido** como en una RNN simple.

** Tipos de tareas t√≠picas con LSTM

Las LSTM se aplican a muchas tareas de secuencia:

- *Modelado de lenguaje*:
  - Predecir la siguiente palabra de una oraci√≥n.
  - Asignar probabilidad a una secuencia de palabras.

- *Traducci√≥n autom√°tica*:
  - Modelos encoder‚Äìdecoder (LSTM para codificar una oraci√≥n, otra LSTM
    para decodificar en otro idioma).

- *Etiquetado secuencial*:
  - Etiquetado de partes del habla (POS tagging).
  - Reconocimiento de entidades nombradas (NER).

- *Series temporales*:
  - Predicci√≥n de valores futuros (ej. precios de acciones).
  - Detecci√≥n de anomal√≠as en se√±ales.

- *Procesamiento de audio / voz*:
  - Reconocimiento de voz.
  - S√≠ntesis de voz (en combinaci√≥n con otras arquitecturas).

** Variantes y extensiones de LSTM

A partir de la LSTM est√°ndar, han surgido m√∫ltiples variantes:

- *LSTM bidireccional (Bidirectional LSTM)*:
  - Procesa la secuencia en dos direcciones:
    - de izquierda a derecha (forward),
    - de derecha a izquierda (backward).
  - Se concatena la informaci√≥n de ambos sentidos.
  - √ötil cuando se tiene acceso a la secuencia completa (texto, frases).

- *Pilado de LSTMs (Stacked LSTM)*:
  - Varias capas LSTM apiladas una sobre otra.
  - Las salidas de una capa sirven de entradas a la siguiente.
  - Permite aprender representaciones m√°s complejas.

- *LSTM con atenci√≥n (Attention)*:
  - Combinaci√≥n de LSTM con mecanismos de atenci√≥n.
  - El modelo decide a qu√© partes de la secuencia ‚Äúprestar m√°s atenci√≥n‚Äù
    al hacer una predicci√≥n.

- *GRU (Gated Recurrent Unit)*:
  - Variante simplificada de LSTM (menos puertas, menos par√°metros).
  - Suele tener rendimiento comparable en muchos problemas.

** Implementaci√≥n b√°sica en Python (Keras)

A modo de ejemplo muy simple (no ligado a un dataset espec√≠fico):

#+begin_src python
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Supongamos una secuencia de longitud 10 con 5 features por timestep
timesteps = 10
features = 5
num_samples = 100
num_classes = 3

# Datos aleatorios de ejemplo (solo para ilustrar la forma)
X = np.random.randn(num_samples, timesteps, features)
y = np.random.randint(0, num_classes, size=(num_samples,))

# One-hot encoding
y_onehot = tf.keras.utils.to_categorical(y, num_classes=num_classes)

# Definir modelo LSTM
model = Sequential([
    LSTM(32, input_shape=(timesteps, features)),
    Dense(num_classes, activation='softmax')
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

model.summary()

# Entrenamiento de ejemplo
model.fit(X, y_onehot, epochs=10, batch_size=16)
#+end_src

En este ejemplo:

- La entrada tiene forma =(num_samples, timesteps, features)=.
- La LSTM devuelve un vector (el √∫ltimo estado oculto).
- La capa =Dense= con softmax produce una distribuci√≥n de probabilidad
  sobre las clases.

** Ventajas y limitaciones de LSTM

*** Ventajas

- Manejan mejor dependencias de largo plazo que las RNN simples.
- Funcionan bien en problemas donde el orden y el contexto importan.
- Son muy flexibles y pueden combinarse con otras arquitecturas
  (convolucionales, atenci√≥n, etc.).

*** Limitaciones

- Entrenamiento relativamente costoso (m√°s par√°metros que RNN simple).
- Dif√≠ciles de paralelizar completamente debido a su naturaleza
  secuencial.
- En tareas muy complejas y con grandes vol√∫menes de datos, han sido en
  muchos casos superadas por arquitecturas basadas en *transformers*.

** Conclusi√≥n

Las LSTM representan un paso fundamental en la historia de las redes
neuronales para secuencias:

- resolvieron en gran medida el problema del desvanecimiento del
  gradiente en RNN,
- permitieron avances significativos en NLP, series temporales y voz,
- siguen siendo una herramienta muy √∫til y educativa para entender c√≥mo
  las redes pueden ‚Äúrecordar‚Äù informaci√≥n a lo largo del tiempo.

Aun cuando hoy en d√≠a los *transformers* dominen muchas aplicaciones de
NLP, las LSTM siguen siendo:

- una excelente base conceptual,
- √∫tiles en problemas con secuencias peque√±as o recursos limitados,
- y una parte importante de la ‚Äúcaja de herramientas‚Äù de cualquier
  persona que trabaja con aprendizaje profundo y datos secuenciales.


* Ejemplo Clasificaci√≥n del dataset Iris con una red LSTM

Este apartado muestra un ejemplo completo en Python usando el dataset
cl√°sico Iris y una red neuronal recurrente del tipo *LSTM* (Long Short-Term Memory)
usando la librer√≠a *Keras* (TensorFlow).

El objetivo es clasificar flores Iris en tres clases:

- Setosa
- Versicolor
- Virginica

A diferencia del MLP (Perceptr√≥n Multicapa), la LSTM est√° dise√±ada
para procesar datos *secuenciales*. En este ejemplo, forzamos la
estructura secuencial tratando las 4 caracter√≠sticas de Iris como una
secuencia de 4 pasos temporales.

** Importar librer√≠as

#+begin_src python
import numpy as np

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.utils import to_categorical
#+end_src

** Cargar el dataset Iris

#+begin_src python
iris = load_iris()
X = iris.data      # Caracter√≠sticas (150 x 4)
y = iris.target    # Clases (150,)

print(X.shape)     # (150, 4)
print(y.shape)     # (150,)
#+end_src

Las 4 caracter√≠sticas son:

- Largo del s√©palo
- Ancho del s√©palo
- Largo del p√©talo
- Ancho del p√©talo

Las clases est√°n codificadas como:

- 0 ‚Üí Setosa
- 1 ‚Üí Versicolor
- 2 ‚Üí Virginica

** Partici√≥n entrenamiento / prueba

El siguiente fragmento de c√≥digo realiza la partici√≥n del conjunto de
datos original en dos subconjuntos disjuntos: uno destinado al
entrenamiento del modelo y otro a su evaluaci√≥n.

#+begin_src python
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)
#+end_src

*** Prop√≥sito de la partici√≥n

En aprendizaje autom√°tico supervisado, es fundamental evaluar la
capacidad de generalizaci√≥n de un modelo. Para ello, los datos
disponibles se dividen en:

- *Conjunto de entrenamiento*: utilizado para ajustar los par√°metros del modelo (pesos y sesgos).
- *Conjunto de prueba*: utilizado exclusivamente para medir el desempe√±o del modelo sobre datos no vistos durante el entrenamiento.

Esta separaci√≥n permite detectar fen√≥menos como overfitting y
underfitting, y proporciona una estimaci√≥n m√°s realista del
rendimiento esperado en producci√≥n.

*** Par√°metro test_size

#+begin_src python
test_size = 0.2
#+end_src

indica que el 20 % del conjunto total de datos se reserva para el
conjunto de prueba, mientras que el 80 % restante se utiliza para
entrenamiento.

*** Reproducibilidad del experimento

El par√°metro:

#+begin_src python
random_state = 42
#+end_src

fija la semilla del generador de n√∫meros aleatorios utilizado durante
la partici√≥n. Esto garantiza que la divisi√≥n de los datos sea
reproducible.

*** Estratificaci√≥n de clases

El par√°metro:

#+begin_src python
stratify = y
#+end_src

indica que la divisi√≥n debe realizarse de forma estratificada,
conservando la proporci√≥n original de cada clase en ambos
subconjuntos.

** Normalizaci√≥n de los datos

La normalizaci√≥n de los datos de entrada es un paso cr√≠tico en el
entrenamiento de redes neuronales (incluyendo LSTM), ya que influye
directamente en la estabilidad num√©rica, la velocidad de convergencia
y la eficacia del aprendizaje.

Usaremos estandarizaci√≥n con =StandardScaler=:

#+begin_src python
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
#+end_src

Cada caracter√≠stica \(x\) se transforma seg√∫n:

#+begin_latex
x' = \frac{x - \mu}{\sigma}
#+end_latex

donde:

- \( \mu \) es la media de la caracter√≠stica,
- \( \sigma \) es la desviaci√≥n est√°ndar.

El resultado es:

- media aproximadamente 0,
- desviaci√≥n est√°ndar aproximadamente 1.

** Preparar los datos para LSTM

Las LSTM en Keras esperan entradas con forma:

- \((n\_muestras, n\_timesteps, n\_features)\)

En Iris, tenemos 4 caracter√≠sticas. Una forma simple de usar LSTM es:

- considerar una secuencia de longitud 4 (=timesteps=4=),
- con 1 caracter√≠stica por paso (=features=1=).

Esto implica reestructurar cada muestra de forma (4,) a (4, 1):

#+begin_src python
# Reshape para LSTM: (n_muestras, timesteps=4, features=1)
X_train_lstm = X_train.reshape((X_train.shape[0], 4, 1))
X_test_lstm = X_test.reshape((X_test.shape[0], 4, 1))

print(X_train_lstm.shape)  # (120, 4, 1)
print(X_test_lstm.shape)   # (30, 4, 1)
#+end_src

Adem√°s, para clasificaci√≥n multiclase con Keras, se suele usar
one-hot encoding de las etiquetas:

#+begin_src python
num_classes = len(np.unique(y))
y_train_cat = to_categorical(y_train, num_classes=num_classes)
y_test_cat = to_categorical(y_test, num_classes=num_classes)
#+end_src

** Definir la red LSTM

Definimos un modelo secuencial con una capa LSTM y una capa densa de
salida con softmax:

#+begin_src python
model = Sequential([
    LSTM(
        units=16,           # n√∫mero de unidades LSTM
        activation='tanh',  # activaci√≥n interna
        input_shape=(4, 1)  # (timesteps=4, features=1)
    ),
    Dense(num_classes, activation='softmax')
])
#+end_src

*** Arquitectura de la red

- *Capa de entrada*:
  - Forma: (4, 1)
  - 4 pasos "temporales" (cada uno con 1 valor), derivados de las 4 caracter√≠sticas.

- *Capa LSTM*:
  - =units=16=: 16 unidades de memoria.
  - Procesa la secuencia \((x_1, x_2, x_3, x_4)\) y genera una representaci√≥n que captura
    dependencias entre pasos.

- *Capa de salida (Dense + softmax)*:
  - 3 neuronas (una por clase).
  - Activaci√≥n softmax para obtener probabilidades.

** Compilaci√≥n del modelo

Escogemos una funci√≥n de p√©rdida apropiada para clasificaci√≥n
multiclase y un optimizador:

#+begin_src python
model.compile(
    loss='categorical_crossentropy',
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    metrics=['accuracy']
)
#+end_src

- =categorical_crossentropy=: log-loss multiclase.
- *Adam*: optimizador basado en descenso de gradiente con momento y tasas
  de aprendizaje adaptativas.
- Tasa de aprendizaje inicial \(\eta = 0.001\).

** Entrenamiento del modelo LSTM

#+begin_src python
history = model.fit(
    X_train_lstm,
    y_train_cat,
    epochs=200,         # n√∫mero de √©pocas
    batch_size=16,
    validation_split=0.1,
    verbose=1
)
#+end_src

Durante el entrenamiento:

*** Propagaci√≥n hacia adelante (forward pass)

- Cada muestra de entrada se considera como una secuencia de 4 pasos.
- En cada paso, la LSTM actualiza su:
  - estado oculto \(h_t\),
  - estado de memoria \(c_t\).

*** C√°lculo del error

- La salida softmax se compara con la etiqueta real codificada en one-hot.
- Se calcula la p√©rdida mediante entrop√≠a cruzada categ√≥rica.

*** Backpropagation Through Time (BPTT)

- El error se propaga hacia atr√°s a lo largo del tiempo (sobre los 4 pasos).
- Se calculan los gradientes de los pesos de la LSTM y de la capa de salida.

*** Descenso de gradiente con Adam

- Adam combina Momentum y RMSProp.
- Ajusta autom√°ticamente la tasa de aprendizaje para cada par√°metro.
- Proporciona convergencia r√°pida y estable.

** Evaluaci√≥n del modelo

Una vez entrenado el modelo, se eval√∫a su desempe√±o usando datos no
vistos (conjunto de prueba).

#+begin_src python
# Probabilidades por clase
y_pred_proba = model.predict(X_test_lstm)

# Clase predicha = √≠ndice de la probabilidad m√°xima
y_pred = np.argmax(y_pred_proba, axis=1)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificaci√≥n:\n")
print(classification_report(y_test, y_pred, target_names=iris.target_names))
#+end_src

*** M√©tricas utilizadas

- *Accuracy*: proporci√≥n total de predicciones correctas.
- *Precision*: qu√© tan confiables son las predicciones positivas.
- *Recall*: capacidad del modelo para encontrar todos los ejemplos de una clase.
- *F1-score*: balance entre precisi√≥n y recall.

En el dataset Iris, el accuracy tambi√©n suele estar en el rango del
95 % al 100 %.

** Predicci√≥n con una nueva flor

El modelo entrenado puede utilizarse para predecir nuevas muestras.
Es importante repetir el mismo preprocesamiento: normalizaci√≥n y
reshape para LSTM.

#+begin_src python
# [largo_sepalo, ancho_sepalo, largo_petalo, ancho_petalo]
flor_nueva = np.array([[5.1, 3.5, 1.4, 0.2]])

# 1) Normalizaci√≥n con el mismo scaler del entrenamiento
flor_nueva_scaled = scaler.transform(flor_nueva)

# 2) Reshape para LSTM: (1, timesteps=4, features=1)
flor_nueva_lstm = flor_nueva_scaled.reshape((1, 4, 1))

# 3) Predicci√≥n
proba = model.predict(flor_nueva_lstm)
prediccion = np.argmax(proba, axis=1)

print("Clase predicha:", iris.target_names[prediccion[0]])
#+end_src

Es fundamental aplicar la misma normalizaci√≥n y la misma estructura de
entrada (forma (1, 4, 1)) que se usaron en el entrenamiento.

** Interpretaci√≥n matem√°tica b√°sica de la LSTM

En una LSTM, en cada paso temporal \(t\) se procesan:

- la entrada \(x_t\),
- el estado oculto anterior \(h_{t-1}\),
- el estado de memoria anterior \(c_{t-1}\).

La LSTM utiliza *puertas* que controlan el flujo de informaci√≥n:

#+begin_latex
\begin{aligned}
f_t &= \sigma(W_f [h_{t-1}, x_t] + b_f) \\
i_t &= \sigma(W_i [h_{t-1}, x_t] + b_i) \\
\tilde{c}_t &= \tanh(W_c [h_{t-1}, x_t] + b_c) \\
c_t &= f_t \odot c_{t-1} + i_t \odot \tilde{c}_t \\
o_t &= \sigma(W_o [h_{t-1}, x_t] + b_o) \\
h_t &= o_t \odot \tanh(c_t)
\end{aligned}
#+end_latex

donde:

- \(\sigma\) es la funci√≥n sigmoide,
- \(\odot\) denota el producto elemento a elemento.

Al final de la secuencia (tras los 4 pasos), el √∫ltimo estado oculto
\(h_T\) se pasa a la capa densa con funci√≥n softmax:

#+begin_latex
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}
#+end_latex

lo que permite interpretar las salidas como probabilidades para cada
clase (Setosa, Versicolor, Virginica).


* Bibliograf√≠a  Deep Learning

** Te√≥rica y Acad√©mica :MATEMATICAS:FUNDAMENTOS:
Libros dise√±ados para entender el "porqu√©" de los algoritmos.

*** Deep Learning
- *Autores:* Ian Goodfellow, Yoshua Bengio y Aaron Courville.
- *Editorial:* MIT Press (2016).
- *Nota:* Considerada la "Biblia" de la IA. Cubre √°lgebra lineal, probabilidad y arquitecturas complejas.
- *Web:* [[https://www.deeplearningbook.org/][Acceso gratuito a la versi√≥n web (HTML)]]

*** Neural Networks and Deep Learning: A Textbook
- *Autor:* Charu C. Aggarwal.
- *Editorial:* Springer (2018).
- *Enfoque:* Muy estructurado para estudiantes de ingenier√≠a y computaci√≥n.

** Pr√°ctica y Programaci√≥n :PYTHON:PYTORCH:KERAS:
Libros enfocados en la implementaci√≥n inmediata usando librer√≠as de Python.

*** Deep Learning with Python (3rd Edition)
- *Autor:* Fran√ßois Chollet (Creador de Keras).
- *Editorial:* Manning Publications (2025).
- *Por qu√© leerlo:* Explicaciones excepcionales sobre la intuici√≥n detr√°s de las redes neuronales.
- *Enlace:* [[https://www.manning.com/books/deep-learning-with-python-third-edition][P√°gina del libro]]

*** Hands-On Machine Learning with Scikit-Learn and PyTorch
- *Autor:* Aur√©lien G√©ron.
- *Editorial:* O'Reilly Media (Edici√≥n 2025).
- *Enfoque:* Es el manual m√°s completo para pasar de la teor√≠a a la pr√°ctica industrial. Cubre desde regresiones simples hasta Transformers.

** Aprendizaje "Desde Cero" :NUMPY:LOGICA:
Ideales para entender c√≥mo funciona el "motor" de una red neuronal sin usar herramientas autom√°ticas.

*** Grokking Deep Learning
- *Autor:* Andrew Trask.
- *Editorial:* Manning Publications.
- *Descripci√≥n:* Aprender√°s a programar redes neuronales usando solo =NumPy=. Ideal si quieres entender la "caja negra".

*** Neural Networks from Scratch (NNFS)
- *Autores:* Harrison Kinsley (Sentdex) y Daniel Kukie≈Ça.
- *Descripci√≥n:* Basado en c√≥digo puro de Python. Muy popular entre autodidactas.
- *Web:* [[https://nnfs.io/][Sitio Oficial de NNFS]]

** Tabla Comparativa para Elecci√≥n R√°pida

| Libro      | Nivel        | Enfoque Principal  | Tecnolog√≠a           |
|------------+--------------+--------------------+----------------------|
| Goodfellow | Avanzado     | Teor√≠a/Matem√°ticas | Gen√©rico             |
| Chollet    | Intermedio   | Intuici√≥n          | Keras/TensorFlow     |
| G√©ron      | Todos        | Pr√°ctica/Industria | PyTorch/Scikit-Learn |
| Trask      | Principiante | L√≥gica Interna     | NumPy                |



