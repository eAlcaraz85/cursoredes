#+TITLE: Redes Neuronales Artificiales
#+AUTHOR: Eduardo Alcaraz
#+LANGUAGE: es
#+LaTeX_HEADER: \usepackage[spanish]{inputenc}
#+SETUPFILE: /home/likcos/Dropbox/org/cursos/redesneuronales/theme-readtheorg-local.setup
#+EXPORT_FILE_NAME: index.html
#+OPTIONS: num:nil
#+HTML_HEAD: <style> #content{max-width:1800px;}</style>
#+HTML_HEAD: <style>pre.src {background-color: #303030; color: #e5e5e5;}</style>




* Presentación del Curso
** Objetivo general
  Este curso tiene como objetivo proporcionar una
  comprensión *profunda y progresiva* de las redes neuronales
  artificiales, desde sus fundamentos teóricos hasta las principales
  arquitecturas modernas utilizadas en la industria y la
  investigación.


- Fundamentos matemáticos y conceptuales
- Funcionamiento interno de una red neuronal
- Entrenamiento y optimización
- Arquitecturas principales
- Intuición práctica y casos de uso



* Introducción a la Inteligencia Artificial (IA)
** Definición formal

La *Inteligencia Artificial* es el área de la computación que estudia
  cómo construir sistemas capaces de realizar tareas que, si fueran
  realizadas por humanos, requerirían inteligencia.

Esto incluye capacidades como:

- Aprender de la experiencia
- Razonar
- Reconocer patrones
- Tomar decisiones bajo incertidumbre

La IA no implica necesariamente consciencia; se centra en *comportamiento inteligente observable*.

** IA débil vs IA fuerte

- *IA débil*: sistemas especializados en una tarea concreta (la IA actual)
- *IA fuerte*: inteligencia general comparable a la humana (teórica)

Las redes neuronales pertenecen claramente a la IA débil.


* Machine Learning (Aprendizaje Automático)
  ** Relación entre IA y ML
  El *Machine Learning (ML)* es una subdisciplina de la IA. Mientras la IA es el objetivo general, el ML es una de las herramientas principales para alcanzarlo.

Idea clave:
#+begin_quote
En lugar de programar reglas, el sistema aprende las reglas a partir de datos.
#+end_quote

** Tipos de aprendizaje

- *Supervisado*: datos con etiqueta (clasificación, regresión)
- *No supervisado*: datos sin etiqueta (clustering, reducción de dimensión)
- *Por refuerzo*: aprendizaje mediante recompensa y castigo

Las redes neuronales pueden adaptarse a los tres esquemas.


* Historia de las Redes Neuronales
** Contexto histórico
Desde mediados del siglo XX, científicos han intentado entender si la inteligencia podía ser replicada mediante modelos matemáticos.

** McCulloch y Pitts (1943)
Propusieron la primera neurona artificial basada en lógica
booleana. Demostraron que redes de estas neuronas podían computar
cualquier función lógica.

Este trabajo sentó las bases teóricas de las redes neuronales.

** Perceptrón y optimismo inicial
En los años 50 y 60, el perceptrón generó grandes expectativas al ser uno de los primeros sistemas que *aprendía* automáticamente.

** Críticas y estancamiento
El libro *Perceptrons* (Minsky & Papert, 1969) demostró limitaciones severas del perceptrón, provocando una fuerte caída en el interés por las redes neuronales.

** Renacimiento moderno

Con mayor poder computacional, grandes bases de datos y mejores algoritmos, las redes neuronales resurgen como *Deep Learning*.





* La Neurona Artificial
** Motivación
  Una red neuronal artificial es un modelo matemático inspirado en la
  organización y conectividad de las neuronas biológicas, que abstrae
  su funcionamiento esencial para construir sistemas capaces de
  aprender representaciones a partir de datos mediante el ajuste de
  parámetros.

** Componentes

- Entradas: variables numéricas
- Pesos: importancia relativa de cada entrada
- Bias: ajuste del umbral
- Activación: decisión final

** Modelo matemático
#+begin_src text
z = w·x + b
a = f(z)
#+end_src

Este modelo es la unidad básica de todas las redes neuronales modernas.


* El Perceptrón
** Definición
  El perceptrón es una neurona artificial entrenable utilizada para clasificación binaria.

** Interpretación geométrica
El perceptrón aprende una *frontera de decisión lineal* que separa los datos en dos clases.

** Aprendizaje
Cuando el perceptrón se equivoca, ajusta sus pesos para reducir el error.

** Limitaciones
No puede aprender relaciones no lineales, como XOR.


* ¿Qué es un problema linealmente separable?

**  Intuición básica 

Un problema es linealmente separable si puedes separar las clases usando una línea recta (en 2D),
un plano (en 3D), o en general un hiperplano.

Si existe una sola frontera recta que divide perfectamente las clases, el problema es linealmente separable.



* Estructura de un Perceptrón Simple


** Entradas (Inputs)
- Representadas como $x_1, x_2, ..., x_n$.
- Son los datos brutos o características que recibe el modelo.

** Pesos Sinápticos (Weights)
- Representados como $w_1, w_2, ..., w_n$.
- Determinan la importancia o influencia de cada entrada en el resultado final.

** Suma Ponderada (Weighted Sum)
- Es la combinación lineal de las entradas y los pesos.
- La fórmula matemática es:
  $$z = \sum_{i=1}^{n} w_i x_i + b$$


** Sesgo (Bias)
- Representado generalmente como $b$ (o $w_0$).
- Permite desplazar la función de activación hacia la izquierda o derecha para ajustar mejor los datos.

** Función de Activación
- Decide si la neurona debe "dispararse" (activarse) o no.
- En el perceptrón original de Rosenblatt, se utiliza la *Función Escalón* (Heaviside):
  - $f(z) = 1$ si $z > 0$
  - $f(z) = 0$ en caso contrario.

** Salida (Output)
- Es el resultado final del procesamiento ($\hat{y}$).
- En un perceptrón simple, suele ser un valor binario (0 o 1).



* 1. El Escenario: La Decisión de la Cena
Para entender cómo aprende una IA, vamos a usar un ejemplo de la vida real. Queremos que nuestra neurona artificial aprenda cuándo estamos "Satisfechos" (1) o "Inconformes" (0).

** Nuestras Entradas (Inputs)
- $x_0$: ¿Hay Tacos? (1 = Sí, 0 = No)
- $x_1$: ¿Hay Refresco? (1 = Sí, 0 = No)

** El Peso (Weight): La Importancia
No todo nos hace igual de felices. Los **Pesos** ($w_0, w_1$) representan qué tanto nos importa cada ingrediente. 
- Si el peso del taco es alto, el taco es fundamental para nuestra felicidad.

* 2. ¿Cómo toma la decisión? (La Suma y el Sesgo)
La neurona hace un cálculo matemático simple:
$$net = (x_0 \cdot w_0) + (x_1 \cdot w_1) - \text{bias}$$



** El Sesgo (Bias)
El **Bias** es nuestro "nivel de exigencia". Si el Bias es muy alto, necesitaremos mucha comida (pesos altos) para poder llegar a estar satisfechos.

* 3. El Descenso del Gradiente: ¿Cómo "Aprende" la Neurona?
Cuando la neurona se equivoca, necesita ajustar sus pesos. Este proceso se llama **Descenso del Gradiente**.

** El Error: La Brújula
Si esperábamos estar felices (~target = 1~) pero la neurona dice que estamos tristes (~net = 0~), tenemos un **Error de 1**.
$$Error = Target - Net$$

** El Ajuste (La Regla Delta)
Para corregir el error, cambiamos los pesos usando esta lógica:
1. Miramos el **Error**.
2. Miramos la **Entrada** (¿Quién tuvo la culpa? Si no había tacos, el taco no pudo causar el error).
3. Aplicamos el **Learning Rate (K)**: Que es qué tan rápido queremos aprender.

$$Nuevo\_Peso = Peso\_Actual + (K \cdot Error \cdot Entrada)$$


Imagina que $K = 0.1$ y el Peso inicial del taco es $0.5$.
1. **Situación:** Hay tacos ($x_0=1$), pero la red dice "Triste" ($net=0$). Nosotros queríamos "Feliz" ($target=1$).
2. **Cálculo del Error:** $1 - 0 = 1$.
3. **Ajuste del Peso:**
   - $Delta = 0.1 \cdot 1 \cdot 1 = 0.1$
   - $Nuevo\_Peso\_Taco = 0.5 + 0.1 = 0.6$

**Resultado:** La próxima vez que haya tacos, la neurona estará un poco más cerca de hacernos felices. ¡Eso es el aprendizaje!

* 5. Conclusión
- El **Gradiente** nos dice en qué dirección mover los pesos para que el error sea cero.
- El **Learning Rate** controla qué tan grandes son los pasos que damos hacia esa solución.
- Si repetimos este proceso miles de veces (Épocas), la neurona encontrará los pesos perfectos para nuestra felicidad.





*  Manual de Entornos Virtuales en Python

** Introducción
El uso de entornos virtuales es esencial para mantener las
dependencias de tus proyectos aisladas. En este manual aprenderás a
gestionarlos usando el módulo estándar =venv=.

** Flujo de Trabajo Básico

*** 1. Creación del entorno
Para crear un entorno virtual, navega a la raíz de tu proyecto en la terminal (o dentro de un buffer de Emacs con =M-x shell=) y ejecuta:

#+begin_src bash
python -m venv .venv
#+end_src

*Nota:* El nombre =.venv= es una convención que hace que el directorio sea oculto en sistemas Unix.

*** 2. Activación
La activación depende de tu sistema operativo:

**** En Windows (PowerShell)
#+begin_src powershell
.\.venv\Scripts\Activate.ps1
#+end_src

**** En macOS / Linux
#+begin_src bash
source .venv/bin/activate
#+end_src

** Gestión de paquetes
Una vez activado (verás el prefijo =(.venv)= en tu prompt), puedes instalar librerías:

#+begin_src bash
pip install requests pandas
#+end_src


** El archivo de Requerimientos
Es fundamental para la reproducibilidad del proyecto.

** Exportar dependencias
#+begin_src bash
pip freeze > requirements.txt
#+end_src

** Instalar desde el archivo
#+begin_src bash
pip install -r requirements.txt
#+end_src

** Tips de Limpieza
Para salir del entorno virtual:
#+begin_src bash
deactivate
#+end_src

Para borrar el entorno, simplemente elimina la carpeta:
#+begin_src bash
rm -rf .venv  # En Linux/macOS
rmdir /s /q .venv  # En Windows
#+end_src

---
#+BEGIN_QUOTE
"Keep your global Python clean, keep your projects isolated."
#+END_QUOTE




** Entornos Virtuales Python (Edición Windows)

** Requisitos Previos
1. Tener instalado Python (descargado de [[https://www.python.org/][python.org]] o la Microsoft Store).
2. Durante la instalación, asegúrate de marcar la casilla: **"Add Python to PATH"**.

** Flujo de Trabajo en Windows

*** 1. Crear el Entorno Virtual
Abre tu terminal (PowerShell o CMD) en la carpeta de tu proyecto. El comando es el mismo para ambos:

#+begin_src powershell
python -m venv venv
#+end_src

*** 2. El Paso Crítico: La Activación
En Windows, la activación depende de qué terminal estés usando.

**** Opción A: PowerShell (Recomendado)
Si es la primera vez que usas scripts en Windows, podrías recibir un error de seguridad. Primero, ejecuta esto como administrador (solo una vez):
#+begin_src powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
#+end_src

Luego, para activar el entorno:
#+begin_src powershell
.\venv\Scripts\Activate.ps1
#+end_src

**** Opción B: Símbolo del Sistema (CMD)
#+begin_src cmd
.\venv\Scripts\activate.bat
#+end_src

*** 3. Confirmación
Sabrás que el entorno está activo porque el nombre =(venv)= aparecerá a la izquierda de la ruta en tu terminal:
#+example
(venv) C:\Proyectos\MiProyecto>
#+example

** Gestión de Librerías con PIP

*** Instalación de paquetes
Una vez activo el entorno, instala lo que necesites:
#+begin_src powershell
pip install pandas requests openpyxl
#+end_src

*** Congelar dependencias (Compartir proyecto)
Para que otros participantes tengan exactamente lo mismo que tú:
#+begin_src powershell
pip freeze > requirements.txt
#+end_src

*** Instalar desde un archivo recibido
Si un compañero te pasa su =requirements.txt=:
#+begin_src powershell
pip install -r requirements.txt
#+end_src

** Uso de Entornos en Emacs (Windows)

Para que Emacs en Windows gestione bien el entorno, añade esto a tu archivo de configuración (=init.el= o =.emacs=):

*** Instalación del paquete pyvenv
#+begin_src elisp
(use-package pyvenv
  :ensure t
  :config
  (pyvenv-mode 1))
#+end_src

*** Cómo activarlo dentro de Emacs
1. Presiona =M-x pyvenv-activate=.
2. Emacs te pedirá la ruta. Navega hasta la carpeta =venv= de tu proyecto.
3. Al seleccionarla, Emacs usará ese intérprete de Python para todos los scripts que ejecutes.

** Solución de Problemas Comunes en Windows

| Error / Problema | Solución |
| :--- | :--- |
| "python" no se reconoce | Reinstala Python y marca "Add to PATH" o usa el comando `py`. |
| Error de "Execution Policy" | Ejecuta `Set-ExecutionPolicy RemoteSigned -Scope CurrentUser`. |
| No aparece el (venv) | Asegúrate de usar el comando de activación correcto para tu terminal (.ps1 vs .bat). |

** Desactivación y Limpieza
Para salir del entorno:
#+begin_src powershell
deactivate
#+end_src

Si quieres borrar el entorno por completo (para empezar de cero):
#+begin_src powershell
rmdir /s /q venv
#+end_src

---
#+BEGIN_IMPORTANT
*Recordatorio:* Nunca incluyas la carpeta =venv= en tus archivos compartidos o en tu repositorio de Git. Solo comparte el código y el archivo =requirements.txt=.
#+END_IMPORTANT






* Redes Multicapa (MLP)
  ** Necesidad de capas ocultas
  Para resolver problemas no lineales, se introducen capas ocultas que permiten componer funciones simples en funciones complejas.

** Capacidad de representación
Un MLP con suficientes neuronas puede aproximar cualquier función continua (teorema de aproximación universal).

** Estructura

* Entrada
* Capas ocultas
* Salida
* Perceptrón ejemplo (Python)

Un perceptrón es una neurona artificial que:
1. Recibe entradas ($x_1, x_2, \dots$).
2. Las multiplica por pesos ($w_1, w_2, \dots$).
3. Suma un sesgo ($b$).
4. Aplica una función de activación (ej. Escalón).

** Perceptrón para una compuerta "AND"
Este código simula una neurona que solo se activa si ambas entradas son 1.

#+begin_src python
def perceptron_and(x1, x2):
    # 1. Definimos los Pesos y el Sesgo (Bias)
    # Estos valores normalmente se aprenden, aquí los asignamos manualmente
    w1, w2 = 0.5, 0.5
    bias = -0.7

    # 2. Suma ponderada: (x1 * w1) + (x2 * w2) + bias
    suma = (x1 * w1) + (x2 * w2) + bias

    # 3. Función de activación (Escalón de Heaviside)
    # Si la suma es mayor a 0, la neurona se dispara (1)
    if suma > 0:
        return 1
    else:
        return 0

# Prueba de la tabla de verdad AND
entradas = [(0, 0), (0, 1), (1, 0), (1, 1)]

print("Entrada | Salida")
print("--------|-------")
for e in entradas:
    resultado = perceptron_and(e[0], e[1])
    print(f" {e}  |   {resultado}")
#+end_src

#+RESULTS:
: Entrada | Salida
: --------|-------
:  (0, 0)  |   0
:  (0, 1)  |   0
:  (1, 0)  |   0
:  (1, 1)  |   1


* Bibliografía  Deep Learning

** Teórica y Académica :MATEMATICAS:FUNDAMENTOS:
Libros diseñados para entender el "porqué" de los algoritmos.

*** Deep Learning
- *Autores:* Ian Goodfellow, Yoshua Bengio y Aaron Courville.
- *Editorial:* MIT Press (2016).
- *Nota:* Considerada la "Biblia" de la IA. Cubre álgebra lineal, probabilidad y arquitecturas complejas.
- *Web:* [[https://www.deeplearningbook.org/][Acceso gratuito a la versión web (HTML)]]

*** Neural Networks and Deep Learning: A Textbook
- *Autor:* Charu C. Aggarwal.
- *Editorial:* Springer (2018).
- *Enfoque:* Muy estructurado para estudiantes de ingeniería y computación.

** Práctica y Programación :PYTHON:PYTORCH:KERAS:
Libros enfocados en la implementación inmediata usando librerías de Python.

*** Deep Learning with Python (3rd Edition)
- *Autor:* François Chollet (Creador de Keras).
- *Editorial:* Manning Publications (2025).
- *Por qué leerlo:* Explicaciones excepcionales sobre la intuición detrás de las redes neuronales.
- *Enlace:* [[https://www.manning.com/books/deep-learning-with-python-third-edition][Página del libro]]

*** Hands-On Machine Learning with Scikit-Learn and PyTorch
- *Autor:* Aurélien Géron.
- *Editorial:* O'Reilly Media (Edición 2025).
- *Enfoque:* Es el manual más completo para pasar de la teoría a la práctica industrial. Cubre desde regresiones simples hasta Transformers.

** Aprendizaje "Desde Cero" :NUMPY:LOGICA:
Ideales para entender cómo funciona el "motor" de una red neuronal sin usar herramientas automáticas.

*** Grokking Deep Learning
- *Autor:* Andrew Trask.
- *Editorial:* Manning Publications.
- *Descripción:* Aprenderás a programar redes neuronales usando solo =NumPy=. Ideal si quieres entender la "caja negra".

*** Neural Networks from Scratch (NNFS)
- *Autores:* Harrison Kinsley (Sentdex) y Daniel Kukieła.
- *Descripción:* Basado en código puro de Python. Muy popular entre autodidactas.
- *Web:* [[https://nnfs.io/][Sitio Oficial de NNFS]]

* Tabla Comparativa para Elección Rápida

| Libro      | Nivel        | Enfoque Principal  | Tecnología           |
|------------+--------------+--------------------+----------------------|
| Goodfellow | Avanzado     | Teoría/Matemáticas | Genérico             |
| Chollet    | Intermedio   | Intuición          | Keras/TensorFlow     |
| Géron      | Todos        | Práctica/Industria | PyTorch/Scikit-Learn |
| Trask      | Principiante | Lógica Interna     | NumPy                |

